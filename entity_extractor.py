"""
å®ä½“å’Œå…³ç³»æå–æ¨¡å—
ä½¿ç”¨LLMä»æ–‡æ¡£ä¸­æå–å®ä½“ã€å…³ç³»å’Œå±æ€§ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±çš„åŸºç¡€
"""

from typing import List, Dict, Tuple
import time
import asyncio
import aiohttp
import json
try:
    from langchain_core.prompts import PromptTemplate
except ImportError:
    try:
        from langchain_core.prompts import PromptTemplate
    except ImportError:
        from langchain.prompts import PromptTemplate

from langchain_core.output_parsers import JsonOutputParser
from config import LOCAL_LLM
from routers_and_graders import create_chat_model


class EntityExtractor:
    """å®ä½“æå–å™¨ - ä½¿ç”¨LLMä»æ–‡æœ¬ä¸­æå–å®ä½“ï¼ˆæ”¯æŒå¼‚æ­¥æ‰¹å¤„ç†ï¼‰"""
    
    def __init__(self, timeout: int = 180, max_retries: int = 3, enable_async: bool = True):
        """åˆå§‹åŒ–å®ä½“æå–å™¨
        
        Args:
            timeout: LLMè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- é»˜è®¤180ç§’ä»¥åº”å¯¹é¦–æ¬¡æ¨¡å‹åŠ è½½
            max_retries: å¤±è´¥é‡è¯•æ¬¡æ•°
            enable_async: æ˜¯å¦å¯ç”¨å¼‚æ­¥å¤„ç†ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        """
        self.llm = create_chat_model(format="json", temperature=0.0, timeout=timeout)
        self.max_retries = max_retries
        self.enable_async = enable_async
        self.ollama_url = "http://localhost:11434/api/generate"
        self.timeout = timeout  # ä¿å­˜è¶…æ—¶è®¾ç½®ä¾›å¼‚æ­¥ä½¿ç”¨
        
        # å®ä½“æå–æç¤ºæ¨¡æ¿
        self.entity_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®ä½“è¯†åˆ«ä¸“å®¶ã€‚ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰é‡è¦çš„å®ä½“ã€‚
            
å®ä½“ç±»å‹åŒ…æ‹¬:
- PERSON: äººç‰©ã€ä½œè€…ã€ç ”ç©¶è€…
- ORGANIZATION: ç»„ç»‡ã€æœºæ„ã€å…¬å¸
- CONCEPT: æŠ€æœ¯æ¦‚å¿µã€ç®—æ³•ã€æ–¹æ³•è®º
- TECHNOLOGY: å…·ä½“æŠ€æœ¯ã€å·¥å…·ã€æ¡†æ¶
- PAPER: è®ºæ–‡ã€å‡ºç‰ˆç‰©
- EVENT: äº‹ä»¶ã€ä¼šè®®

æ–‡æœ¬å†…å®¹:
{text}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
    "entities": [
        {{
            "name": "å®ä½“åç§°",
            "type": "å®ä½“ç±»å‹",
            "description": "ç®€çŸ­æè¿°"
        }}
    ]
}}

ä¸è¦åŒ…å«å‰è¨€æˆ–è§£é‡Šï¼Œåªè¿”å›JSONã€‚
""",
            input_variables=["text"]
        )
        
        # å…³ç³»æå–æç¤ºæ¨¡æ¿
        self.relation_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªå…³ç³»æŠ½å–ä¸“å®¶ã€‚ä»æ–‡æœ¬ä¸­è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

å·²è¯†åˆ«çš„å®ä½“:
{entities}

æ–‡æœ¬å†…å®¹:
{text}

è¯·è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä»¥JSONæ ¼å¼è¿”å›:
{{
    "relations": [
        {{
            "source": "æºå®ä½“åç§°",
            "target": "ç›®æ ‡å®ä½“åç§°",
            "relation_type": "å…³ç³»ç±»å‹",
            "description": "å…³ç³»æè¿°"
        }}
    ]
}}

å…³ç³»ç±»å‹åŒ…æ‹¬: AUTHOR_OF, USES, BASED_ON, RELATED_TO, PART_OF, APPLIES_TO, IMPROVES, CITES

ä¸è¦åŒ…å«å‰è¨€æˆ–è§£é‡Šï¼Œåªè¿”å›JSONã€‚
""",
            input_variables=["text", "entities"]
        )
        
        self.entity_chain = self.entity_prompt | self.llm | JsonOutputParser()
        self.relation_chain = self.relation_prompt | self.llm | JsonOutputParser()
    
    def extract_entities(self, text: str) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–å®ä½“ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å®ä½“åˆ—è¡¨
        """
        for attempt in range(self.max_retries):
            try:
                print(f"   ğŸ”„ æå–å®ä½“ (å°è¯• {attempt + 1}/{self.max_retries})...", end="")
                result = self.entity_chain.invoke({"text": text[:2000]})  # é™åˆ¶é•¿åº¦
                entities = result.get("entities", [])
                print(f" âœ… æå–åˆ° {len(entities)} ä¸ªå®ä½“")
                return entities
            except TimeoutError as e:
                print(f" â±ï¸ è¶…æ—¶")
                if attempt < self.max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    print(f"   â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"   âŒ å®ä½“æå–æœ€ç»ˆå¤±è´¥: è¶…æ—¶")
                    return []
            except Exception as e:
                print(f" âŒ é”™è¯¯: {str(e)[:100]}")
                if attempt < self.max_retries - 1:
                    time.sleep(1)
                else:
                    print(f"   âŒ å®ä½“æå–æœ€ç»ˆå¤±è´¥: {e}")
                    return []
        return []
    
    def extract_relations(self, text: str, entities: List[Dict]) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–å®ä½“å…³ç³»ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            entities: å·²è¯†åˆ«çš„å®ä½“åˆ—è¡¨
            
        Returns:
            å…³ç³»åˆ—è¡¨
        """
        if not entities:
            print("   âš ï¸ æ— å®ä½“ï¼Œè·³è¿‡å…³ç³»æå–")
            return []
        
        for attempt in range(self.max_retries):
            try:
                print(f"   ğŸ”„ æå–å…³ç³» (å°è¯• {attempt + 1}/{self.max_retries})...", end="")
                entity_names = [e["name"] for e in entities]
                result = self.relation_chain.invoke({
                    "text": text[:2000],
                    "entities": ", ".join(entity_names)
                })
                relations = result.get("relations", [])
                print(f" âœ… æå–åˆ° {len(relations)} ä¸ªå…³ç³»")
                return relations
            except TimeoutError as e:
                print(f" â±ï¸ è¶…æ—¶")
                if attempt < self.max_retries - 1:
                    wait_time = (attempt + 1) * 2
                    print(f"   â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"   âŒ å…³ç³»æå–æœ€ç»ˆå¤±è´¥: è¶…æ—¶")
                    return []
            except Exception as e:
                print(f" âŒ é”™è¯¯: {str(e)[:100]}")
                if attempt < self.max_retries - 1:
                    time.sleep(1)
                else:
                    print(f"   âŒ å…³ç³»æå–æœ€ç»ˆå¤±è´¥: {e}")
                    return []
        return []
    
    async def _async_llm_call(self, prompt: str, session: aiohttp.ClientSession, attempt: int = 0) -> Dict:
        """å¼‚æ­¥è°ƒç”¨ Ollama API"""
        try:
            timeout = aiohttp.ClientTimeout(
                total=self.timeout,      # æ€»è¶…æ—¶
                connect=30,               # è¿æ¥è¶…æ—¶ 30 ç§’
                sock_read=self.timeout    # è¯»å–è¶…æ—¶
            )
            
            async with session.post(
                self.ollama_url,
                json={
                    "model": LOCAL_LLM,
                    "prompt": prompt,
                    "format": "json",
                    "stream": False,
                    "options": {"temperature": 0}
                },
                timeout=timeout
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return json.loads(result.get('response', '{}'))
                else:
                    raise Exception(f"APIè¿”å›é”™è¯¯: {response.status}")
        except (asyncio.TimeoutError, aiohttp.ClientError) as e:
            if attempt < self.max_retries - 1:
                wait_time = (attempt + 1) * 3
                await asyncio.sleep(wait_time)
                return await self._async_llm_call(prompt, session, attempt + 1)
            raise Exception(f"è¿æ¥å¤±è´¥: {str(e)}")
        except Exception as e:
            if attempt < self.max_retries - 1:
                await asyncio.sleep(2)
                return await self._async_llm_call(prompt, session, attempt + 1)
            raise
    
    async def _extract_entities_async(self, text: str, doc_index: int, session: aiohttp.ClientSession) -> List[Dict]:
        """å¼‚æ­¥æå–å®ä½“"""
        prompt = self.entity_prompt.format(text=text[:2000])
        
        for attempt in range(self.max_retries):
            try:
                print(f"   [æ–‡æ¡£ #{doc_index + 1}] ğŸ”„ æå–å®ä½“ (å°è¯• {attempt + 1}/{self.max_retries})...", end="")
                result = await self._async_llm_call(prompt, session, attempt)
                entities = result.get("entities", [])
                print(f" âœ… {len(entities)} ä¸ªå®ä½“")
                return entities
            except Exception as e:
                print(f" âŒ {str(e)[:50]}")
                if attempt == self.max_retries - 1:
                    return []
        return []
    
    async def _extract_relations_async(self, text: str, entities: List[Dict], doc_index: int, session: aiohttp.ClientSession) -> List[Dict]:
        """å¼‚æ­¥æå–å…³ç³»"""
        if not entities:
            return []
        
        entity_names = [e["name"] for e in entities]
        prompt = self.relation_prompt.format(
            text=text[:2000],
            entities=", ".join(entity_names)
        )
        
        for attempt in range(self.max_retries):
            try:
                print(f"   [æ–‡æ¡£ #{doc_index + 1}] ğŸ”„ æå–å…³ç³» (å°è¯• {attempt + 1}/{self.max_retries})...", end="")
                result = await self._async_llm_call(prompt, session, attempt)
                relations = result.get("relations", [])
                print(f" âœ… {len(relations)} ä¸ªå…³ç³»")
                return relations
            except Exception as e:
                print(f" âŒ {str(e)[:50]}")
                if attempt == self.max_retries - 1:
                    return []
        return []
    
    async def _extract_from_document_async(self, document_text: str, doc_index: int, session: aiohttp.ClientSession) -> Dict:
        """å¼‚æ­¥å¤„ç†å•ä¸ªæ–‡æ¡£"""
        print(f"\nğŸ” [æ–‡æ¡£ #{doc_index + 1}] å¼€å§‹å¼‚æ­¥æå–...")
        
        # å¹¶å‘æå–å®ä½“å’Œå…³ç³»ï¼ˆå…ˆå®ä½“ï¼Œå†å…³ç³»ï¼‰
        entities = await self._extract_entities_async(document_text, doc_index, session)
        relations = await self._extract_relations_async(document_text, entities, doc_index, session)
        
        print(f"ğŸ“Š [æ–‡æ¡£ #{doc_index + 1}] å®Œæˆ: {len(entities)} å®ä½“, {len(relations)} å…³ç³»")
        
        return {
            "entities": entities,
            "relations": relations
        }
    
    async def extract_batch_async(self, documents: List[Tuple[str, int]]) -> List[Dict]:
        """å¼‚æ­¥æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (document_text, doc_index) å…ƒç»„
            
        Returns:
            æå–ç»“æœåˆ—è¡¨
        """
        async with aiohttp.ClientSession() as session:
            tasks = [
                self._extract_from_document_async(doc_text, doc_idx, session)
                for doc_text, doc_idx in documents
            ]
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    print(f"âš ï¸ æ–‡æ¡£ #{documents[i][1] + 1} å¤„ç†å¤±è´¥: {result}")
                    processed_results.append({"entities": [], "relations": []})
                else:
                    processed_results.append(result)
            
            return processed_results
    
    def extract_from_document(self, document_text: str, doc_index: int = 0) -> Dict:
        """
        ä»å•ä¸ªæ–‡æ¡£ä¸­æå–å®ä½“å’Œå…³ç³»ï¼ˆåŒæ­¥æ¥å£ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        
        Args:
            document_text: æ–‡æ¡£æ–‡æœ¬
            doc_index: æ–‡æ¡£ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            åŒ…å«å®ä½“å’Œå…³ç³»çš„å­—å…¸
        """
        # åŒæ­¥æ–¹å¼è°ƒç”¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        print(f"\nğŸ” æ–‡æ¡£ #{doc_index + 1}: å¼€å§‹æå–...")
        
        entities = self.extract_entities(document_text)
        relations = self.extract_relations(document_text, entities)
        
        print(f"ğŸ“Š æ–‡æ¡£ #{doc_index + 1} å®Œæˆ: {len(entities)} å®ä½“, {len(relations)} å…³ç³»")
        
        return {
            "entities": entities,
            "relations": relations
        }


class EntityDeduplicator:
    """å®ä½“å»é‡å’Œåˆå¹¶"""
    
    def __init__(self):
        self.llm = create_chat_model(format="json", temperature=0.0)
        
        self.merge_prompt = PromptTemplate(
            template="""åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªå®ä½“æ˜¯å¦æŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡:

å®ä½“1: {entity1_name} - {entity1_desc}
å®ä½“2: {entity2_name} - {entity2_desc}

å¦‚æœæ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œè¿”å›:
{{
    "is_same": true,
    "canonical_name": "æ ‡å‡†åç§°",
    "reason": "åŸå› "
}}

å¦‚æœä¸æ˜¯ï¼Œè¿”å›:
{{
    "is_same": false,
    "reason": "åŸå› "
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
""",
            input_variables=["entity1_name", "entity1_desc", "entity2_name", "entity2_desc"]
        )
        
        self.merge_chain = self.merge_prompt | self.llm | JsonOutputParser()
    
    def _is_same_entity(self, entity1: Dict, entity2: Dict) -> bool:
        """
        ä½¿ç”¨LLMåˆ¤æ–­ä¸¤ä¸ªå®ä½“æ˜¯å¦æŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡
        
        Args:
            entity1: å®ä½“1å­—å…¸
            entity2: å®ä½“2å­—å…¸
            
        Returns:
            bool: æ˜¯å¦ç›¸åŒ
        """
        try:
            # å‡†å¤‡è¾“å…¥
            input_data = {
                "entity1_name": entity1["name"],
                "entity1_desc": entity1.get("description", "æ— æè¿°"),
                "entity2_name": entity2["name"],
                "entity2_desc": entity2.get("description", "æ— æè¿°")
            }
            
            # è°ƒç”¨LLM
            result = self.merge_chain.invoke(input_data)
            
            # è§£æç»“æœ
            return result.get("is_same", False)
        except Exception as e:
            print(f"   âš ï¸ LLMåˆ¤é‡å¤±è´¥ ({entity1['name']} vs {entity2['name']}): {e}")
            return False

    def deduplicate_entities(self, entities: List[Dict]) -> Dict:
        """
        å»é‡å®ä½“åˆ—è¡¨
        
        Args:
            entities: å®ä½“åˆ—è¡¨
            
        Returns:
            åŒ…å«entitieså’Œmappingçš„å­—å…¸
        """
        if len(entities) <= 1:
            # è¿”å›å­—å…¸æ ¼å¼ï¼Œä¿æŒä¸€è‡´æ€§
            entity_mapping = {entity["name"]: entity["name"] for entity in entities} if entities else {}
            return {
                "entities": entities,
                "mapping": entity_mapping
            }
        
        print(f"ğŸ”„ å¼€å§‹å»é‡ {len(entities)} ä¸ªå®ä½“...")
        
        # åŸºäºåç§°å’ŒLLMçš„æ™ºèƒ½å»é‡
        unique_entities = {}
        entity_mapping = {}  # æ˜ å°„åˆ«ååˆ°æ ‡å‡†åç§°
        
        for entity in entities:
            name = entity["name"].lower().strip()
            
            # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸ä¼¼å®ä½“
            merged = False
            for canonical_name, canonical_entity in unique_entities.items():
                # 1. ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼ˆä½œä¸ºé¢„ç­›é€‰ï¼‰
                # å¦‚æœåç§°å®Œå…¨ç›¸åŒï¼Œæˆ–è€…æ˜¯å­ä¸²å…³ç³»ï¼Œåˆ™è€ƒè™‘åˆå¹¶
                is_substring = name in canonical_name or canonical_name in name
                
                if name == canonical_name:
                    # å®Œå…¨åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰ï¼Œç›´æ¥åˆå¹¶
                    entity_mapping[entity["name"]] = canonical_entity["name"]
                    merged = True
                    break
                elif is_substring:
                    # å­ä¸²åŒ¹é…ï¼Œä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½ç¡®è®¤
                    # ä¾‹å¦‚ï¼š"Python" å’Œ "Python Programming Language" -> åˆå¹¶
                    # "Java" å’Œ "JavaScript" -> ä¸åˆå¹¶
                    if self._is_same_entity(entity, canonical_entity):
                        print(f"   âœ¨ åˆå¹¶: {entity['name']} -> {canonical_entity['name']}")
                        entity_mapping[entity["name"]] = canonical_entity["name"]
                        merged = True
                        break
            
            if not merged:
                unique_entities[name] = entity
                entity_mapping[entity["name"]] = entity["name"]
                
        print(f"âœ… å»é‡å®Œæˆï¼Œå‰©ä½™ {len(unique_entities)} ä¸ªå”¯ä¸€å®ä½“")
        
        return {
            "entities": list(unique_entities.values()),
            "mapping": entity_mapping
        }


def initialize_entity_extractor():
    """åˆå§‹åŒ–å®ä½“æå–å™¨"""
    return EntityExtractor()
