"""
å®ä½“å’Œå…³ç³»æå–æ¨¡å—
ä½¿ç”¨LLMä»æ–‡æ¡£ä¸­æå–å®ä½“ã€å…³ç³»å’Œå±æ€§ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±çš„åŸºç¡€
"""

from typing import List, Dict, Tuple
from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatOllama
from langchain_core.output_parsers import JsonOutputParser
from config import LOCAL_LLM


class EntityExtractor:
    """å®ä½“æå–å™¨ - ä½¿ç”¨LLMä»æ–‡æœ¬ä¸­æå–å®ä½“"""
    
    def __init__(self):
        self.llm = ChatOllama(model=LOCAL_LLM, format="json", temperature=0)
        
        # å®ä½“æå–æç¤ºæ¨¡æ¿
        self.entity_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®ä½“è¯†åˆ«ä¸“å®¶ã€‚ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰é‡è¦çš„å®ä½“ã€‚
            
å®ä½“ç±»å‹åŒ…æ‹¬:
- PERSON: äººç‰©ã€ä½œè€…ã€ç ”ç©¶è€…
- ORGANIZATION: ç»„ç»‡ã€æœºæ„ã€å…¬å¸
- CONCEPT: æŠ€æœ¯æ¦‚å¿µã€ç®—æ³•ã€æ–¹æ³•è®º
- TECHNOLOGY: å…·ä½“æŠ€æœ¯ã€å·¥å…·ã€æ¡†æ¶
- PAPER: è®ºæ–‡ã€å‡ºç‰ˆç‰©
- EVENT: äº‹ä»¶ã€ä¼šè®®

æ–‡æœ¬å†…å®¹:
{text}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
    "entities": [
        {{
            "name": "å®ä½“åç§°",
            "type": "å®ä½“ç±»å‹",
            "description": "ç®€çŸ­æè¿°"
        }}
    ]
}}

ä¸è¦åŒ…å«å‰è¨€æˆ–è§£é‡Šï¼Œåªè¿”å›JSONã€‚
""",
            input_variables=["text"]
        )
        
        # å…³ç³»æå–æç¤ºæ¨¡æ¿
        self.relation_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªå…³ç³»æŠ½å–ä¸“å®¶ã€‚ä»æ–‡æœ¬ä¸­è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚

å·²è¯†åˆ«çš„å®ä½“:
{entities}

æ–‡æœ¬å†…å®¹:
{text}

è¯·è¯†åˆ«å®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä»¥JSONæ ¼å¼è¿”å›:
{{
    "relations": [
        {{
            "source": "æºå®ä½“åç§°",
            "target": "ç›®æ ‡å®ä½“åç§°",
            "relation_type": "å…³ç³»ç±»å‹",
            "description": "å…³ç³»æè¿°"
        }}
    ]
}}

å…³ç³»ç±»å‹åŒ…æ‹¬: AUTHOR_OF, USES, BASED_ON, RELATED_TO, PART_OF, APPLIES_TO, IMPROVES, CITES

ä¸è¦åŒ…å«å‰è¨€æˆ–è§£é‡Šï¼Œåªè¿”å›JSONã€‚
""",
            input_variables=["text", "entities"]
        )
        
        self.entity_chain = self.entity_prompt | self.llm | JsonOutputParser()
        self.relation_chain = self.relation_prompt | self.llm | JsonOutputParser()
    
    def extract_entities(self, text: str) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–å®ä½“
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å®ä½“åˆ—è¡¨
        """
        try:
            result = self.entity_chain.invoke({"text": text[:2000]})  # é™åˆ¶é•¿åº¦
            entities = result.get("entities", [])
            print(f"âœ… æå–åˆ° {len(entities)} ä¸ªå®ä½“")
            return entities
        except Exception as e:
            print(f"âŒ å®ä½“æå–å¤±è´¥: {e}")
            return []
    
    def extract_relations(self, text: str, entities: List[Dict]) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–å®ä½“å…³ç³»
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            entities: å·²è¯†åˆ«çš„å®ä½“åˆ—è¡¨
            
        Returns:
            å…³ç³»åˆ—è¡¨
        """
        try:
            entity_names = [e["name"] for e in entities]
            result = self.relation_chain.invoke({
                "text": text[:2000],
                "entities": ", ".join(entity_names)
            })
            relations = result.get("relations", [])
            print(f"âœ… æå–åˆ° {len(relations)} ä¸ªå…³ç³»")
            return relations
        except Exception as e:
            print(f"âŒ å…³ç³»æå–å¤±è´¥: {e}")
            return []
    
    def extract_from_document(self, document_text: str) -> Dict:
        """
        ä»å•ä¸ªæ–‡æ¡£ä¸­æå–å®ä½“å’Œå…³ç³»
        
        Args:
            document_text: æ–‡æ¡£æ–‡æœ¬
            
        Returns:
            åŒ…å«å®ä½“å’Œå…³ç³»çš„å­—å…¸
        """
        print("ğŸ” å¼€å§‹æå–å®ä½“...")
        entities = self.extract_entities(document_text)
        
        print("ğŸ” å¼€å§‹æå–å…³ç³»...")
        relations = self.extract_relations(document_text, entities)
        
        return {
            "entities": entities,
            "relations": relations
        }


class EntityDeduplicator:
    """å®ä½“å»é‡å’Œåˆå¹¶"""
    
    def __init__(self):
        self.llm = ChatOllama(model=LOCAL_LLM, format="json", temperature=0)
        
        self.merge_prompt = PromptTemplate(
            template="""åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªå®ä½“æ˜¯å¦æŒ‡å‘åŒä¸€ä¸ªå¯¹è±¡:

å®ä½“1: {entity1_name} - {entity1_desc}
å®ä½“2: {entity2_name} - {entity2_desc}

å¦‚æœæ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œè¿”å›:
{{
    "is_same": true,
    "canonical_name": "æ ‡å‡†åç§°",
    "reason": "åŸå› "
}}

å¦‚æœä¸æ˜¯ï¼Œè¿”å›:
{{
    "is_same": false,
    "reason": "åŸå› "
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
""",
            input_variables=["entity1_name", "entity1_desc", "entity2_name", "entity2_desc"]
        )
        
        self.merge_chain = self.merge_prompt | self.llm | JsonOutputParser()
    
    def deduplicate_entities(self, entities: List[Dict]) -> Dict:
        """
        å»é‡å®ä½“åˆ—è¡¨
        
        Args:
            entities: å®ä½“åˆ—è¡¨
            
        Returns:
            åŒ…å«entitieså’Œmappingçš„å­—å…¸
        """
        if len(entities) <= 1:
            # è¿”å›å­—å…¸æ ¼å¼ï¼Œä¿æŒä¸€è‡´æ€§
            entity_mapping = {entity["name"]: entity["name"] for entity in entities} if entities else {}
            return {
                "entities": entities,
                "mapping": entity_mapping
            }
        
        print(f"ğŸ”„ å¼€å§‹å»é‡ {len(entities)} ä¸ªå®ä½“...")
        
        # ç®€å•çš„åŸºäºåç§°çš„å»é‡
        unique_entities = {}
        entity_mapping = {}  # æ˜ å°„åˆ«ååˆ°æ ‡å‡†åç§°
        
        for entity in entities:
            name = entity["name"].lower().strip()
            
            # æŸ¥æ‰¾æ˜¯å¦æœ‰ç›¸ä¼¼å®ä½“
            merged = False
            for canonical_name, canonical_entity in unique_entities.items():
                # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…ï¼ˆå¯ä»¥ç”¨LLMåšæ›´æ™ºèƒ½çš„åˆ¤æ–­ï¼‰
                if name in canonical_name or canonical_name in name:
                    entity_mapping[entity["name"]] = canonical_name
                    merged = True
                    break
            
            if not merged:
                unique_entities[name] = entity
                entity_mapping[entity["name"]] = name
        
        print(f"âœ… å»é‡å®Œæˆï¼Œå‰©ä½™ {len(unique_entities)} ä¸ªå”¯ä¸€å®ä½“")
        
        return {
            "entities": list(unique_entities.values()),
            "mapping": entity_mapping
        }


def initialize_entity_extractor():
    """åˆå§‹åŒ–å®ä½“æå–å™¨"""
    return EntityExtractor()
