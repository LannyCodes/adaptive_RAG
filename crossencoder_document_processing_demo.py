"""
CrossEncoder æ–‡æ¡£å¤„ç†è¯¦è§£
è§£ç­”ï¼šDocument æ˜¯ä½œä¸ºæ•´ä½“è¿˜æ˜¯æ‹†åˆ†æˆ sentencesï¼Ÿ
"""

print("=" * 80)
print("CrossEncoder å¦‚ä½•å¤„ç† Documentï¼Ÿ")
print("=" * 80)

# ============================================================================
# Part 1: Document çš„å®é™…å¤„ç†æ–¹å¼
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“ Part 1: Document çš„å®é™…å¤„ç†æ–¹å¼")
print("=" * 80)

query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
document = """äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚å®ƒè‡´åŠ›äºåˆ›å»ºæ™ºèƒ½ç³»ç»Ÿã€‚
è¿™äº›ç³»ç»Ÿå¯ä»¥æ‰§è¡Œéœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡ã€‚äººå·¥æ™ºèƒ½åŒ…æ‹¬æœºå™¨å­¦ä¹ ç­‰å­é¢†åŸŸã€‚"""

print(f"\nåŸå§‹è¾“å…¥ï¼š")
print(f"Query: {query}")
print(f"\nDocument (åŒ…å«å¤šä¸ªå¥å­):")
print(f"{document}")

print("\n" + "-" * 80)
print("å…³é”®é—®é¢˜ï¼šDocument æœ‰å¤šä¸ªå¥å­ï¼ŒCrossEncoder å¦‚ä½•å¤„ç†ï¼Ÿ")
print("-" * 80)

print("""
ç­”æ¡ˆï¼šCrossEncoder æŠŠæ•´ä¸ª Document ä½œä¸ºä¸€ä¸ªæ•´ä½“å¤„ç†ï¼

å…·ä½“è¿‡ç¨‹ï¼š
1. è¾“å…¥æ‹¼æ¥ï¼š[CLS] Query [SEP] Document [SEP]
   â””â”€ Document çš„æ‰€æœ‰å¥å­éƒ½æ‹¼æ¥åœ¨ä¸€èµ·
   
2. åˆ†è¯ï¼šæ•´ä¸ªåºåˆ—è¢«åˆ‡åˆ†æˆ tokens
   â””â”€ ä¸æ˜¯æŒ‰å¥å­åˆ†ï¼Œè€Œæ˜¯æ•´ä¸ª Document ä¸€èµ·åˆ†è¯
   
3. ç”Ÿæˆ embeddingsï¼š
   â””â”€ æ¯ä¸ª token ä¸€ä¸ªå‘é‡ï¼ˆä¸æ˜¯æ¯ä¸ªå¥å­ä¸€ä¸ªå‘é‡ï¼ï¼‰
   â””â”€ Document å¯èƒ½æœ‰ 100 ä¸ª tokens = 100 ä¸ªå‘é‡
""")


# ============================================================================
# Part 2: è¯¦ç»†çš„ Token çº§åˆ«å¤„ç†
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ”¤ Part 2: Token çº§åˆ«çš„å¤„ç†ï¼ˆå®é™…å‘ç”Ÿçš„äº‹æƒ…ï¼‰")
print("=" * 80)

# æ¨¡æ‹ŸçœŸå®çš„å¤„ç†è¿‡ç¨‹
concatenated = f"[CLS] {query} [SEP] {document} [SEP]"

print(f"\næ­¥éª¤1ï¼šæ‹¼æ¥æˆå•ä¸€åºåˆ—")
print(f"{'â”€' * 40}")
print(f"{concatenated[:100]}...")

# ç®€åŒ–çš„åˆ†è¯ï¼ˆå®é™… BERT tokenizer ä¼šç”¨ WordPieceï¼‰
def tokenize_chinese(text):
    """ç®€åŒ–çš„ä¸­æ–‡åˆ†è¯"""
    tokens = []
    i = 0
    while i < len(text):
        if text[i:i+5] == '[CLS]':
            tokens.append('[CLS]')
            i += 5
        elif text[i:i+5] == '[SEP]':
            tokens.append('[SEP]')
            i += 5
        elif text[i] == ' ':
            i += 1
            continue
        else:
            tokens.append(text[i])
            i += 1
    return tokens

tokens = tokenize_chinese(concatenated)

print(f"\næ­¥éª¤2ï¼šåˆ†è¯ï¼ˆæ¯ä¸ªå­—/è¯å˜æˆ tokenï¼‰")
print(f"{'â”€' * 40}")
print(f"æ€»å…± {len(tokens)} ä¸ª tokens")
print(f"å‰ 30 ä¸ª tokens: {tokens[:30]}")

print(f"\næ­¥éª¤3ï¼šæ¯ä¸ª token ç”Ÿæˆä¸€ä¸ªå‘é‡")
print(f"{'â”€' * 40}")
print(f"""
Token åºåˆ— (é•¿åº¦={len(tokens)}):
  tokens[0]  = '[CLS]'  â†’ embedding[0]  (768ç»´å‘é‡)
  tokens[1]  = 'ä»€'     â†’ embedding[1]  (768ç»´å‘é‡)
  tokens[2]  = 'ä¹ˆ'     â†’ embedding[2]  (768ç»´å‘é‡)
  ...
  tokens[10] = '[SEP]'  â†’ embedding[10] (768ç»´å‘é‡)
  tokens[11] = 'äºº'     â†’ embedding[11] (768ç»´å‘é‡) â† Document å¼€å§‹
  tokens[12] = 'å·¥'     â†’ embedding[12] (768ç»´å‘é‡)
  tokens[13] = 'æ™º'     â†’ embedding[13] (768ç»´å‘é‡)
  tokens[14] = 'èƒ½'     â†’ embedding[14] (768ç»´å‘é‡)
  ...
  tokens[{len(tokens)-1}] = '[SEP]'  â†’ embedding[{len(tokens)-1}] (768ç»´å‘é‡)

å…³é”®ç‚¹ï¼š
âœ… Document ä¸æ˜¯ä¸€ä¸ªå‘é‡ï¼
âœ… Document çš„æ¯ä¸ªå­—/è¯éƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼
âœ… å³ä½¿ Document æœ‰å¤šä¸ªå¥å­ï¼Œä¹Ÿæ˜¯è¿ç»­çš„ token åºåˆ—
""")


# ============================================================================
# Part 3: æ³¨æ„åŠ›å¦‚ä½•è·¨å¥å­å·¥ä½œ
# ============================================================================
print("\n" + "=" * 80)
print("ğŸŒŸ Part 3: æ³¨æ„åŠ›æœºåˆ¶è·¨å¥å­å·¥ä½œ")
print("=" * 80)

print("""
Document æœ‰å¤šä¸ªå¥å­æ—¶çš„æ³¨æ„åŠ›è®¡ç®—ï¼š

å‡è®¾ Document = "å¥å­1ã€‚å¥å­2ã€‚å¥å­3ã€‚"

Tokenåºåˆ—ï¼š
  [CLS] Queryè¯1 Queryè¯2 [SEP] å¥å­1è¯1 å¥å­1è¯2 ã€‚ å¥å­2è¯1 å¥å­2è¯2 ã€‚ å¥å­3è¯1 [SEP]
   â†‘      â†‘        â†‘        â†‘      â†‘        â†‘      â†‘    â†‘        â†‘      â†‘    â†‘         â†‘
  t[0]   t[1]    t[2]     t[3]   t[4]     t[5]   t[6] t[7]     t[8]   t[9] t[10]     t[11]

Self-Attention è®¡ç®—ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Queryè¯1 (t[1]) çš„æ³¨æ„åŠ›ï¼š
  - å¯ä»¥å…³æ³¨ å¥å­1è¯1 (t[4])  âœ“
  - å¯ä»¥å…³æ³¨ å¥å­2è¯1 (t[7])  âœ“
  - å¯ä»¥å…³æ³¨ å¥å­3è¯1 (t[10]) âœ“
  â†’ Query çš„è¯å¯ä»¥çœ‹åˆ° Document æ‰€æœ‰å¥å­çš„æ‰€æœ‰è¯ï¼

å¥å­1è¯1 (t[4]) çš„æ³¨æ„åŠ›ï¼š
  - å¯ä»¥å…³æ³¨ Queryè¯1 (t[1])   âœ“
  - å¯ä»¥å…³æ³¨ å¥å­2è¯1 (t[7])   âœ“ (è·¨å¥å­ï¼)
  - å¯ä»¥å…³æ³¨ å¥å­3è¯1 (t[10])  âœ“ (è·¨å¥å­ï¼)
  â†’ Document å†…çš„ä¸åŒå¥å­ä¹Ÿèƒ½äº’ç›¸çœ‹åˆ°ï¼

è¿™å°±æ˜¯"å…¨å±€æ³¨æ„åŠ›"(Global Attention)ï¼š
æ¯ä¸ª token éƒ½èƒ½çœ‹åˆ°æ•´ä¸ªåºåˆ—çš„æ‰€æœ‰ tokenï¼
""")


# ============================================================================
# Part 4: ä¸ºä»€ä¹ˆä¸æ‹†åˆ†æˆå¥å­ï¼Ÿ
# ============================================================================
print("\n" + "=" * 80)
print("â“ Part 4: ä¸ºä»€ä¹ˆä¸æŠŠ Document æ‹†æˆå¤šä¸ªå¥å­ï¼Ÿ")
print("=" * 80)

print("""
æ–¹æ¡ˆAï¼šæŠŠ Document å½“æ•´ä½“ï¼ˆCrossEncoder å®é™…åšæ³•ï¼‰âœ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¾“å…¥ï¼š[CLS] Query [SEP] å¥å­1+å¥å­2+å¥å­3 [SEP]
      â†“
  å•æ¬¡æ¨ç†ï¼Œå¾—åˆ°ä¸€ä¸ªåˆ†æ•°: 8.5
  
ä¼˜ç‚¹ï¼š
  âœ… ä¸€æ¬¡è®¡ç®—ï¼Œé€Ÿåº¦å¿«
  âœ… å¥å­ä¹‹é—´å¯ä»¥äº’ç›¸å…³æ³¨ï¼Œç†è§£ä¸Šä¸‹æ–‡
  âœ… æ•´ä½“è¯­ä¹‰ç†è§£æ›´å¥½
  
ç¼ºç‚¹ï¼š
  âš ï¸  æœ‰é•¿åº¦é™åˆ¶ï¼ˆé€šå¸¸ 512 tokensï¼‰
      å¦‚æœ Document å¤ªé•¿ä¼šè¢«æˆªæ–­


æ–¹æ¡ˆBï¼šæ‹†æˆå¤šä¸ªå¥å­åˆ†åˆ«è®¡ç®—ï¼ˆä¸æ¨èï¼‰âŒ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¾“å…¥1ï¼š[CLS] Query [SEP] å¥å­1 [SEP] â†’ åˆ†æ•°: 7.2
è¾“å…¥2ï¼š[CLS] Query [SEP] å¥å­2 [SEP] â†’ åˆ†æ•°: 8.1  
è¾“å…¥3ï¼š[CLS] Query [SEP] å¥å­3 [SEP] â†’ åˆ†æ•°: 6.5

ç„¶åå–å¹³å‡æˆ–æœ€å¤§å€¼ï¼Ÿ

ç¼ºç‚¹ï¼š
  âŒ éœ€è¦è®¡ç®— 3 æ¬¡ï¼Œé€Ÿåº¦æ…¢ 3 å€
  âŒ å¥å­ä¹‹é—´æ— æ³•äº’ç›¸ç†è§£
  âŒ ä¸¢å¤±äº†ä¸Šä¸‹æ–‡ä¿¡æ¯
  âŒ å¦‚ä½•èšåˆåˆ†æ•°ï¼Ÿå¹³å‡ï¼Ÿæœ€å¤§ï¼Ÿéƒ½ä¸å®Œç¾
""")


# ============================================================================
# Part 5: å®é™…ä»£ç ç¤ºä¾‹
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ’» Part 5: å®é™…ä»£ç ç¤ºä¾‹")
print("=" * 80)

print("""
ä½¿ç”¨ CrossEncoder çš„çœŸå®ä»£ç ï¼š

```python
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"

# Document æœ‰å¤šä¸ªå¥å­
document = \"\"\"
äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚
å®ƒè‡´åŠ›äºåˆ›å»ºæ™ºèƒ½ç³»ç»Ÿã€‚
è¿™äº›ç³»ç»Ÿå¯ä»¥æ‰§è¡Œéœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡ã€‚
\"\"\"

# ç›´æ¥ä¼ å…¥æ•´ä¸ª Documentï¼
pairs = [[query, document]]  # â† æ³¨æ„ï¼šæ•´ä¸ª document ä½œä¸ºä¸€ä¸ªå­—ç¬¦ä¸²

# æ¨¡å‹å†…éƒ¨ä¼šè‡ªåŠ¨ï¼š
# 1. æ‹¼æ¥ï¼š[CLS] query [SEP] document [SEP]
# 2. åˆ†è¯ï¼šåˆ‡åˆ†æˆ tokensï¼ˆå¯èƒ½æœ‰ 50-100 ä¸ªï¼‰
# 3. ç¼–ç ï¼šæ¯ä¸ª token ä¸€ä¸ªå‘é‡
# 4. æ³¨æ„åŠ›ï¼šæ‰€æœ‰ tokens äº’ç›¸å…³æ³¨
# 5. è¾“å‡ºï¼šä¸€ä¸ªåˆ†æ•°

scores = model.predict(pairs)
print(f"ç›¸å…³æ€§åˆ†æ•°: {scores[0]}")  # è¾“å‡º: 8.26
```

å…³é”®ç†è§£ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Document ä¸ä¼šè¢«æ‹†åˆ†ï¼
Document çš„æ¯ä¸ªå­—/è¯éƒ½ä¼šå˜æˆä¸€ä¸ªå‘é‡ï¼
æ‰€æœ‰å‘é‡é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶äº’ç›¸è¿æ¥ï¼
æœ€ç»ˆè¾“å‡ºä¸€ä¸ªæ•´ä½“çš„ç›¸å…³æ€§åˆ†æ•°ï¼
""")


# ============================================================================
# Part 6: Token é™åˆ¶é—®é¢˜
# ============================================================================
print("\n" + "=" * 80)
print("âš ï¸  Part 6: Document å¤ªé•¿æ€ä¹ˆåŠï¼Ÿ")
print("=" * 80)

print("""
CrossEncoder æœ‰é•¿åº¦é™åˆ¶ï¼ˆé€šå¸¸ 512 tokensï¼‰

å¦‚æœ Document å¤ªé•¿ï¼ˆæ¯”å¦‚ 1000 ä¸ªå­—ï¼‰ï¼š

è§£å†³æ–¹æ¡ˆ1ï¼šæˆªæ–­ï¼ˆæœ€å¸¸ç”¨ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  åªä¿ç•™å‰ 512 tokensï¼š
  [CLS] Query [SEP] Documentå‰400ä¸ªå­— [SEP]
  
  ä¼˜ç‚¹ï¼šç®€å•å¿«é€Ÿ
  ç¼ºç‚¹ï¼šå¯èƒ½ä¸¢å¤±é‡è¦ä¿¡æ¯


è§£å†³æ–¹æ¡ˆ2ï¼šæ»‘åŠ¨çª—å£
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  åˆ†æˆå¤šä¸ªçª—å£ï¼Œæ¯ä¸ªçª—å£å•ç‹¬è®¡ç®—ï¼š
  çª—å£1: [CLS] Query [SEP] Document[0:400]   [SEP] â†’ åˆ†æ•°: 7.2
  çª—å£2: [CLS] Query [SEP] Document[200:600] [SEP] â†’ åˆ†æ•°: 8.5
  çª—å£3: [CLS] Query [SEP] Document[400:800] [SEP] â†’ åˆ†æ•°: 6.8
  
  å–æœ€é«˜åˆ†: 8.5
  
  ä¼˜ç‚¹ï¼šä¸ä¼šä¸¢å¤±ä¿¡æ¯
  ç¼ºç‚¹ï¼šè®¡ç®—é‡å¢åŠ 


è§£å†³æ–¹æ¡ˆ3ï¼šå…ˆç”¨ Bi-Encoder ç²—æ’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  1. æŠŠé•¿ Document æ‹†æˆæ®µè½
  2. ç”¨ Bi-Encoder å¿«é€Ÿæ‰¾åˆ°æœ€ç›¸å…³çš„ 1-2 ä¸ªæ®µè½
  3. åªå¯¹è¿™äº›æ®µè½ç”¨ CrossEncoder é‡æ’
  
  ä¼˜ç‚¹ï¼šé€Ÿåº¦å¿«ï¼Œå‡†ç¡®ç‡é«˜
  ç¼ºç‚¹ï¼šä¸¤é˜¶æ®µå¤„ç†


ä½ çš„é¡¹ç›®ä½¿ç”¨çš„æ˜¯æ–¹æ¡ˆ1ï¼ˆæˆªæ–­ï¼‰ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åœ¨ reranker.py ä¸­ï¼š
  CrossEncoderReranker(max_length=512)  â† è¶…è¿‡ 512 ä¼šè‡ªåŠ¨æˆªæ–­
""")


# ============================================================================
# Part 7: å¯è§†åŒ–æ€»ç»“
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š Part 7: å¯è§†åŒ–æ€»ç»“")
print("=" * 80)

print("""
Document å¤„ç†çš„å®Œæ•´æµç¨‹ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

è¾“å…¥ Document (å¤šå¥å­):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚å®ƒè‡´åŠ›äºåˆ›å»ºæ™ºèƒ½ç³»ç»Ÿã€‚" â”‚
â”‚  å¥å­1                              å¥å­2                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                  æ‹¼æ¥æˆå•ä¸€åºåˆ—
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [CLS] ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ [SEP] äººå·¥æ™ºèƒ½æ˜¯...æ™ºèƒ½ç³»ç»Ÿã€‚ [SEP] â”‚
â”‚  ç‰¹æ®Š  Query tokens    åˆ†éš”  Document tokens         ç»“æŸ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                   åˆ†è¯ (Tokenization)
                        â†“
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚[CLS]â”‚ ä»€  â”‚ ä¹ˆ  â”‚[SEP]â”‚ äºº  â”‚ å·¥  â”‚ ...â”‚ ç»Ÿ  â”‚ ã€‚ â”‚[SEP]â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
                        â†“
              æ¯ä¸ª token â†’ ä¸€ä¸ª 768ç»´å‘é‡
                        â†“
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ Vâ‚€  â”‚ Vâ‚  â”‚ Vâ‚‚  â”‚ Vâ‚ƒ  â”‚ Vâ‚„  â”‚ Vâ‚…  â”‚ ... â”‚ Vâ‚™â‚‹â‚‚â”‚ Vâ‚™â‚‹â‚â”‚ Vâ‚™  â”‚
â”‚768ç»´â”‚768ç»´â”‚768ç»´â”‚768ç»´â”‚768ç»´â”‚768ç»´â”‚ ... â”‚768ç»´â”‚768ç»´â”‚768ç»´â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
                        â†“
              Self-Attention (12 å±‚)
              æ¯ä¸ªå‘é‡éƒ½èƒ½"çœ‹åˆ°"æ‰€æœ‰å…¶ä»–å‘é‡
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Vâ‚€' (æ›´æ–°åçš„ [CLS] å‘é‡)                        â”‚
â”‚            åŒ…å«äº†æ•´ä¸ªåºåˆ—çš„ä¿¡æ¯                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
                  å…¨è¿æ¥å±‚ (åˆ†ç±»å¤´)
                        â†“
                   ç›¸å…³æ€§åˆ†æ•°
                      8.26

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å…³é”®ç‚¹æ€»ç»“ï¼š

1. Document æ•´ä½“å¤„ç† âœ“
   â””â”€ ä¸æ˜¯ä¸€ä¸ªå‘é‡ï¼Œæ˜¯å¾ˆå¤šå‘é‡çš„åºåˆ—

2. æ¯ä¸ªå­—/è¯ä¸€ä¸ªå‘é‡ âœ“
   â””â”€ ä¸æ˜¯æ¯ä¸ªå¥å­ä¸€ä¸ªå‘é‡

3. å…¨å±€æ³¨æ„åŠ› âœ“
   â””â”€ Query çš„è¯èƒ½çœ‹åˆ° Document æ‰€æœ‰å¥å­çš„æ‰€æœ‰è¯

4. æœ€ç»ˆä¸€ä¸ªåˆ†æ•° âœ“
   â””â”€ ä» [CLS] å‘é‡æå–å‡ºæ¥
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")


# ============================================================================
# Part 8: å¯¹æ¯” Bi-Encoder çš„å¤„ç†æ–¹å¼
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ”„ Part 8: å¯¹æ¯” Bi-Encoder çš„å¤„ç†æ–¹å¼")
print("=" * 80)

print("""
Bi-Encoder (å‘é‡æ£€ç´¢):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Document: "å¥å­1ã€‚å¥å­2ã€‚å¥å­3ã€‚"
           â†“
     Encoder (BERT)
           â†“
     å– [CLS] å‘é‡
           â†“
   å•ä¸ªå‘é‡ (768ç»´)  â† Document è¢«å‹ç¼©æˆä¸€ä¸ªå‘é‡ï¼
           â†“
   ä¸ Query å‘é‡åšä½™å¼¦ç›¸ä¼¼åº¦
           â†“
     ç›¸å…³æ€§åˆ†æ•°


CrossEncoder (æ·±åº¦é‡æ’):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Query + Document: "[CLS] Query [SEP] å¥å­1ã€‚å¥å­2ã€‚å¥å­3ã€‚ [SEP]"
                              â†“
                        Encoder (BERT)
                              â†“
                   ä¿ç•™æ‰€æœ‰ token çš„å‘é‡
                              â†“
                   å‘é‡åºåˆ— (n Ã— 768)  â† ä¿ç•™äº†æ‰€æœ‰ç»†èŠ‚ï¼
                              â†“
              Self-Attention è®©æ‰€æœ‰è¯äº’ç›¸ç†è§£
                              â†“
                       ç›¸å…³æ€§åˆ†æ•°

åŒºåˆ«ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Bi-Encoder:  Document â†’ 1 ä¸ªå‘é‡ (ä¿¡æ¯å‹ç¼©)
CrossEncoder: Document â†’ n ä¸ªå‘é‡ (ä¿¡æ¯ä¿ç•™)

Bi-Encoder:  Query å’Œ Document åˆ†å¼€å¤„ç†
CrossEncoder: Query å’Œ Document ä¸€èµ·å¤„ç†

Bi-Encoder:  å¿«é€Ÿä½†ä¸å¤Ÿå‡†ç¡®
CrossEncoder: æ…¢ä½†éå¸¸å‡†ç¡®
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")


print("\n" + "=" * 80)
print("âœ… æ€»ç»“ç­”æ¡ˆ")
print("=" * 80)
print("""
ä½ çš„é—®é¢˜ï¼šDocument æ˜¯åšæˆä¸€ä¸ª embeddingï¼Œè¿˜æ˜¯æ¯ä¸ª sentence åšæˆä¸€å †å‘é‡ï¼Ÿ

ç­”æ¡ˆï¼šéƒ½ä¸æ˜¯ï¼ ğŸ˜Š

æ­£ç¡®ç†è§£ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Document æ•´ä½“ä½œä¸ºè¾“å…¥ï¼ˆä¸æ‹†åˆ†å¥å­ï¼‰
âœ… ä½† Document çš„æ¯ä¸ªå­—/è¯éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå‘é‡
âœ… ä¸æ˜¯"ä¸€ä¸ª embedding"ï¼Œè€Œæ˜¯"ä¸€ä¸ªå‘é‡åºåˆ—"
âœ… ä¸æ˜¯"æŒ‰å¥å­åˆ†"ï¼Œè€Œæ˜¯"æŒ‰å­—/è¯åˆ†"

Document (50ä¸ªå­—) â†’ 50 ä¸ªå‘é‡ (æ¯ä¸ª 768 ç»´)
                    ä¸æ˜¯ 1 ä¸ªå‘é‡
                    ä¹Ÿä¸æ˜¯ 3 ä¸ªå‘é‡(å¦‚æœæœ‰3ä¸ªå¥å­)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ CrossEncoder èƒ½ç†è§£ç»†ç²’åº¦çš„è¯­ä¹‰å…³ç³»ï¼
""")

print("\nğŸ’¡ ç°åœ¨ä½ ç†è§£äº†å—ï¼Ÿå¦‚æœ‰ç–‘é—®ï¼Œè¯·ç»§ç»­æé—®ï¼\n")
