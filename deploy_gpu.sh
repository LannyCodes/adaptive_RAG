#!/bin/bash
# GPUéƒ¨ç½²è„šæœ¬ - ä¸€é”®éƒ¨ç½²è‡ªé€‚åº”RAGç³»ç»Ÿåˆ°Linux RTX 4090ç¯å¢ƒ

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ å¼€å§‹éƒ¨ç½²è‡ªé€‚åº”RAGç³»ç»Ÿåˆ°GPUç¯å¢ƒ..."

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# æ£€æŸ¥æ˜¯å¦ä¸ºrootç”¨æˆ·
if [[ $EUID -eq 0 ]]; then
   echo -e "${RED}è¯·ä¸è¦ä½¿ç”¨rootç”¨æˆ·è¿è¡Œæ­¤è„šæœ¬${NC}"
   exit 1
fi

# æ£€æŸ¥GPU
check_gpu() {
    echo "ğŸ” æ£€æŸ¥GPUç¯å¢ƒ..."
    if command -v nvidia-smi &> /dev/null; then
        echo -e "${GREEN}âœ… å‘ç°NVIDIA GPU:${NC}"
        nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
    else
        echo -e "${RED}âŒ æœªå‘ç°NVIDIA GPUæˆ–é©±åŠ¨æœªå®‰è£…${NC}"
        exit 1
    fi
}

# æ£€æŸ¥CUDA
check_cuda() {
    echo "ğŸ” æ£€æŸ¥CUDAç¯å¢ƒ..."
    if command -v nvcc &> /dev/null; then
        echo -e "${GREEN}âœ… CUDAç‰ˆæœ¬:${NC}"
        nvcc --version | grep "release"
    else
        echo -e "${YELLOW}âš ï¸ CUDAæœªå®‰è£…æˆ–æœªæ·»åŠ åˆ°PATH${NC}"
    fi
}

# å®‰è£…Docker
install_docker() {
    if ! command -v docker &> /dev/null; then
        echo "ğŸ“¦ å®‰è£…Docker..."
        curl -fsSL https://get.docker.com -o get-docker.sh
        sudo sh get-docker.sh
        sudo usermod -aG docker $USER
        rm get-docker.sh
        echo -e "${GREEN}âœ… Dockerå®‰è£…å®Œæˆ${NC}"
    else
        echo -e "${GREEN}âœ… Dockerå·²å®‰è£…${NC}"
    fi
}

# å®‰è£…NVIDIA Container Toolkit
install_nvidia_docker() {
    if ! docker run --rm --gpus all nvidia/cuda:11.0.3-base-ubuntu20.04 nvidia-smi &> /dev/null; then
        echo "ğŸ³ å®‰è£…NVIDIA Container Toolkit..."
        distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
        curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
        curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
                sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
                sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
        
        sudo apt-get update
        sudo apt-get install -y nvidia-container-toolkit
        sudo systemctl restart docker
        echo -e "${GREEN}âœ… NVIDIA Container Toolkitå®‰è£…å®Œæˆ${NC}"
    else
        echo -e "${GREEN}âœ… NVIDIA Container Toolkitå·²é…ç½®${NC}"
    fi
}

# åˆ›å»ºç¯å¢ƒé…ç½®
setup_env() {
    echo "âš™ï¸ é…ç½®ç¯å¢ƒå˜é‡..."
    if [ ! -f .env ]; then
        cp .env.example .env
        echo -e "${YELLOW}âš ï¸ è¯·ç¼–è¾‘ .env æ–‡ä»¶å¹¶è®¾ç½®æ‚¨çš„APIå¯†é’¥${NC}"
        echo "   - TAVILY_API_KEY: ä» https://tavily.com/ è·å–"
        read -p "æŒ‰å›è½¦é”®ç»§ç»­..."
    fi
}

# é€‰æ‹©éƒ¨ç½²æ–¹å¼
choose_deployment() {
    echo "ğŸ¯ é€‰æ‹©éƒ¨ç½²æ–¹å¼:"
    echo "1) Docker Composeéƒ¨ç½² (æ¨è)"
    echo "2) ç›´æ¥Pythonéƒ¨ç½²"
    read -p "è¯·é€‰æ‹© (1-2): " choice
    
    case $choice in
        1)
            deploy_docker
            ;;
        2)
            deploy_python
            ;;
        *)
            echo -e "${RED}æ— æ•ˆé€‰æ‹©${NC}"
            exit 1
            ;;
    esac
}

# Dockeréƒ¨ç½²
deploy_docker() {
    echo "ğŸ³ ä½¿ç”¨Docker Composeéƒ¨ç½²..."
    
    # å®‰è£…docker-compose
    if ! command -v docker-compose &> /dev/null; then
        echo "å®‰è£…Docker Compose..."
        sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
    fi
    
    # æ„å»ºå¹¶å¯åŠ¨æœåŠ¡
    echo "æ„å»ºé•œåƒ..."
    docker-compose -f docker-compose.gpu.yml build
    
    echo "å¯åŠ¨æœåŠ¡..."
    docker-compose -f docker-compose.gpu.yml up -d
    
    echo -e "${GREEN}âœ… Dockeréƒ¨ç½²å®Œæˆ!${NC}"
    echo "è®¿é—®: http://localhost:8000"
    echo "ç›‘æ§: http://localhost:9445 (GPUç›‘æ§)"
    echo "æ—¥å¿—: docker-compose -f docker-compose.gpu.yml logs -f"
}

# Pythonç›´æ¥éƒ¨ç½²
deploy_python() {
    echo "ğŸ ä½¿ç”¨Pythonç›´æ¥éƒ¨ç½²..."
    
    # æ£€æŸ¥Python
    if ! command -v python3 &> /dev/null; then
        echo "å®‰è£…Python3..."
        sudo apt-get update
        sudo apt-get install -y python3 python3-pip python3-venv
    fi
    
    # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
    if [ ! -d "rag_env" ]; then
        echo "åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ..."
        python3 -m venv rag_env
    fi
    
    # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
    source rag_env/bin/activate
    pip install --upgrade pip
    pip install -r requirements_gpu.txt
    
    # å®‰è£…Ollama
    if ! command -v ollama &> /dev/null; then
        echo "å®‰è£…Ollama..."
        curl -fsSL https://ollama.ai/install.sh | sh
    fi
    
    # å¯åŠ¨OllamaæœåŠ¡
    echo "å¯åŠ¨OllamaæœåŠ¡..."
    ollama serve &
    sleep 5
    
    # ä¸‹è½½æ¨¡å‹
    echo "ä¸‹è½½Mistralæ¨¡å‹..."
    ollama pull mistral
    
    # åˆ›å»ºå¯åŠ¨è„šæœ¬
    cat > start_gpu.sh << 'EOF'
#!/bin/bash
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export TOKENIZERS_PARALLELISM=false
source rag_env/bin/activate
python main.py
EOF
    chmod +x start_gpu.sh
    
    echo -e "${GREEN}âœ… Pythonéƒ¨ç½²å®Œæˆ!${NC}"
    echo "å¯åŠ¨å‘½ä»¤: ./start_gpu.sh"
}

# éªŒè¯éƒ¨ç½²
verify_deployment() {
    echo "ğŸ” éªŒè¯éƒ¨ç½²..."
    sleep 10
    
    if curl -f http://localhost:8000/health 2>/dev/null; then
        echo -e "${GREEN}âœ… æœåŠ¡è¿è¡Œæ­£å¸¸${NC}"
    else
        echo -e "${YELLOW}âš ï¸ æœåŠ¡å¯èƒ½è¿˜åœ¨å¯åŠ¨ä¸­ï¼Œè¯·ç¨åæ£€æŸ¥${NC}"
    fi
    
    # æ˜¾ç¤ºGPUä½¿ç”¨æƒ…å†µ
    echo "ğŸ“Š GPUçŠ¶æ€:"
    nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits
}

# æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
show_info() {
    echo ""
    echo "ğŸ‰ éƒ¨ç½²å®Œæˆ!"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ğŸ“Š æœåŠ¡åœ°å€:"
    echo "   - ä¸»æœåŠ¡: http://localhost:8000"
    echo "   - Ollama: http://localhost:11434"
    echo ""
    echo "ğŸ”§ å¸¸ç”¨å‘½ä»¤:"
    echo "   - æŸ¥çœ‹æ—¥å¿—: docker-compose -f docker-compose.gpu.yml logs -f"
    echo "   - é‡å¯æœåŠ¡: docker-compose -f docker-compose.gpu.yml restart"
    echo "   - åœæ­¢æœåŠ¡: docker-compose -f docker-compose.gpu.yml down"
    echo "   - GPUç›‘æ§: watch -n 1 nvidia-smi"
    echo ""
    echo "ğŸ“š æ–‡æ¡£ä½ç½®:"
    echo "   - éƒ¨ç½²æŒ‡å—: DEPLOYMENT_GUIDE.md"
    echo "   - å¿«é€Ÿå¼€å§‹: QUICKSTART.md"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸ¤– è‡ªé€‚åº”RAGç³»ç»Ÿ GPUéƒ¨ç½²è„šæœ¬"
    echo "é€‚ç”¨äº: Linux + RTX 4090"
    echo ""
    
    check_gpu
    check_cuda
    install_docker
    install_nvidia_docker
    setup_env
    choose_deployment
    verify_deployment
    show_info
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"

reactive