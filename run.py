import subprocess
import time
import os
import sys
import threading

def stream_logs(process, prefix):
    """å®æ—¶è¯»å–å­è¿›ç¨‹çš„æ—¥å¿—å¹¶æ‰“å°åˆ°æ ‡å‡†è¾“å‡º"""
    for line in iter(process.stdout.readline, ''):
        print(f"[{prefix}] {line.strip()}", flush=True)

def main():
    print("ğŸš€ Starting application via Python Runner...", flush=True)

    # 1. è®¾ç½®ç¯å¢ƒå˜é‡
    # ç¡®ä¿ä½¿ç”¨ root ç›®å½• (å› ä¸ºæˆ‘ä»¬ç°åœ¨æ˜¯ç”¨ root è¿è¡Œ)
    os.environ["OLLAMA_MODELS"] = "/root/.ollama/models"
    os.environ["OLLAMA_HOST"] = "127.0.0.1:11434"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("/root/.ollama/models", exist_ok=True)

    # 2. å¯åŠ¨ Ollama
    print("ğŸ”´ Starting Ollama...", flush=True)
    # ä½¿ç”¨ Popen å¯åŠ¨ï¼Œå°† stderr é‡å®šå‘åˆ° stdout ä»¥ä¾¿æ•è·
    ollama_process = subprocess.Popen(
        ["ollama", "serve"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )
    # å¼€å¯çº¿ç¨‹è¯»å– Ollama æ—¥å¿—
    threading.Thread(target=stream_logs, args=(ollama_process, "OLLAMA"), daemon=True).start()

    # ç­‰å¾… Ollama å¯åŠ¨
    print("â³ Waiting for Ollama to initialize...", flush=True)
    time.sleep(5)

    # 3. åå°æ‹‰å–æ¨¡å‹ (ä¸é˜»å¡ä¸»çº¿ç¨‹)
    def pull_model():
        print("â¬‡ï¸  Starting background model pull (qwen2:1.5b)...", flush=True)
        try:
            result = subprocess.run(
                ["ollama", "pull", "qwen2:1.5b"],
                capture_output=True,
                text=True
            )
            if result.returncode == 0:
                print("âœ… Model pulled successfully!", flush=True)
            else:
                print(f"âš ï¸ Model pull failed: {result.stderr}", flush=True)
        except Exception as e:
            print(f"âš ï¸ Exception during model pull: {e}", flush=True)

    threading.Thread(target=pull_model, daemon=True).start()

    # 4. å¯åŠ¨ FastAPI (Uvicorn)
    print("ğŸŸ¢ Starting FastAPI Server...", flush=True)
    uvicorn_process = subprocess.Popen(
        ["uvicorn", "server:app", "--host", "0.0.0.0", "--port", "7860"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )
    # å¼€å¯çº¿ç¨‹è¯»å– Uvicorn æ—¥å¿—
    threading.Thread(target=stream_logs, args=(uvicorn_process, "FASTAPI"), daemon=True).start()

    # 5. ç›‘æ§è¿›ç¨‹
    # åªè¦ä»»ä½•ä¸€ä¸ªå…³é”®è¿›ç¨‹æŒ‚äº†ï¼Œä¸»ç¨‹åºå°±é€€å‡ºï¼ˆä»¥ä¾¿ Docker é‡å¯æˆ–æŠ¥é”™ï¼‰
    while True:
        if ollama_process.poll() is not None:
            print("âŒ Ollama process exited unexpectedly!", flush=True)
            sys.exit(1)
        
        if uvicorn_process.poll() is not None:
            print("âŒ Uvicorn process exited unexpectedly!", flush=True)
            sys.exit(1)
            
        time.sleep(1)

if __name__ == "__main__":
    main()
