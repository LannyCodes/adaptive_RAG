"""
è½»é‡çº§å¼€æºå¹»è§‰æ£€æµ‹å™¨
æ›¿ä»£ Vectara æ¨¡å‹çš„æœ€ä½³æ–¹æ¡ˆ
"""

import os
import re
import torch
from typing import List, Dict, Tuple
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import numpy as np


class LightweightHallucinationDetector:
    """
    è½»é‡çº§å¹»è§‰æ£€æµ‹å™¨
    ä½¿ç”¨å¼€æº NLI æ¨¡å‹ï¼Œæ— éœ€ç‰¹æ®Šæƒé™
    """
    
    def __init__(self, model_name="cross-encoder/nli-MiniLM2-L6-H768"):
        """
        åˆå§‹åŒ–è½»é‡çº§å¹»è§‰æ£€æµ‹å™¨
        
        Args:
            model_name: å¯é€‰çš„å¼€æºæ¨¡å‹
                - "cross-encoder/nli-MiniLM2-L6-H768" (æ¨è: 80MB, 85%å‡†ç¡®ç‡)
                - "cross-encoder/nli-deberta-v3-xsmall" (æ›´å°: 40MB, 82%å‡†ç¡®ç‡)
                - "cross-encoder/nli-roberta-base" (æ›´å‡†: 430MB, 88%å‡†ç¡®ç‡)
        """
        self.model_name = model_name
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"ğŸ”§ åˆå§‹åŒ–è½»é‡çº§å¹»è§‰æ£€æµ‹å™¨...")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   è®¾å¤‡: {self.device}")
        
        try:
            self.nli_model = pipeline(
                "text-classification",
                model=model_name,
                device=self.device,
                truncation=True,
                max_length=512,
                return_all_scores=True
            )
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨å¤‡ç”¨æ¨¡å‹...")
            
            # å¤‡ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰ä»è½»åˆ°é‡æ’åˆ—ï¼‰
            backup_models = [
                "cross-encoder/nli-deberta-v3-xsmall",
                "cross-encoder/nli-roberta-base",
                "facebook/bart-large-mnli"
            ]
            
            self.nli_model = None
            for backup_model in backup_models:
                try:
                    print(f"   å°è¯•å¤‡ç”¨æ¨¡å‹: {backup_model}")
                    self.nli_model = pipeline(
                        "text-classification",
                        model=backup_model,
                        device=self.device,
                        truncation=True,
                        max_length=512,
                        return_all_scores=True
                    )
                    print(f"âœ… å¤‡ç”¨æ¨¡å‹åŠ è½½æˆåŠŸ: {backup_model}")
                    self.model_name = backup_model
                    break
                except Exception as backup_e:
                    print(f"   âŒ å¤‡ç”¨æ¨¡å‹å¤±è´¥: {backup_e}")
                    continue
    
    def _split_text_into_sentences(self, text: str) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å‰²ä¸ºå¥å­"""
        # ç®€å•ä½†æœ‰æ•ˆçš„å¥å­åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\\s*', text)
        return [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]
    
    def _nli_score(self, premise: str, hypothesis: str) -> Dict:
        """è®¡ç®— NLI åˆ†æ•°"""
        if self.nli_model is None:
            return {"label": "NEUTRAL", "score": 0.5}
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥
            input_text = f"{premise} [SEP] {hypothesis}"
            
            # è·å–æ‰€æœ‰åˆ†æ•°
            results = self.nli_model(input_text)[0]
            
            # è§£æç»“æœ
            result_dict = {item['label']: item['score'] for item in results}
            
            return result_dict
        except Exception as e:
            print(f"âŒ NLI æ¨ç†å¤±è´¥: {e}")
            return {"label": "NEUTRAL", "score": 0.5}
    
    def _calculate_hallucination_score(self, nli_results: Dict) -> float:
        """
        æ ¹æ® NLI ç»“æœè®¡ç®—å¹»è§‰åˆ†æ•°
        
        Args:
            nli_results: NLI æ¨¡å‹çš„è¾“å‡ºç»“æœ
            
        Returns:
            float: å¹»è§‰åˆ†æ•° (0-1)
        """
        contradiction = nli_results.get('CONTRADICTION', 0.0)
        neutral = nli_results.get('NEUTRAL', 0.0)
        entailment = nli_results.get('ENTAILMENT', 0.0)
        
        # å¹»è§‰åˆ†æ•°è®¡ç®—å…¬å¼
        # çŸ›ç›¾ -> é«˜å¹»è§‰åˆ†æ•°
        # ä¸­ç«‹ -> ä¸­ç­‰å¹»è§‰åˆ†æ•°  
        # è•´å« -> ä½å¹»è§‰åˆ†æ•°
        
        hallucination_score = contradiction * 0.9 + neutral * 0.5 + entailment * 0.1
        
        return min(1.0, hallucination_score)
    
    def detect(self, generation: str, documents: str, method="sentence_level") -> Dict:
        """
        æ£€æµ‹å¹»è§‰
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£
            method: æ£€æµ‹æ–¹æ³•
                - "sentence_level": å¥å­çº§åˆ«æ£€æµ‹ï¼ˆæ¨èï¼‰
                - "document_level": æ–‡æ¡£çº§åˆ«æ£€æµ‹
                
        Returns:
            Dict: æ£€æµ‹ç»“æœ
        """
        if self.nli_model is None:
            return {
                "has_hallucination": False,
                "hallucination_score": 0.0,
                "factuality_score": 1.0,
                "method": "model_failed",
                "details": "æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¿”å›å®‰å…¨é»˜è®¤å€¼"
            }
        
        if method == "sentence_level":
            return self._detect_sentence_level(generation, documents)
        else:
            return self._detect_document_level(generation, documents)
    
    def _detect_sentence_level(self, generation: str, documents: str) -> Dict:
        """å¥å­çº§åˆ«çš„å¹»è§‰æ£€æµ‹"""
        sentences = self._split_text_into_sentences(generation)
        
        if not sentences:
            return {
                "has_hallucination": False,
                "hallucination_score": 0.0,
                "factuality_score": 1.0,
                "method": "sentence_level",
                "details": "æ²¡æœ‰å¯åˆ†æçš„å¥å­"
            }
        
        # åˆ†ææ¯ä¸ªå¥å­
        sentence_scores = []
        problematic_sentences = []
        
        for sentence in sentences:
            nli_result = self._nli_score(documents, sentence)
            hallucination_score = self._calculate_hallucination_score(nli_result)
            
            sentence_scores.append(hallucination_score)
            
            if hallucination_score > 0.6:  # é˜ˆå€¼
                problematic_sentences.append({
                    "sentence": sentence,
                    "score": hallucination_score,
                    "nli_result": nli_result
                })
        
        # è®¡ç®—æ•´ä½“åˆ†æ•°
        avg_hallucination_score = np.mean(sentence_scores)
        max_hallucination_score = np.max(sentence_scores)
        
        # åˆ¤æ–­æ˜¯å¦æœ‰å¹»è§‰
        has_hallucination = max_hallucination_score > 0.7  # ä¸¥æ ¼é˜ˆå€¼
        
        return {
            "has_hallucination": has_hallucination,
            "hallucination_score": float(max_hallucination_score),
            "factuality_score": float(1.0 - avg_hallucination_score),
            "method": "sentence_level",
            "details": {
                "sentence_count": len(sentences),
                "avg_score": float(avg_hallucination_score),
                "max_score": float(max_hallucination_score),
                "problematic_sentences": problematic_sentences[:3]  # åªè¿”å›å‰3ä¸ªé—®é¢˜å¥å­
            }
        }
    
    def _detect_document_level(self, generation: str, documents: str) -> Dict:
        """æ–‡æ¡£çº§åˆ«çš„å¹»è§‰æ£€æµ‹"""
        nli_result = self._nli_score(documents, generation)
        hallucination_score = self._calculate_hallucination_score(nli_result)
        
        has_hallucination = hallucination_score > 0.5  # æ ‡å‡†é˜ˆå€¼
        
        return {
            "has_hallucination": has_hallucination,
            "hallucination_score": float(hallucination_score),
            "factuality_score": float(1.0 - hallucination_score),
            "method": "document_level",
            "details": {
                "nli_result": nli_result,
                "primary_label": max(nli_result.keys(), key=lambda k: nli_result[k])
            }
        }
    
    def batch_detect(self, generations: List[str], documents: str, method="sentence_level") -> List[Dict]:
        """
        æ‰¹é‡æ£€æµ‹å¹»è§‰
        
        Args:
            generations: å¤šä¸ªç”Ÿæˆå†…å®¹
            documents: å‚è€ƒæ–‡æ¡£
            method: æ£€æµ‹æ–¹æ³•
            
        Returns:
            List[Dict]: æ¯ä¸ªç”Ÿæˆå†…å®¹çš„æ£€æµ‹ç»“æœ
        """
        results = []
        for generation in generations:
            result = self.detect(generation, documents, method)
            results.append(result)
        
        return results


# ==========================================
# ä½¿ç”¨ç¤ºä¾‹
# ==========================================

if __name__ == "__main__":
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = LightweightHallucinationDetector()
    
    # æµ‹è¯•æ•°æ®
    documents = "The capital of France is Paris. It is a beautiful city with many historical landmarks."
    
    test_cases = [
        "The capital of France is Berlin.",  # æ˜æ˜¾é”™è¯¯
        "Paris is the capital of France.",  # æ­£ç¡®
        "Paris is the capital of Germany and has many beautiful landmarks.",  # éƒ¨åˆ†é”™è¯¯
        "The French capital has several famous museums and historical sites."  # æ­£ç¡®ï¼Œä½†è¡¨è¿°ä¸åŒ
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª è½»é‡çº§å¹»è§‰æ£€æµ‹å™¨æµ‹è¯•")
    print("="*60)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. æµ‹è¯•æ¡ˆä¾‹:")
        print(f"   å‰æ: {documents[:50]}...")
        print(f"   å‡è®¾: {test_case}")
        
        # æ£€æµ‹å¹»è§‰
        result = detector.detect(test_case, documents, method="sentence_level")
        
        print(f"   ç»“æœ:")
        print(f"     - æ˜¯å¦æœ‰å¹»è§‰: {result['has_hallucination']}")
        print(f"     - å¹»è§‰åˆ†æ•°: {result['hallucination_score']:.3f}")
        print(f"     - äº‹å®æ€§åˆ†æ•°: {result['factuality_score']:.3f}")
        print(f"     - æ£€æµ‹æ–¹æ³•: {result['method']}")
        
        if result['details'].get('problematic_sentences'):
            print(f"     - é—®é¢˜å¥å­: {len(result['details']['problematic_sentences'])} ä¸ª")
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60)