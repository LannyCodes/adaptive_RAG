"""
æ–‡æ¡£å¤„ç†å’Œå‘é‡åŒ–æ¨¡å—
è´Ÿè´£æ–‡æ¡£åŠ è½½ã€æ–‡æœ¬åˆ†å—ã€å‘é‡åŒ–å’Œå‘é‡æ•°æ®åº“åˆå§‹åŒ–
"""

try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except ImportError:
    try:
        from langchain_text_splitters import RecursiveCharacterTextSplitter
    except ImportError:
        from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever

from config import (
    KNOWLEDGE_BASE_URLS,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    COLLECTION_NAME,
    EMBEDDING_MODEL,
    # æ··åˆæ£€ç´¢é…ç½®
    ENABLE_HYBRID_SEARCH,
    HYBRID_SEARCH_WEIGHTS,
    KEYWORD_SEARCH_K,
    BM25_K1,
    BM25_B,
    # æŸ¥è¯¢æ‰©å±•é…ç½®
    ENABLE_QUERY_EXPANSION,
    QUERY_EXPANSION_MODEL,
    QUERY_EXPANSION_PROMPT,
    MAX_EXPANDED_QUERIES,
    # å¤šæ¨¡æ€é…ç½®
    ENABLE_MULTIMODAL,
    MULTIMODAL_IMAGE_MODEL,
    SUPPORTED_IMAGE_FORMATS,
    IMAGE_EMBEDDING_DIM,
    MULTIMODAL_WEIGHTS
)
from reranker import create_reranker

# å¤šæ¨¡æ€æ”¯æŒç›¸å…³å¯¼å…¥
import base64
import io
from PIL import Image
import numpy as np
from typing import List, Dict, Any, Optional, Union


class CustomEnsembleRetriever:
    """è‡ªå®šä¹‰é›†æˆæ£€ç´¢å™¨ï¼Œç»“åˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢"""
    
    def __init__(self, retrievers, weights):
        self.retrievers = retrievers
        self.weights = weights
        
    def invoke(self, query):
        """æ‰§è¡Œæ£€ç´¢å¹¶åˆå¹¶ç»“æœ"""
        # è·å–å„æ£€ç´¢å™¨çš„ç»“æœ
        all_results = []
        for i, retriever in enumerate(self.retrievers):
            results = retriever.invoke(query)
            for doc in results:
                # æ·»åŠ æ£€ç´¢å™¨ç´¢å¼•å’Œæƒé‡ä¿¡æ¯
                doc.metadata["retriever_index"] = i
                doc.metadata["retriever_weight"] = self.weights[i]
                all_results.append(doc)
        
        # æ ¹æ®æƒé‡æ’åºå¹¶å»é‡
        # ç®€å•å®ç°ï¼šå…ˆæŒ‰æ£€ç´¢å™¨ç´¢å¼•æ’åºï¼Œå†æŒ‰æƒé‡æ’åº
        all_results.sort(key=lambda x: (x.metadata["retriever_index"], -x.metadata["retriever_weight"]))
        
        # å»é‡ï¼ˆåŸºäºæ–‡æ¡£å†…å®¹ï¼‰
        unique_results = []
        seen_content = set()
        for doc in all_results:
            content = doc.page_content
            if content not in seen_content:
                seen_content.add(content)
                unique_results.append(doc)
                
        return unique_results


class DocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»ï¼Œè´Ÿè´£æ–‡æ¡£åŠ è½½ã€å¤„ç†å’Œå‘é‡åŒ–"""
    
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            chunk_size=CHUNK_SIZE, 
            chunk_overlap=CHUNK_OVERLAP
        )
        
        # Try to initialize embeddings with error handling
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"âœ… æ£€æµ‹åˆ°è®¾å¤‡: {device}")
            if device == 'cuda':
                print(f"   GPUå‹å·: {torch.cuda.get_device_name(0)}")
                print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",  # è½»é‡çº§åµŒå…¥æ¨¡å‹
                model_kwargs={'device': device},  # è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
                encode_kwargs={'normalize_embeddings': True}  # æ ‡å‡†åŒ–åµŒå…¥å‘é‡
            )
            print(f"âœ… HuggingFaceåµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (è®¾å¤‡: {device})")
        except Exception as e:
            print(f"âš ï¸ HuggingFaceåµŒå…¥åˆå§‹åŒ–å¤±è´¥: {e}")
            print("æ­£åœ¨å°è¯•å¤‡ç”¨åµŒå…¥æ–¹æ¡ˆ...")
            # Fallback to OpenAI embeddings or other alternatives
            from langchain_community.embeddings import FakeEmbeddings
            self.embeddings = FakeEmbeddings(size=384)  # For testing purposes
            print("âœ… ä½¿ç”¨æµ‹è¯•åµŒå…¥æ¨¡å‹")
            
        self.vectorstore = None
        self.retriever = None
        self.bm25_retriever = None  # BM25æ£€ç´¢å™¨
        self.ensemble_retriever = None  # é›†æˆæ£€ç´¢å™¨
        
        # åˆå§‹åŒ–é‡æ’å™¨
        self.reranker = None
        self._setup_reranker()
        
        # åˆå§‹åŒ–å¤šæ¨¡æ€æ”¯æŒ
        self.image_embeddings_model = None
        self._setup_multimodal()
        
        # åˆå§‹åŒ–æŸ¥è¯¢æ‰©å±•
        self.query_expansion_model = None
        self._setup_query_expansion()
    
    def _setup_reranker(self):
        """
        è®¾ç½®é‡æ’å™¨
        ä½¿ç”¨ CrossEncoder æå‡é‡æ’å‡†ç¡®ç‡
        """
        try:
            # ä½¿ç”¨ CrossEncoder é‡æ’å™¨ (å‡†ç¡®ç‡æœ€é«˜) â­
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– CrossEncoder é‡æ’å™¨...")
            self.reranker = create_reranker(
                'crossencoder',
                model_name='cross-encoder/ms-marco-MiniLM-L-6-v2',  # è½»é‡çº§æ¨¡å‹
                max_length=512
            )
            print("âœ… CrossEncoder é‡æ’å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ CrossEncoder åˆå§‹åŒ–å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•å›é€€åˆ°æ··åˆé‡æ’å™¨...")
            try:
                # å›é€€åˆ°æ··åˆé‡æ’å™¨
                self.reranker = create_reranker('hybrid', self.embeddings)
                print("âœ… æ··åˆé‡æ’å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e2:
                print(f"âš ï¸ é‡æ’å™¨åˆå§‹åŒ–å®Œå…¨å¤±è´¥: {e2}")
                print("âš ï¸ å°†ä½¿ç”¨åŸºç¡€æ£€ç´¢ï¼Œä¸è¿›è¡Œé‡æ’")
    
    def _setup_multimodal(self):
        """è®¾ç½®å¤šæ¨¡æ€æ”¯æŒ"""
        if not ENABLE_MULTIMODAL:
            print("âš ï¸ å¤šæ¨¡æ€æ”¯æŒå·²ç¦ç”¨")
            return
            
        try:
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å¤šæ¨¡æ€æ”¯æŒ...")
            from transformers import CLIPProcessor, CLIPModel
            import torch
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.image_embeddings_model = CLIPModel.from_pretrained(MULTIMODAL_IMAGE_MODEL).to(device)
            self.image_processor = CLIPProcessor.from_pretrained(MULTIMODAL_IMAGE_MODEL)
            print(f"âœ… å¤šæ¨¡æ€æ”¯æŒåˆå§‹åŒ–æˆåŠŸ (è®¾å¤‡: {device})")
        except Exception as e:
            print(f"âš ï¸ å¤šæ¨¡æ€æ”¯æŒåˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†ä»…ä½¿ç”¨æ–‡æœ¬æ£€ç´¢")
            self.image_embeddings_model = None
    
    def _setup_query_expansion(self):
        """è®¾ç½®æŸ¥è¯¢æ‰©å±•"""
        if not ENABLE_QUERY_EXPANSION:
            print("âš ï¸ æŸ¥è¯¢æ‰©å±•å·²ç¦ç”¨")
            return
            
        try:
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æŸ¥è¯¢æ‰©å±•...")
            from langchain_community.llms import Ollama
            
            self.query_expansion_model = Ollama(model=QUERY_EXPANSION_MODEL)
            print(f"âœ… æŸ¥è¯¢æ‰©å±•åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {QUERY_EXPANSION_MODEL})")
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢æ‰©å±•åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†ä¸ä½¿ç”¨æŸ¥è¯¢æ‰©å±•")
            self.query_expansion_model = None
    
    def load_documents(self, urls=None):
        """ä»URLåŠ è½½æ–‡æ¡£"""
        if urls is None:
            urls = KNOWLEDGE_BASE_URLS
        
        print(f"æ­£åœ¨åŠ è½½ {len(urls)} ä¸ªURLçš„æ–‡æ¡£...")
        docs = [WebBaseLoader(url).load() for url in urls]
        docs_list = [item for sublist in docs for item in sublist]
        print(f"æˆåŠŸåŠ è½½ {len(docs_list)} ä¸ªæ–‡æ¡£")
        return docs_list
    
    def split_documents(self, docs):
        """å°†æ–‡æ¡£åˆ†å‰²æˆå—"""
        print("æ­£åœ¨åˆ†å‰²æ–‡æ¡£...")
        doc_splits = self.text_splitter.split_documents(docs)
        print(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…± {len(doc_splits)} ä¸ªæ–‡æ¡£å—")
        return doc_splits
    
    def create_vectorstore(self, doc_splits):
        """åˆ›å»ºå‘é‡æ•°æ®åº“"""
        print("æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“...")
        self.vectorstore = Chroma.from_documents(
            documents=doc_splits,
            collection_name=COLLECTION_NAME,
            embedding=self.embeddings,
        )
        self.retriever = self.vectorstore.as_retriever()
        
        # å¦‚æœå¯ç”¨æ··åˆæ£€ç´¢ï¼Œåˆ›å»ºBM25æ£€ç´¢å™¨å’Œé›†æˆæ£€ç´¢å™¨
        if ENABLE_HYBRID_SEARCH:
            print("æ­£åœ¨åˆå§‹åŒ–æ··åˆæ£€ç´¢...")
            try:
                # åˆ›å»ºBM25æ£€ç´¢å™¨
                self.bm25_retriever = BM25Retriever.from_documents(
                    doc_splits, 
                    k=KEYWORD_SEARCH_K,
                    k1=BM25_K1,
                    b=BM25_B
                )
                
                # åˆ›å»ºé›†æˆæ£€ç´¢å™¨ï¼Œç»“åˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢
                self.ensemble_retriever = CustomEnsembleRetriever(
                    retrievers=[self.retriever, self.bm25_retriever],
                    weights=[HYBRID_SEARCH_WEIGHTS["vector"], HYBRID_SEARCH_WEIGHTS["keyword"]]
                )
                print("âœ… æ··åˆæ£€ç´¢åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ æ··åˆæ£€ç´¢åˆå§‹åŒ–å¤±è´¥: {e}")
                print("âš ï¸ å°†ä»…ä½¿ç”¨å‘é‡æ£€ç´¢")
                self.ensemble_retriever = None
        
        print("å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ")
        return self.vectorstore, self.retriever
    
    def setup_knowledge_base(self, urls=None, enable_graphrag=False):
        """è®¾ç½®å®Œæ•´çš„çŸ¥è¯†åº“ï¼ˆåŠ è½½ã€åˆ†å‰²ã€å‘é‡åŒ–ï¼‰
        
        Args:
            urls: æ–‡æ¡£URLåˆ—è¡¨
            enable_graphrag: æ˜¯å¦å¯ç”¨GraphRAGç´¢å¼•
            
        Returns:
            vectorstore, retriever, doc_splits
        """
        docs = self.load_documents(urls)
        doc_splits = self.split_documents(docs)
        vectorstore, retriever = self.create_vectorstore(doc_splits)
        
        # è¿”å›doc_splitsç”¨äºGraphRAGç´¢å¼•
        return vectorstore, retriever, doc_splits
    
    def expand_query(self, query: str) -> List[str]:
        """æ‰©å±•æŸ¥è¯¢ï¼Œç”Ÿæˆç›¸å…³æŸ¥è¯¢"""
        if not self.query_expansion_model:
            return [query]
            
        try:
            # ä½¿ç”¨LLMç”Ÿæˆæ‰©å±•æŸ¥è¯¢
            prompt = QUERY_EXPANSION_PROMPT.format(query=query)
            expanded_queries_text = self.query_expansion_model.invoke(prompt)
            
            # è§£ææ‰©å±•æŸ¥è¯¢
            expanded_queries = [query]  # åŒ…å«åŸå§‹æŸ¥è¯¢
            for line in expanded_queries_text.strip().split('\n'):
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('//'):
                    # ç§»é™¤å¯èƒ½çš„ç¼–å·å‰ç¼€
                    if line[0].isdigit() and '.' in line[:5]:
                        line = line.split('.', 1)[1].strip()
                    expanded_queries.append(line)
            
            # é™åˆ¶æ‰©å±•æŸ¥è¯¢æ•°é‡
            return expanded_queries[:MAX_EXPANDED_QUERIES + 1]  # +1 å› ä¸ºåŒ…å«åŸå§‹æŸ¥è¯¢
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢æ‰©å±•å¤±è´¥: {e}")
            return [query]
    
    def encode_image(self, image_path: str) -> np.ndarray:
        """ç¼–ç å›¾åƒä¸ºåµŒå…¥å‘é‡"""
        if not self.image_embeddings_model:
            raise ValueError("å¤šæ¨¡æ€æ”¯æŒæœªåˆå§‹åŒ–")
            
        try:
            # åŠ è½½å¹¶å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            inputs = self.image_processor(images=image, return_tensors="pt")
            
            # è·å–å›¾åƒåµŒå…¥
            with torch.no_grad():
                image_features = self.image_embeddings_model.get_image_features(**inputs)
                # æ ‡å‡†åŒ–åµŒå…¥å‘é‡
                image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
                
            return image_features.cpu().numpy().flatten()
        except Exception as e:
            print(f"âš ï¸ å›¾åƒç¼–ç å¤±è´¥: {e}")
            raise
    
    def multimodal_retrieve(self, query: str, image_paths: List[str] = None, top_k: int = 5) -> List:
        """å¤šæ¨¡æ€æ£€ç´¢ï¼Œç»“åˆæ–‡æœ¬å’Œå›¾åƒ"""
        if not ENABLE_MULTIMODAL or not self.image_embeddings_model:
            # å¦‚æœå¤šæ¨¡æ€æœªå¯ç”¨ï¼Œå›é€€åˆ°æ–‡æœ¬æ£€ç´¢
            return self.hybrid_retrieve(query, top_k) if ENABLE_HYBRID_SEARCH else self.retriever.invoke(query)[:top_k]
        
        # æ–‡æœ¬æ£€ç´¢
        text_docs = self.hybrid_retrieve(query, top_k) if ENABLE_HYBRID_SEARCH else self.retriever.invoke(query)[:top_k]
        
        # å¦‚æœæ²¡æœ‰æä¾›å›¾åƒï¼Œç›´æ¥è¿”å›æ–‡æœ¬æ£€ç´¢ç»“æœ
        if not image_paths:
            return text_docs
            
        try:
            # å›¾åƒæ£€ç´¢
            image_results = []
            for image_path in image_paths:
                # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
                file_ext = image_path.split('.')[-1].lower()
                if file_ext not in SUPPORTED_IMAGE_FORMATS:
                    print(f"âš ï¸ ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {file_ext}")
                    continue
                    
                # ç¼–ç å›¾åƒ
                image_embedding = self.encode_image(image_path)
                
                # è¿™é‡Œåº”è¯¥å®ç°å›¾åƒåˆ°æ–‡æœ¬çš„åŒ¹é…é€»è¾‘
                # ç”±äºåŸå§‹å®ç°ä¸­æ²¡æœ‰å›¾åƒæ•°æ®åº“ï¼Œæˆ‘ä»¬ç®€åŒ–å¤„ç†
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥æœ‰ä¸€ä¸ªå›¾åƒæ•°æ®åº“å’Œç›¸åº”çš„æ£€ç´¢é€»è¾‘
                
            # åˆå¹¶æ–‡æœ¬å’Œå›¾åƒç»“æœï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥æœ‰æ›´å¤æ‚çš„èåˆé€»è¾‘
            final_docs = text_docs  # ç®€åŒ–ç‰ˆæœ¬ï¼Œä»…è¿”å›æ–‡æœ¬ç»“æœ
            
            print(f"âœ… å¤šæ¨¡æ€æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(final_docs)} ä¸ªç»“æœ")
            return final_docs
        except Exception as e:
            print(f"âš ï¸ å¤šæ¨¡æ€æ£€ç´¢å¤±è´¥: {e}")
            print("å›é€€åˆ°æ–‡æœ¬æ£€ç´¢")
            return text_docs
    
    def hybrid_retrieve(self, query: str, top_k: int = 5) -> List:
        """æ··åˆæ£€ç´¢ï¼Œç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢"""
        if not ENABLE_HYBRID_SEARCH or not self.ensemble_retriever:
            # å¦‚æœæ··åˆæ£€ç´¢æœªå¯ç”¨ï¼Œå›é€€åˆ°å‘é‡æ£€ç´¢
            return self.retriever.invoke(query)[:top_k]
            
        try:
            # ä½¿ç”¨é›†æˆæ£€ç´¢å™¨è¿›è¡Œæ··åˆæ£€ç´¢
            results = self.ensemble_retriever.invoke(query)
            return results[:top_k]
        except Exception as e:
            print(f"âš ï¸ æ··åˆæ£€ç´¢å¤±è´¥: {e}")
            print("å›é€€åˆ°å‘é‡æ£€ç´¢")
            return self.retriever.invoke(query)[:top_k]
    
    def enhanced_retrieve(self, query: str, top_k: int = 5, rerank_candidates: int = 20, 
                         image_paths: List[str] = None, use_query_expansion: bool = None):
        """å¢å¼ºæ£€ç´¢ï¼šå…ˆæ£€ç´¢æ›´å¤šå€™é€‰ï¼Œç„¶åé‡æ’ï¼Œæ”¯æŒæŸ¥è¯¢æ‰©å±•å’Œå¤šæ¨¡æ€
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            rerank_candidates: é‡æ’å‰çš„å€™é€‰æ–‡æ¡£æ•°é‡
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨ï¼Œç”¨äºå¤šæ¨¡æ€æ£€ç´¢
            use_query_expansion: æ˜¯å¦ä½¿ç”¨æŸ¥è¯¢æ‰©å±•ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é…ç½®é»˜è®¤å€¼
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨æŸ¥è¯¢æ‰©å±•
        if use_query_expansion is None:
            use_query_expansion = ENABLE_QUERY_EXPANSION
            
        # å¦‚æœå¯ç”¨æŸ¥è¯¢æ‰©å±•ï¼Œç”Ÿæˆæ‰©å±•æŸ¥è¯¢
        if use_query_expansion:
            expanded_queries = self.expand_query(query)
            print(f"æŸ¥è¯¢æ‰©å±•: {len(expanded_queries)} ä¸ªæŸ¥è¯¢")
        else:
            expanded_queries = [query]
            
        # å¤šæ¨¡æ€æ£€ç´¢ï¼ˆå¦‚æœæä¾›äº†å›¾åƒï¼‰
        if image_paths and ENABLE_MULTIMODAL:
            return self.multimodal_retrieve(query, image_paths, top_k)
            
        # æ··åˆæ£€ç´¢æˆ–å‘é‡æ£€ç´¢
        all_candidate_docs = []
        for expanded_query in expanded_queries:
            if ENABLE_HYBRID_SEARCH:
                # ä½¿ç”¨æ··åˆæ£€ç´¢
                docs = self.hybrid_retrieve(expanded_query, rerank_candidates)
            else:
                # ä½¿ç”¨å‘é‡æ£€ç´¢
                docs = self.retriever.invoke(expanded_query)
                if len(docs) > rerank_candidates:
                    docs = docs[:rerank_candidates]
            
            all_candidate_docs.extend(docs)
            
        # å»é‡ï¼ˆåŸºäºæ–‡æ¡£å†…å®¹ï¼‰
        unique_docs = []
        seen_content = set()
        for doc in all_candidate_docs:
            content = doc.page_content
            if content not in seen_content:
                seen_content.add(content)
                unique_docs.append(doc)
                
        print(f"æ£€ç´¢è·å¾— {len(unique_docs)} ä¸ªå€™é€‰æ–‡æ¡£")
        
        # é‡æ’ï¼ˆå¦‚æœé‡æ’å™¨å¯ç”¨ï¼‰
        if self.reranker and len(unique_docs) > top_k:
            try:
                reranked_results = self.reranker.rerank(query, unique_docs, top_k)
                final_docs = [doc for doc, score in reranked_results]
                scores = [score for doc, score in reranked_results]
                
                print(f"é‡æ’åè¿”å› {len(final_docs)} ä¸ªæ–‡æ¡£")
                print(f"é‡æ’åˆ†æ•°èŒƒå›´: {min(scores):.4f} - {max(scores):.4f}")
                
                return final_docs
            except Exception as e:
                print(f"âš ï¸ é‡æ’å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ")
                return unique_docs[:top_k]
        else:
            # ä¸é‡æ’æˆ–å€™é€‰æ•°é‡ä¸è¶³
            return unique_docs[:top_k]
    
    def compare_retrieval_methods(self, query: str, top_k: int = 5, image_paths: List[str] = None):
        """æ¯”è¾ƒä¸åŒæ£€ç´¢æ–¹æ³•çš„æ•ˆæœ"""
        if not self.retriever:
            return {}
        
        results = {
            'query': query,
            'image_paths': image_paths
        }
        
        # åŸå§‹æ£€ç´¢ (ä½¿ç”¨ invoke æ›¿ä»£ get_relevant_documents)
        original_docs = self.retriever.invoke(query)[:top_k]
        results['vector_retrieval'] = {
            'count': len(original_docs),
            'documents': [{
                'content': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,
                'metadata': getattr(doc, 'metadata', {})
            } for doc in original_docs]
        }
        
        # æ··åˆæ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if ENABLE_HYBRID_SEARCH and self.ensemble_retriever:
            hybrid_docs = self.hybrid_retrieve(query, top_k)
            results['hybrid_retrieval'] = {
                'count': len(hybrid_docs),
                'documents': [{
                    'content': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,
                    'metadata': getattr(doc, 'metadata', {})
                } for doc in hybrid_docs]
            }
        
        # æŸ¥è¯¢æ‰©å±•æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if ENABLE_QUERY_EXPANSION and self.query_expansion_model:
            expanded_docs = self.enhanced_retrieve(query, top_k, use_query_expansion=True)
            results['expanded_query_retrieval'] = {
                'count': len(expanded_docs),
                'documents': [{
                    'content': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,
                    'metadata': getattr(doc, 'metadata', {})
                } for doc in expanded_docs]
            }
        
        # å¤šæ¨¡æ€æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ä¸”æœ‰å›¾åƒï¼‰
        if ENABLE_MULTIMODAL and image_paths:
            multimodal_docs = self.multimodal_retrieve(query, image_paths, top_k)
            results['multimodal_retrieval'] = {
                'count': len(multimodal_docs),
                'documents': [{
                    'content': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,
                    'metadata': getattr(doc, 'metadata', {})
                } for doc in multimodal_docs]
            }
        
        # å¢å¼ºæ£€ç´¢ï¼ˆå¸¦é‡æ’ï¼‰
        enhanced_docs = self.enhanced_retrieve(query, top_k)
        results['enhanced_retrieval'] = {
            'count': len(enhanced_docs),
            'documents': [{
                'content': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,
                'metadata': getattr(doc, 'metadata', {})
            } for doc in enhanced_docs]
        }
        
        # æ·»åŠ é…ç½®ä¿¡æ¯
        results['configuration'] = {
            'hybrid_search_enabled': ENABLE_HYBRID_SEARCH,
            'query_expansion_enabled': ENABLE_QUERY_EXPANSION,
            'multimodal_enabled': ENABLE_MULTIMODAL,
            'reranker_used': self.reranker is not None,
            'hybrid_weights': HYBRID_SEARCH_WEIGHTS if ENABLE_HYBRID_SEARCH else None,
            'multimodal_weights': MULTIMODAL_WEIGHTS if ENABLE_MULTIMODAL else None
        }
        
        return results

    def format_docs(self, docs):
        """æ ¼å¼åŒ–æ–‡æ¡£ç”¨äºç”Ÿæˆ"""
        return "\n\n".join(doc.page_content for doc in docs)


def initialize_document_processor():
    """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨å¹¶è®¾ç½®çŸ¥è¯†åº“"""
    processor: DocumentProcessor = DocumentProcessor()
    vectorstore, retriever, doc_splits = processor.setup_knowledge_base()
    return processor, vectorstore, retriever, doc_splits