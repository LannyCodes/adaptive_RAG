#!/usr/bin/env python3
"""
Kaggle Ollama è¿æ¥é—®é¢˜è¯Šæ–­å’Œä¿®å¤è„šæœ¬
è§£å†³ GraphRAG å¼‚æ­¥å¤„ç†æ—¶çš„è¿æ¥é”™è¯¯
"""

import subprocess
import time
import requests
import os

def check_ollama_service():
    """æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€"""
    print("="*70)
    print("ğŸ” Ollama æœåŠ¡è¯Šæ–­")
    print("="*70)
    
    # 1. æ£€æŸ¥è¿›ç¨‹
    print("\n1ï¸âƒ£ æ£€æŸ¥ Ollama è¿›ç¨‹...")
    ps_check = subprocess.run(['pgrep', '-f', 'ollama serve'], capture_output=True)
    
    if ps_check.returncode == 0:
        print("   âœ… Ollama è¿›ç¨‹æ­£åœ¨è¿è¡Œ")
        pids = ps_check.stdout.decode().strip().split('\n')
        print(f"   ğŸ“Š è¿›ç¨‹ PID: {', '.join(pids)}")
    else:
        print("   âŒ Ollama è¿›ç¨‹æœªè¿è¡Œ")
        return False
    
    # 2. æ£€æŸ¥ç«¯å£
    print("\n2ï¸âƒ£ æ£€æŸ¥ç«¯å£ 11434...")
    port_check = subprocess.run(
        ['netstat', '-tuln'], 
        capture_output=True, 
        text=True
    )
    
    if '11434' in port_check.stdout:
        print("   âœ… ç«¯å£ 11434 å·²ç›‘å¬")
    else:
        print("   âŒ ç«¯å£ 11434 æœªç›‘å¬")
        return False
    
    # 3. æµ‹è¯• API è¿æ¥
    print("\n3ï¸âƒ£ æµ‹è¯• API è¿æ¥...")
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        if response.status_code == 200:
            print("   âœ… API è¿æ¥æ­£å¸¸")
            models = response.json().get('models', [])
            print(f"   ğŸ“¦ å¯ç”¨æ¨¡å‹: {len(models)}")
            for model in models:
                print(f"      â€¢ {model.get('name', 'unknown')}")
            return True
        else:
            print(f"   âŒ API è¿”å›é”™è¯¯: {response.status_code}")
            return False
    except Exception as e:
        print(f"   âŒ API è¿æ¥å¤±è´¥: {e}")
        return False

def start_ollama_service():
    """å¯åŠ¨ Ollama æœåŠ¡"""
    print("\n"+"="*70)
    print("ğŸš€ å¯åŠ¨ Ollama æœåŠ¡")
    print("="*70)
    
    # å…ˆæ€æ­»å¯èƒ½å­˜åœ¨çš„åƒµå°¸è¿›ç¨‹
    print("\n1ï¸âƒ£ æ¸…ç†æ—§è¿›ç¨‹...")
    subprocess.run(['pkill', '-9', 'ollama'], capture_output=True)
    time.sleep(2)
    
    # å¯åŠ¨æœåŠ¡
    print("\n2ï¸âƒ£ å¯åŠ¨æ–°æœåŠ¡...")
    process = subprocess.Popen(
        ['ollama', 'serve'],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        env=os.environ.copy()
    )
    
    print(f"   âœ… æœåŠ¡è¿›ç¨‹å·²å¯åŠ¨ (PID: {process.pid})")
    
    # ç­‰å¾…æœåŠ¡å°±ç»ª
    print("\n3ï¸âƒ£ ç­‰å¾…æœåŠ¡å°±ç»ª...")
    max_wait = 30
    for i in range(max_wait):
        try:
            response = requests.get('http://localhost:11434/api/tags', timeout=2)
            if response.status_code == 200:
                print(f"   âœ… æœåŠ¡å°±ç»ªï¼(è€—æ—¶ {i+1} ç§’)")
                return True
        except:
            pass
        
        if i < max_wait - 1:
            print(f"   â³ ç­‰å¾…ä¸­... ({i+1}/{max_wait})", end='\r')
            time.sleep(1)
    
    print(f"\n   âš ï¸ æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼Œä½†å¯èƒ½ä»åœ¨åˆå§‹åŒ–ä¸­")
    return False

def test_generation():
    """æµ‹è¯•ç”ŸæˆåŠŸèƒ½"""
    print("\n"+"="*70)
    print("ğŸ§ª æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ")
    print("="*70)
    
    print("\n   â„¹ï¸ é¦–æ¬¡è°ƒç”¨ä¼šåŠ è½½æ¨¡å‹åˆ°å†…å­˜ï¼Œéœ€è¦ 30-60 ç§’...")
    print("   â³ è¯·è€å¿ƒç­‰å¾…...\n")
    
    try:
        response = requests.post(
            'http://localhost:11434/api/generate',
            json={
                "model": "mistral",
                "prompt": "Say 'Hello' in one word",
                "stream": False
            },
            timeout=120  # å¢åŠ åˆ° 120 ç§’ï¼Œé¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦æ—¶é—´
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"   âœ… ç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ“ å“åº”: {result.get('response', '')[:100]}")
            return True
        else:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥: {response.status_code}")
            return False
    except requests.exceptions.Timeout:
        print(f"   âš ï¸ ç”Ÿæˆè¶…æ—¶ï¼ˆä½†è¿™å¯èƒ½æ˜¯æ¨¡å‹åŠ è½½ä¸­ï¼‰")
        print(f"   ğŸ’¡ å»ºè®®ï¼šå†ç­‰å¾… 30 ç§’åé‡è¯•")
        return False
    except Exception as e:
        print(f"   âŒ ç”Ÿæˆé”™è¯¯: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*70)
    print("ğŸ”§ Kaggle Ollama è¿æ¥é—®é¢˜ä¿®å¤å·¥å…·")
    print("="*70)
    print("\nè§£å†³é—®é¢˜: Cannot connect to host localhost:11434")
    print("åœºæ™¯: GraphRAG å¼‚æ­¥æ‰¹å¤„ç†æ—¶")
    
    # æ£€æŸ¥æœåŠ¡
    is_running = check_ollama_service()
    
    if not is_running:
        print("\nâš ï¸ Ollama æœåŠ¡æœªæ­£å¸¸è¿è¡Œï¼Œæ­£åœ¨ä¿®å¤...")
        start_ollama_service()
        
        # å†æ¬¡æ£€æŸ¥
        print("\n"+"="*70)
        print("ğŸ” éªŒè¯ä¿®å¤ç»“æœ")
        print("="*70)
        is_running = check_ollama_service()
    
    # æµ‹è¯•ç”Ÿæˆ
    if is_running:
        test_generation()
    
    # è¾“å‡ºå»ºè®®
    print("\n"+"="*70)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®")
    print("="*70)
    
    if is_running:
        if test_generation():
            print("""
âœ… Ollama æœåŠ¡å®Œå…¨å°±ç»ªï¼ç°åœ¨å¯ä»¥è¿è¡Œ GraphRAG äº†

ğŸ“ åœ¨ Kaggle Notebook ä¸­è¿è¡Œ:

from document_processor import DocumentProcessor
from graph_indexer import GraphRAGIndexer

# åˆå§‹åŒ–
processor = DocumentProcessor()
vectorstore, retriever, doc_splits = processor.setup_knowledge_base(
    enable_graphrag=True
)

# GraphRAG ç´¢å¼•ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰
indexer = GraphRAGIndexer(
    enable_async=True,      # å¯ç”¨å¼‚æ­¥
    async_batch_size=8      # å¹¶å‘å¤„ç† 8 ä¸ªæ–‡æ¡£
)

graph = indexer.index_documents(doc_splits)
        """)
        else:
            print("""
âš ï¸ Ollama æœåŠ¡è¿è¡Œä¸­ï¼Œä½†æ¨¡å‹å¯èƒ½è¿˜åœ¨åŠ è½½

ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š

1. ç­‰å¾… 30-60 ç§’è®©æ¨¡å‹å®Œå…¨åŠ è½½
2. å†æ¬¡è¿è¡Œæ­¤è„šæœ¬éªŒè¯
3. æˆ–è€…ç›´æ¥è¿è¡Œä¸€æ¬¡ç®€å•æµ‹è¯•ï¼š
   !curl http://localhost:11434/api/generate -d '{
     "model": "mistral",
     "prompt": "Hello",
     "stream": false
   }'

4. å¦‚æœä¸Šè¿°æµ‹è¯•æˆåŠŸï¼Œå°±å¯ä»¥è¿è¡Œ GraphRAG äº†
        """)
    else:
        print("""
âŒ Ollama æœåŠ¡ä»ç„¶å¼‚å¸¸

ğŸ”§ æ‰‹åŠ¨ä¿®å¤æ­¥éª¤:

1. åœ¨ Kaggle Notebook æ–°å•å…ƒæ ¼è¿è¡Œ:
   !pkill -9 ollama
   !ollama serve &
   
2. ç­‰å¾… 15 ç§’åï¼Œè¿è¡Œ:
   !curl http://localhost:11434/api/tags
   
3. å¦‚æœæˆåŠŸï¼Œé‡æ–°è¿è¡Œæ­¤è„šæœ¬éªŒè¯

4. å¦‚æœå¤±è´¥ï¼Œæ£€æŸ¥ Ollama æ˜¯å¦æ­£ç¡®å®‰è£…:
   !which ollama
   !ollama --version
        """)
    
    print("="*70)

if __name__ == "__main__":
    main()
