"""
Kaggle Ollama ä¿å­˜è„šæœ¬
å°† Ollama å’Œæ¨¡å‹ä¿å­˜åˆ° Kaggle Datasetï¼Œä¸‹æ¬¡ç›´æ¥ä½¿ç”¨

ä½¿ç”¨æ­¥éª¤:
1. é¦–æ¬¡è¿è¡Œ: å®‰è£… Ollama å’Œä¸‹è½½æ¨¡å‹åï¼Œè¿è¡Œæœ¬è„šæœ¬ä¿å­˜
2. åç»­ä½¿ç”¨: ä½¿ç”¨ KAGGLE_LOAD_OLLAMA.py ä» Dataset åŠ è½½

æ³¨æ„: éœ€è¦æ‰‹åŠ¨åˆ›å»º Kaggle Dataset å¹¶ä¸Šä¼ 
"""

import os
import subprocess
import shutil
import tarfile
import time
from pathlib import Path

print("="*70)
print("ğŸ’¾ Kaggle Ollama ä¿å­˜å·¥å…·")
print("="*70)

# ==================== é…ç½® ====================
OUTPUT_DIR = "/kaggle/working/ollama_backup"
MODEL_NAME = "mistral"  # æˆ–è€… "phi", "tinyllama" ç­‰

print(f"\nğŸ“‹ é…ç½®:")
print(f"   æ¨¡å‹: {MODEL_NAME}")
print(f"   è¾“å‡ºç›®å½•: {OUTPUT_DIR}")

# ==================== æ­¥éª¤ 1: åˆ›å»ºè¾“å‡ºç›®å½• ====================
print(f"\nğŸ“ æ­¥éª¤ 1/4: åˆ›å»ºå¤‡ä»½ç›®å½•...")
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"   âœ… ç›®å½•åˆ›å»ºæˆåŠŸ")

# ==================== æ­¥éª¤ 2: å¤‡ä»½ Ollama äºŒè¿›åˆ¶æ–‡ä»¶ ====================
print(f"\nğŸ“¦ æ­¥éª¤ 2/4: å¤‡ä»½ Ollama äºŒè¿›åˆ¶æ–‡ä»¶...")

ollama_bin = shutil.which('ollama')
if ollama_bin:
    print(f"   æ‰¾åˆ° Ollama: {ollama_bin}")
    
    # å¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
    shutil.copy2(ollama_bin, os.path.join(OUTPUT_DIR, 'ollama'))
    print(f"   âœ… Ollama äºŒè¿›åˆ¶æ–‡ä»¶å·²å¤‡ä»½")
else:
    print(f"   âŒ æœªæ‰¾åˆ° Ollamaï¼Œè¯·å…ˆå®‰è£…")
    exit(1)

# ==================== æ­¥éª¤ 3: å¤‡ä»½æ¨¡å‹æ–‡ä»¶ ====================
print(f"\nğŸ¤– æ­¥éª¤ 3/4: å¤‡ä»½ {MODEL_NAME} æ¨¡å‹...")

# Ollama æ¨¡å‹å­˜å‚¨ä½ç½®ï¼ˆå¯èƒ½åœ¨ä¸åŒä½ç½®ï¼‰
possible_model_dirs = [
    os.path.expanduser("~/.ollama/models"),
    "/root/.ollama/models",
    os.path.expanduser("~/.ollama")
]

ollama_models_dir = None
for dir_path in possible_model_dirs:
    if os.path.exists(dir_path) and os.path.isdir(dir_path):
        # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
        if os.listdir(dir_path):
            ollama_models_dir = os.path.dirname(dir_path) if dir_path.endswith('models') else dir_path
            break

if ollama_models_dir and os.path.exists(ollama_models_dir):
    print(f"   æ‰¾åˆ°æ¨¡å‹ç›®å½•: {ollama_models_dir}")
    
    # è®¡ç®—ç›®å½•å¤§å°
    total_size = sum(
        os.path.getsize(os.path.join(dirpath, filename))
        for dirpath, dirnames, filenames in os.walk(ollama_models_dir)
        for filename in filenames
    )
    print(f"   æ¨¡å‹æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
    
    # åˆ›å»ºå‹ç¼©åŒ…ï¼ˆæ•´ä¸ª .ollama ç›®å½•ï¼‰
    models_archive = os.path.join(OUTPUT_DIR, 'ollama_models.tar.gz')
    print(f"   ğŸ“¦ åˆ›å»ºå‹ç¼©åŒ…ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    print(f"   æ­£åœ¨å‹ç¼©: {ollama_models_dir}")
    
    start_time = time.time()
    with tarfile.open(models_archive, 'w:gz') as tar:
        tar.add(ollama_models_dir, arcname='.ollama')
    
    elapsed = time.time() - start_time
    archive_size = os.path.getsize(models_archive) / (1024**3)
    
    print(f"   âœ… å‹ç¼©å®Œæˆ")
    print(f"      è€—æ—¶: {int(elapsed)}ç§’")
    print(f"      å‹ç¼©åŒ…å¤§å°: {archive_size:.2f} GB")
else:
    print(f"   âŒ æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•")
    print(f"   è¯·å…ˆè¿è¡Œ: ollama pull {MODEL_NAME}")
    exit(1)

# ==================== æ­¥éª¤ 4: ç”Ÿæˆè¯´æ˜æ–‡ä»¶ ====================
print(f"\nğŸ“ æ­¥éª¤ 4/4: ç”Ÿæˆè¯´æ˜æ–‡ä»¶...")

readme_content = f"""# Ollama å¤‡ä»½åŒ…

## å†…å®¹
- `ollama`: Ollama äºŒè¿›åˆ¶æ–‡ä»¶
- `ollama_models.tar.gz`: æ¨¡å‹æ–‡ä»¶å‹ç¼©åŒ…ï¼ˆåŒ…å« {MODEL_NAME}ï¼‰

## å¤‡ä»½ä¿¡æ¯
- å¤‡ä»½æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
- æ¨¡å‹: {MODEL_NAME}
- å‹ç¼©åŒ…å¤§å°: {archive_size:.2f} GB

## ä½¿ç”¨æ–¹æ³•

### 1. åˆ›å»º Kaggle Dataset

1. ä¸‹è½½æ­¤ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°
2. åœ¨ Kaggle ç½‘ç«™åˆ›å»ºæ–° Dataset:
   - è®¿é—®: https://www.kaggle.com/datasets
   - ç‚¹å‡» "New Dataset"
   - ä¸Šä¼  `ollama` å’Œ `ollama_models.tar.gz`
   - å‘½åä¸º: `ollama-{MODEL_NAME}-backup`
   - è®¾ç½®ä¸º Private
   - ç‚¹å‡» "Create"

### 2. åœ¨ Notebook ä¸­åŠ è½½

åœ¨ Kaggle Notebook ä¸­:

1. æ·»åŠ  Dataset:
   - ç‚¹å‡»å³ä¾§ "Add data" â†’ "Your Datasets"
   - é€‰æ‹©ä½ åˆ›å»ºçš„ `ollama-{MODEL_NAME}-backup`

2. è¿è¡ŒåŠ è½½è„šæœ¬:
   ```python
   # ä½¿ç”¨é¡¹ç›®ä¸­çš„ KAGGLE_LOAD_OLLAMA.py
   exec(open('/kaggle/working/adaptive_RAG/KAGGLE_LOAD_OLLAMA.py').read())
   ```

### 3. éªŒè¯

```bash
# æ£€æŸ¥ Ollama
ollama --version

# æ£€æŸ¥æ¨¡å‹
ollama list

# æµ‹è¯•è¿è¡Œ
ollama run {MODEL_NAME} "Hello"
```

## æ–‡ä»¶å¤§å°å‚è€ƒ

ä¸åŒæ¨¡å‹çš„å‹ç¼©åŒ…å¤§å°ï¼ˆè¿‘ä¼¼å€¼ï¼‰:
- qwen:0.5b: ~350 MB
- tinyllama: ~600 MB
- phi: ~1.6 GB
- mistral: ~4 GB
- llama2:7b: ~3.8 GB

## æ³¨æ„äº‹é¡¹

1. âš ï¸ Dataset å¤§å°é™åˆ¶:
   - å…è´¹ç”¨æˆ·: æ¯ä¸ª Dataset æœ€å¤§ 20GB
   - éœ€è¦ç¡®ä¿å‹ç¼©åŒ… < 20GB

2. âš ï¸ ä¸Šä¼ æ—¶é—´:
   - å–å†³äºä½ çš„ç½‘ç»œé€Ÿåº¦
   - 4GB æ–‡ä»¶å¯èƒ½éœ€è¦ 10-30 åˆ†é’Ÿ

3. âœ… ä¼˜åŠ¿:
   - åªéœ€ä¸Šä¼ ä¸€æ¬¡
   - æ¯æ¬¡ Notebook å¯åŠ¨æ—¶ç›´æ¥åŠ è½½ï¼ˆç§’çº§ï¼‰
   - èŠ‚çœå¤§é‡æ—¶é—´

## æ•…éšœæ’é™¤

### é—®é¢˜: ä¸Šä¼ å¤±è´¥
è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–åˆ†å¤šæ¬¡ä¸Šä¼ 

### é—®é¢˜: Dataset è¿‡å¤§
è§£å†³: ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ phi æˆ– tinyllamaï¼‰

### é—®é¢˜: åŠ è½½å Ollama æ— æ³•è¿è¡Œ
è§£å†³: æ£€æŸ¥æ–‡ä»¶æƒé™ï¼Œè¿è¡Œ `chmod +x /usr/local/bin/ollama`
"""

readme_file = os.path.join(OUTPUT_DIR, 'README.md')
with open(readme_file, 'w', encoding='utf-8') as f:
    f.write(readme_content)

print(f"   âœ… è¯´æ˜æ–‡ä»¶å·²ç”Ÿæˆ")

# ==================== ç”ŸæˆåŠ è½½è„šæœ¬ï¼ˆä¾›å‚è€ƒï¼‰ ====================
loader_script = os.path.join(OUTPUT_DIR, 'load_example.py')
with open(loader_script, 'w', encoding='utf-8') as f:
    f.write(f'''"""
ç¤ºä¾‹: ä» Kaggle Dataset åŠ è½½ Ollama
"""
import os
import subprocess
import tarfile
import shutil

# Dataset è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„ Dataset åç§°ä¿®æ”¹ï¼‰
DATASET_PATH = "/kaggle/input/ollama-{MODEL_NAME}-backup"

print("ğŸ“¦ ä» Dataset åŠ è½½ Ollama...")

# 1. å¤åˆ¶ Ollama äºŒè¿›åˆ¶æ–‡ä»¶
ollama_bin = os.path.join(DATASET_PATH, "ollama")
if os.path.exists(ollama_bin):
    shutil.copy2(ollama_bin, "/usr/local/bin/ollama")
    os.chmod("/usr/local/bin/ollama", 0o755)
    print("âœ… Ollama äºŒè¿›åˆ¶æ–‡ä»¶å·²å®‰è£…")

# 2. è§£å‹æ¨¡å‹æ–‡ä»¶
models_archive = os.path.join(DATASET_PATH, "ollama_models.tar.gz")
if os.path.exists(models_archive):
    print("ğŸ“¦ è§£å‹æ¨¡å‹æ–‡ä»¶...")
    with tarfile.open(models_archive, 'r:gz') as tar:
        tar.extractall(os.path.expanduser("~/.ollama"))
    print("âœ… æ¨¡å‹å·²è§£å‹")

# 3. å¯åŠ¨ Ollama æœåŠ¡
print("ğŸš€ å¯åŠ¨ Ollama æœåŠ¡...")
subprocess.Popen(['ollama', 'serve'])
import time
time.sleep(15)

print("âœ… Ollama å·²å‡†å¤‡å°±ç»ª!")
print("\\néªŒè¯:")
subprocess.run(['ollama', 'list'])
''')

print(f"   âœ… ç¤ºä¾‹è„šæœ¬å·²ç”Ÿæˆ")

# ==================== æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ ====================
print(f"\nğŸ“Š å¤‡ä»½å†…å®¹:")
for item in os.listdir(OUTPUT_DIR):
    item_path = os.path.join(OUTPUT_DIR, item)
    size = os.path.getsize(item_path)
    size_str = f"{size / (1024**3):.2f} GB" if size > 1024**3 else f"{size / (1024**2):.2f} MB"
    print(f"   â€¢ {item}: {size_str}")

# ==================== åç»­æ­¥éª¤è¯´æ˜ ====================
print("\n" + "="*70)
print("âœ… å¤‡ä»½å®Œæˆï¼")
print("="*70)

print(f"\nğŸ“‹ åç»­æ­¥éª¤:")
print(f"""
1. ä¸‹è½½å¤‡ä»½æ–‡ä»¶åˆ°æœ¬åœ°:
   åœ¨ Kaggle Notebook å³ä¾§ Output ä¸­ä¸‹è½½ {OUTPUT_DIR} ç›®å½•

2. åˆ›å»º Kaggle Dataset:
   â€¢ è®¿é—®: https://www.kaggle.com/datasets
   â€¢ ç‚¹å‡» "New Dataset"
   â€¢ ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶:
     - ollama (äºŒè¿›åˆ¶æ–‡ä»¶)
     - ollama_models.tar.gz (æ¨¡å‹å‹ç¼©åŒ…)
   â€¢ å‘½å: ollama-{MODEL_NAME}-backup
   â€¢ ç‚¹å‡» "Create"

3. ä¸‹æ¬¡ä½¿ç”¨:
   â€¢ åœ¨ Notebook ä¸­æ·»åŠ ä½ çš„ Dataset
   â€¢ è¿è¡Œ KAGGLE_LOAD_OLLAMA.py è„šæœ¬
   â€¢ å³å¯ç§’çº§åŠ è½½ï¼Œæ— éœ€é‡æ–°ä¸‹è½½ï¼

â±ï¸  æ—¶é—´å¯¹æ¯”:
   â€¢ ä¼ ç»Ÿæ–¹å¼: æ¯æ¬¡å¯åŠ¨éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½
   â€¢ Dataset æ–¹å¼: æ¯æ¬¡å¯åŠ¨åªéœ€ 10-20 ç§’åŠ è½½
   â€¢ èŠ‚çœæ—¶é—´: æ¯æ¬¡èŠ‚çœ 5-10 åˆ†é’Ÿï¼

ğŸ’¡ æç¤º:
   â€¢ ä¸Šä¼  Dataset æ˜¯ä¸€æ¬¡æ€§å·¥ä½œ
   â€¢ ä¹‹åæ¯æ¬¡ Notebook å¯åŠ¨éƒ½èƒ½å¿«é€ŸåŠ è½½
   â€¢ å¼ºçƒˆæ¨èï¼
""")

print("\næŸ¥çœ‹è¯¦ç»†è¯´æ˜: cat {}/README.md".format(OUTPUT_DIR))
