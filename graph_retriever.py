"""
GraphRAGæ£€ç´¢å™¨
å®ç°åŸºäºçŸ¥è¯†å›¾è°±çš„æ£€ç´¢ç­–ç•¥ï¼ŒåŒ…æ‹¬æœ¬åœ°æŸ¥è¯¢å’Œå…¨å±€æŸ¥è¯¢
"""

from typing import List, Dict, Set, Tuple
try:
    from langchain_core.prompts import PromptTemplate
except ImportError:
    try:
    from langchain_core.prompts import PromptTemplate
except ImportError:
    from langchain.prompts import PromptTemplate

from langchain_community.chat_models import ChatOllama
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

from knowledge_graph import KnowledgeGraph
from config import LOCAL_LLM


class GraphRetriever:
    """åŸºäºçŸ¥è¯†å›¾è°±çš„æ£€ç´¢å™¨"""
    
    def __init__(self, knowledge_graph: KnowledgeGraph):
        self.kg = knowledge_graph
        self.llm = ChatOllama(model=LOCAL_LLM, temperature=0.3)
        
        # å®ä½“è¯†åˆ«æç¤º
        self.entity_recognition_prompt = PromptTemplate(
            template="""ä»ä»¥ä¸‹é—®é¢˜ä¸­è¯†åˆ«å…³é”®å®ä½“å’Œæ¦‚å¿µ:

é—®é¢˜: {question}

å·²çŸ¥å®ä½“ç¤ºä¾‹: {sample_entities}

è¯·è¯†åˆ«é—®é¢˜ä¸­æåˆ°çš„å®ä½“ï¼Œè¿”å›JSONæ ¼å¼:
{{
    "entities": ["å®ä½“1", "å®ä½“2", ...]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
""",
            input_variables=["question", "sample_entities"]
        )
        
        # å…¨å±€æŸ¥è¯¢ç”Ÿæˆæç¤º
        self.global_query_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±åˆ†æä¸“å®¶ã€‚åŸºäºä»¥ä¸‹ç¤¾åŒºæ‘˜è¦ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

ç›¸å…³ç¤¾åŒºæ‘˜è¦:
{community_summaries}

è¯·åŸºäºè¿™äº›æ‘˜è¦æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„ç­”æ¡ˆã€‚å¦‚æœæ‘˜è¦ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚

ç­”æ¡ˆ:
""",
            input_variables=["question", "community_summaries"]
        )
        
        # æœ¬åœ°æŸ¥è¯¢ç”Ÿæˆæç¤º
        self.local_query_prompt = PromptTemplate(
            template="""åŸºäºä»¥ä¸‹å®ä½“åŠå…¶å…³ç³»ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: {question}

ç›¸å…³å®ä½“ä¿¡æ¯:
{entity_info}

å®ä½“é—´çš„å…³ç³»:
{relations}

è¯·åŸºäºè¿™äº›ä¿¡æ¯æä¾›ç­”æ¡ˆã€‚

ç­”æ¡ˆ:
""",
            input_variables=["question", "entity_info", "relations"]
        )
        
        self.entity_recognition_chain = self.entity_recognition_prompt | self.llm | JsonOutputParser()
        self.global_query_chain = self.global_query_prompt | self.llm | StrOutputParser()
        self.local_query_chain = self.local_query_prompt | self.llm | StrOutputParser()
    
    def recognize_entities(self, question: str) -> List[str]:
        """
        ä»é—®é¢˜ä¸­è¯†åˆ«å®ä½“
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            è¯†åˆ«åˆ°çš„å®ä½“åˆ—è¡¨
        """
        # è·å–ä¸€äº›ç¤ºä¾‹å®ä½“
        sample_entities = list(self.kg.entities.keys())[:10]
        sample_text = ", ".join(sample_entities)
        
        try:
            result = self.entity_recognition_chain.invoke({
                "question": question,
                "sample_entities": sample_text
            })
            entities = result.get("entities", [])
            
            # åŒ¹é…åˆ°å›¾è°±ä¸­çš„å®ä½“
            matched_entities = []
            for entity in entities:
                # ç²¾ç¡®åŒ¹é…
                if entity in self.kg.entities:
                    matched_entities.append(entity)
                else:
                    # æ¨¡ç³ŠåŒ¹é…
                    for kg_entity in self.kg.entities.keys():
                        if entity.lower() in kg_entity.lower() or kg_entity.lower() in entity.lower():
                            matched_entities.append(kg_entity)
                            break
            
            print(f"ğŸ” è¯†åˆ«åˆ°å®ä½“: {matched_entities}")
            return matched_entities
            
        except Exception as e:
            print(f"âŒ å®ä½“è¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def local_query(self, question: str, max_hops: int = 2, top_k: int = 10) -> str:
        """
        æœ¬åœ°æŸ¥è¯¢ - åŸºäºé—®é¢˜ä¸­çš„å®ä½“åŠå…¶é‚»åŸŸè¿›è¡Œæ£€ç´¢
        
        é€‚ç”¨åœºæ™¯: é’ˆå¯¹ç‰¹å®šå®ä½“çš„è¯¦ç»†é—®é¢˜
        ä¾‹å¦‚: "AlphaCodiumçš„ä½œè€…æ˜¯è°ï¼Ÿ"
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            max_hops: æœ€å¤§è·³æ•°
            top_k: è¿”å›çš„æœ€å¤§å®ä½“æ•°
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        print(f"\nğŸ” æ‰§è¡Œæœ¬åœ°æŸ¥è¯¢...")
        
        # 1. è¯†åˆ«é—®é¢˜ä¸­çš„å®ä½“
        mentioned_entities = self.recognize_entities(question)
        
        if not mentioned_entities:
            return "æœªèƒ½åœ¨çŸ¥è¯†å›¾è°±ä¸­æ‰¾åˆ°ç›¸å…³å®ä½“ã€‚"
        
        # 2. è·å–å®ä½“çš„é‚»åŸŸ
        relevant_entities = set()
        for entity in mentioned_entities:
            neighbors = self.kg.get_node_neighbors(entity, depth=max_hops)
            relevant_entities.update(neighbors)
        
        relevant_entities = list(relevant_entities)[:top_k]
        
        # 3. æ”¶é›†å®ä½“ä¿¡æ¯
        entity_info_list = []
        for entity in relevant_entities:
            info = self.kg.get_entity_info(entity)
            if info:
                entity_info_list.append(
                    f"- {info['name']} ({info.get('type', 'UNKNOWN')}): {info.get('description', 'æ— æè¿°')}"
                )
        
        # 4. æ”¶é›†å…³ç³»ä¿¡æ¯
        relation_list = []
        for u, v, data in self.kg.graph.edges(data=True):
            if u in relevant_entities and v in relevant_entities:
                relation_list.append(
                    f"- {u} --[{data.get('relation_type', 'RELATED')}]--> {v}: {data.get('description', '')}"
                )
        
        entity_info_text = "\n".join(entity_info_list) if entity_info_list else "æ— ç›¸å…³å®ä½“ä¿¡æ¯"
        relations_text = "\n".join(relation_list[:20]) if relation_list else "æ— ç›¸å…³å…³ç³»"
        
        # 5. ç”Ÿæˆç­”æ¡ˆ
        try:
            answer = self.local_query_chain.invoke({
                "question": question,
                "entity_info": entity_info_text,
                "relations": relations_text
            })
            print(f"âœ… æœ¬åœ°æŸ¥è¯¢å®Œæˆ")
            return answer.strip()
        except Exception as e:
            print(f"âŒ æœ¬åœ°æŸ¥è¯¢å¤±è´¥: {e}")
            return "æŸ¥è¯¢å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"
    
    def global_query(self, question: str, top_k_communities: int = 5) -> str:
        """
        å…¨å±€æŸ¥è¯¢ - åŸºäºç¤¾åŒºæ‘˜è¦è¿›è¡Œé«˜å±‚æ¬¡æŸ¥è¯¢
        
        é€‚ç”¨åœºæ™¯: éœ€è¦æ•´ä½“ç†è§£çš„æ¦‚æ‹¬æ€§é—®é¢˜
        ä¾‹å¦‚: "è¿™äº›æ–‡æ¡£ä¸»è¦è®¨è®ºä»€ä¹ˆä¸»é¢˜ï¼Ÿ"
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k_communities: ä½¿ç”¨çš„ç¤¾åŒºæ•°é‡
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        print(f"\nğŸŒ æ‰§è¡Œå…¨å±€æŸ¥è¯¢...")
        
        if not self.kg.community_summaries:
            return "çŸ¥è¯†å›¾è°±å°šæœªç”Ÿæˆç¤¾åŒºæ‘˜è¦ï¼Œè¯·å…ˆè¿è¡Œç´¢å¼•æµç¨‹ã€‚"
        
        # è·å–ç¤¾åŒºæ‘˜è¦
        community_summaries = []
        for cid, summary in list(self.kg.community_summaries.items())[:top_k_communities]:
            community_summaries.append(f"ç¤¾åŒº {cid}:\n{summary}\n")
        
        summaries_text = "\n".join(community_summaries)
        
        # ç”Ÿæˆç­”æ¡ˆ
        try:
            answer = self.global_query_chain.invoke({
                "question": question,
                "community_summaries": summaries_text
            })
            print(f"âœ… å…¨å±€æŸ¥è¯¢å®Œæˆ")
            return answer.strip()
        except Exception as e:
            print(f"âŒ å…¨å±€æŸ¥è¯¢å¤±è´¥: {e}")
            return "æŸ¥è¯¢å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"
    
    def hybrid_query(self, question: str) -> Dict[str, str]:
        """
        æ··åˆæŸ¥è¯¢ - åŒæ—¶æ‰§è¡Œæœ¬åœ°å’Œå…¨å±€æŸ¥è¯¢ï¼Œè¿”å›ä¸¤ç§ç»“æœ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            åŒ…å«æœ¬åœ°å’Œå…¨å±€æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        print(f"\nğŸ”€ æ‰§è¡Œæ··åˆæŸ¥è¯¢...")
        
        local_answer = self.local_query(question)
        global_answer = self.global_query(question)
        
        return {
            "local": local_answer,
            "global": global_answer,
            "question": question
        }
    
    def smart_query(self, question: str) -> str:
        """
        æ™ºèƒ½æŸ¥è¯¢ - æ ¹æ®é—®é¢˜ç±»å‹è‡ªåŠ¨é€‰æ‹©æŸ¥è¯¢ç­–ç•¥
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        # åˆ¤æ–­é—®é¢˜ç±»å‹
        question_lower = question.lower()
        
        # åŒ…å«å…·ä½“å®ä½“åç§°çš„é—®é¢˜ -> æœ¬åœ°æŸ¥è¯¢
        mentioned_entities = self.recognize_entities(question)
        if mentioned_entities:
            print("ğŸ“ æ£€æµ‹åˆ°å…·ä½“å®ä½“ï¼Œä½¿ç”¨æœ¬åœ°æŸ¥è¯¢")
            return self.local_query(question)
        
        # æ¦‚æ‹¬æ€§é—®é¢˜ -> å…¨å±€æŸ¥è¯¢
        global_keywords = ["ä¸»è¦", "æ€»ä½“", "æ¦‚è¿°", "æ•´ä½“", "ä¸»é¢˜", "è®¨è®º", "å†…å®¹", "what", "overview", "main", "topics"]
        if any(keyword in question_lower for keyword in global_keywords):
            print("ğŸŒ æ£€æµ‹åˆ°æ¦‚æ‹¬æ€§é—®é¢˜ï¼Œä½¿ç”¨å…¨å±€æŸ¥è¯¢")
            return self.global_query(question)
        
        # é»˜è®¤ä½¿ç”¨æœ¬åœ°æŸ¥è¯¢
        print("ğŸ“ ä½¿ç”¨æœ¬åœ°æŸ¥è¯¢ä½œä¸ºé»˜è®¤ç­–ç•¥")
        return self.local_query(question)


def initialize_graph_retriever(knowledge_graph: KnowledgeGraph):
    """åˆå§‹åŒ–GraphRAGæ£€ç´¢å™¨"""
    return GraphRetriever(knowledge_graph)
