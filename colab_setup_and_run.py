#!/usr/bin/env python3
"""
Google Colabç¯å¢ƒä¸‹çš„GraphRAGå®Œæ•´è¿è¡Œè„šæœ¬
è§£å†³OllamaæœåŠ¡å¯åŠ¨å’ŒGraphRAGè¿è¡Œçš„é—®é¢˜

ä½¿ç”¨æ–¹æ³•:
1. åœ¨Colabä¸­å¯ç”¨GPU
2. å¤åˆ¶æ­¤æ–‡ä»¶åˆ°Colab
3. è¿è¡Œ: !python colab_setup_and_run.py
"""

import os
import sys
import time
import subprocess
import signal
from pathlib import Path

print("="*70)
print("ğŸš€ GraphRAG Colab è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬")
print("="*70)

# ============================================================
# 1ï¸âƒ£ æ£€æµ‹Colabç¯å¢ƒ
# ============================================================
def check_colab_environment():
    """æ£€æµ‹æ˜¯å¦åœ¨Colabç¯å¢ƒä¸­"""
    try:
        import google.colab
        print("\nâœ… è¿è¡Œç¯å¢ƒ: Google Colab")
        return True
    except ImportError:
        print("\nâš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°Colabç¯å¢ƒ")
        print("   æœ¬è„šæœ¬ä¸ºColabä¼˜åŒ–ï¼Œåœ¨å…¶ä»–ç¯å¢ƒå¯èƒ½éœ€è¦è°ƒæ•´")
        return False

# ============================================================
# 2ï¸âƒ£ å®‰è£…Ollama
# ============================================================
def install_ollama():
    """åœ¨Colabä¸­å®‰è£…Ollama"""
    print("\n" + "="*70)
    print("ğŸ“¦ æ­¥éª¤1: å®‰è£…Ollama")
    print("="*70)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
    if os.path.exists("/usr/local/bin/ollama"):
        print("âœ… Ollamaå·²å®‰è£…")
        return True
    
    print("\nğŸ“¥ ä¸‹è½½å¹¶å®‰è£…Ollama...")
    try:
        # ä¸‹è½½Ollamaå®‰è£…è„šæœ¬
        subprocess.run(
            ["curl", "-fsSL", "https://ollama.com/install.sh", "-o", "/tmp/install_ollama.sh"],
            check=True,
            capture_output=True
        )
        
        # æ‰§è¡Œå®‰è£…
        subprocess.run(
            ["sh", "/tmp/install_ollama.sh"],
            check=True,
            capture_output=True
        )
        
        print("âœ… Ollamaå®‰è£…æˆåŠŸ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Ollamaå®‰è£…å¤±è´¥: {e}")
        return False

# ============================================================
# 3ï¸âƒ£ åå°å¯åŠ¨OllamaæœåŠ¡
# ============================================================
def start_ollama_service():
    """åœ¨åå°å¯åŠ¨OllamaæœåŠ¡"""
    print("\n" + "="*70)
    print("ğŸ”§ æ­¥éª¤2: å¯åŠ¨OllamaæœåŠ¡")
    print("="*70)
    
    print("\nğŸ”„ åœ¨åå°å¯åŠ¨OllamaæœåŠ¡...")
    
    # æ–¹æ³•1: ä½¿ç”¨subprocessåå°è¿è¡Œ
    try:
        # å¯åŠ¨OllamaæœåŠ¡ï¼ˆåå°ï¼‰
        ollama_process = subprocess.Popen(
            ["ollama", "serve"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            preexec_fn=os.setpgrp  # åˆ›å»ºæ–°çš„è¿›ç¨‹ç»„
        )
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        print("â³ ç­‰å¾…OllamaæœåŠ¡å¯åŠ¨...")
        time.sleep(5)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
        try:
            result = subprocess.run(
                ["curl", "-s", "http://localhost:11434/api/tags"],
                capture_output=True,
                timeout=3
            )
            
            if result.returncode == 0:
                print("âœ… OllamaæœåŠ¡å·²å¯åŠ¨ (PID: {})".format(ollama_process.pid))
                
                # ä¿å­˜è¿›ç¨‹IDä»¥ä¾¿åç»­ç®¡ç†
                with open("/tmp/ollama.pid", "w") as f:
                    f.write(str(ollama_process.pid))
                
                return ollama_process
            else:
                print("âš ï¸  æœåŠ¡å¯åŠ¨å¯èƒ½æœ‰é—®é¢˜ï¼Œç»§ç»­å°è¯•...")
                
        except subprocess.TimeoutExpired:
            print("âš ï¸  æœåŠ¡æ£€æŸ¥è¶…æ—¶ï¼Œä½†è¿›ç¨‹å·²å¯åŠ¨")
            return ollama_process
            
    except Exception as e:
        print(f"âŒ å¯åŠ¨Ollamaå¤±è´¥: {e}")
        return None

# ============================================================
# 4ï¸âƒ£ ä¸‹è½½Mistralæ¨¡å‹
# ============================================================
def pull_mistral_model():
    """ä¸‹è½½Mistralæ¨¡å‹"""
    print("\n" + "="*70)
    print("ğŸ“¥ æ­¥éª¤3: ä¸‹è½½Mistralæ¨¡å‹")
    print("="*70)
    
    print("\nğŸ”„ æ‹‰å–mistralæ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        result = subprocess.run(
            ["ollama", "list"],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if "mistral" in result.stdout:
            print("âœ… Mistralæ¨¡å‹å·²å­˜åœ¨")
            return True
        
        # ä¸‹è½½æ¨¡å‹
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½Mistralæ¨¡å‹...")
        process = subprocess.Popen(
            ["ollama", "pull", "mistral"],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True
        )
        
        # å®æ—¶æ˜¾ç¤ºä¸‹è½½è¿›åº¦
        for line in process.stdout:
            print(f"   {line.strip()}")
        
        process.wait()
        
        if process.returncode == 0:
            print("âœ… Mistralæ¨¡å‹ä¸‹è½½å®Œæˆ")
            return True
        else:
            print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½Mistralæ¨¡å‹å¤±è´¥: {e}")
        return False

# ============================================================
# 5ï¸âƒ£ å®‰è£…Pythonä¾èµ–
# ============================================================
def install_python_dependencies():
    """å®‰è£…GraphRAGæ‰€éœ€çš„PythonåŒ…"""
    print("\n" + "="*70)
    print("ğŸ“¦ æ­¥éª¤4: å®‰è£…Pythonä¾èµ–")
    print("="*70)
    
    packages = [
        "langchain",
        "langchain-community",
        "langchain-core",
        "langgraph",
        "langchain-ollama",
        "chromadb",
        "sentence-transformers",
        "tiktoken",
        "beautifulsoup4",
        "requests",
        "tavily-python",
        "python-dotenv",
        "networkx",
        "python-louvain",
        "torch",
        "transformers"
    ]
    
    print("\nğŸ“¥ å®‰è£…å¿…è¦çš„PythonåŒ…...")
    for package in packages:
        try:
            __import__(package.replace("-", "_"))
            print(f"âœ… {package} å·²å®‰è£…")
        except ImportError:
            print(f"ğŸ“¥ å®‰è£… {package}...")
            subprocess.run(
                [sys.executable, "-m", "pip", "install", "-q", package],
                check=True
            )
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ")

# ============================================================
# 6ï¸âƒ£ é…ç½®ç¯å¢ƒå˜é‡
# ============================================================
def setup_environment():
    """é…ç½®ç¯å¢ƒå˜é‡"""
    print("\n" + "="*70)
    print("ğŸ”‘ æ­¥éª¤5: é…ç½®ç¯å¢ƒå˜é‡")
    print("="*70)
    
    # æ£€æŸ¥.envæ–‡ä»¶
    if os.path.exists(".env"):
        print("\nâœ… å‘ç°.envæ–‡ä»¶ï¼ŒåŠ è½½é…ç½®...")
        from dotenv import load_dotenv
        load_dotenv()
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ°.envæ–‡ä»¶")
        
        # äº¤äº’å¼è¾“å…¥APIå¯†é’¥
        if "TAVILY_API_KEY" not in os.environ:
            from getpass import getpass
            api_key = getpass("è¯·è¾“å…¥TAVILY_API_KEY (æˆ–æŒ‰Enterè·³è¿‡): ")
            if api_key:
                os.environ["TAVILY_API_KEY"] = api_key
                print("âœ… TAVILY_API_KEYå·²è®¾ç½®")
            else:
                print("âš ï¸  è·³è¿‡TAVILY_API_KEYè®¾ç½®ï¼ˆç½‘ç»œæœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨ï¼‰")
    
    print("\nğŸ“‹ å½“å‰ç¯å¢ƒå˜é‡:")
    print(f"   TAVILY_API_KEY: {'å·²è®¾ç½®' if os.environ.get('TAVILY_API_KEY') else 'æœªè®¾ç½®'}")

# ============================================================
# 7ï¸âƒ£ è¿è¡ŒGraphRAG
# ============================================================
def run_graphrag():
    """è¿è¡ŒGraphRAGä¸»ç¨‹åº"""
    print("\n" + "="*70)
    print("ğŸš€ æ­¥éª¤6: è¿è¡ŒGraphRAG")
    print("="*70)
    
    # æ£€æŸ¥main_graphrag.pyæ˜¯å¦å­˜åœ¨
    if not os.path.exists("main_graphrag.py"):
        print("\nâŒ æœªæ‰¾åˆ°main_graphrag.pyæ–‡ä»¶")
        print("   è¯·ç¡®ä¿å·²ä¸Šä¼ é¡¹ç›®æ–‡ä»¶åˆ°Colab")
        return False
    
    print("\nğŸ”„ å¯åŠ¨GraphRAGç´¢å¼•æ„å»º...\n")
    
    try:
        # è¿è¡ŒGraphRAG
        result = subprocess.run(
            [sys.executable, "main_graphrag.py"],
            capture_output=False,  # å®æ—¶è¾“å‡º
            text=True
        )
        
        if result.returncode == 0:
            print("\nâœ… GraphRAGè¿è¡ŒæˆåŠŸ!")
            return True
        else:
            print(f"\nâŒ GraphRAGè¿è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode})")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return False
    except Exception as e:
        print(f"\nâŒ è¿è¡ŒGraphRAGæ—¶å‡ºé”™: {e}")
        return False

# ============================================================
# 8ï¸âƒ£ æ¸…ç†å‡½æ•°
# ============================================================
def cleanup():
    """æ¸…ç†åå°è¿›ç¨‹"""
    print("\n" + "="*70)
    print("ğŸ§¹ æ¸…ç†åå°è¿›ç¨‹")
    print("="*70)
    
    # åœæ­¢OllamaæœåŠ¡
    if os.path.exists("/tmp/ollama.pid"):
        try:
            with open("/tmp/ollama.pid", "r") as f:
                pid = int(f.read().strip())
            
            os.kill(pid, signal.SIGTERM)
            print(f"âœ… OllamaæœåŠ¡å·²åœæ­¢ (PID: {pid})")
            os.remove("/tmp/ollama.pid")
            
        except Exception as e:
            print(f"âš ï¸  åœæ­¢OllamaæœåŠ¡å¤±è´¥: {e}")

# ============================================================
# ä¸»å‡½æ•°
# ============================================================
def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    ollama_process = None
    
    try:
        # 1. æ£€æµ‹ç¯å¢ƒ
        is_colab = check_colab_environment()
        
        # 2. å®‰è£…Ollama
        if not install_ollama():
            print("\nâŒ Ollamaå®‰è£…å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return
        
        # 3. å¯åŠ¨OllamaæœåŠ¡
        ollama_process = start_ollama_service()
        if not ollama_process:
            print("\nâŒ OllamaæœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return
        
        # 4. ä¸‹è½½æ¨¡å‹
        if not pull_mistral_model():
            print("\nâŒ Mistralæ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return
        
        # 5. å®‰è£…Pythonä¾èµ–
        install_python_dependencies()
        
        # 6. é…ç½®ç¯å¢ƒ
        setup_environment()
        
        # 7. è¿è¡ŒGraphRAG
        success = run_graphrag()
        
        if success:
            print("\n" + "="*70)
            print("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
            print("="*70)
            
            print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
            if os.path.exists("data/knowledge_graph.json"):
                print("   âœ… data/knowledge_graph.json")
                
                # æä¾›ä¸‹è½½é€‰é¡¹
                if is_colab:
                    print("\nğŸ’¾ ä¸‹è½½ç»“æœ:")
                    print("   from google.colab import files")
                    print("   files.download('data/knowledge_graph.json')")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # æ¸…ç†
        print("\nâš ï¸  æ³¨æ„: OllamaæœåŠ¡ä»åœ¨åå°è¿è¡Œ")
        print("   å¦‚éœ€åœæ­¢: !pkill -f 'ollama serve'")
        print("   æˆ–è¿è¡Œ: cleanup()")

if __name__ == "__main__":
    main()
