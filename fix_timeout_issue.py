"""
ä¸´æ—¶ä¿®å¤è¶…æ—¶é—®é¢˜çš„è„šæœ¬
åœ¨ Colab ä¸­è¿è¡Œæ­¤è„šæœ¬æ¥å¢åŠ è¶…æ—¶æ—¶é—´
"""

import sys
import os

# ç¡®ä¿è·¯å¾„æ­£ç¡®
sys.path.insert(0, '/content/drive/MyDrive/adaptive_RAG')

print("ğŸ”§ ä¿®å¤è¶…æ—¶é—®é¢˜...")
print("="*60)

# æ–¹æ¡ˆ 1: ä¿®æ”¹ entity_extractor çš„è¶…æ—¶è®¾ç½®
print("\nğŸ“ æ–¹æ¡ˆ 1: å¢åŠ è¶…æ—¶æ—¶é—´å’Œé‡è¯•æ¬¡æ•°")
print("-"*60)

# é‡æ–°å¯¼å…¥å¹¶ä¿®æ”¹
from entity_extractor import EntityExtractor, EntityDeduplicator
from graph_indexer import GraphRAGIndexer

# åˆ›å»ºè‡ªå®šä¹‰çš„ GraphRAG ç´¢å¼•å™¨ï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶
class GraphRAGIndexerWithLongerTimeout(GraphRAGIndexer):
    """å¢åŠ è¶…æ—¶æ—¶é—´çš„ GraphRAG ç´¢å¼•å™¨"""
    
    def __init__(self, timeout=180, max_retries=5):
        """
        åˆå§‹åŒ–ç´¢å¼•å™¨ï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤180ç§’ï¼ˆ3åˆ†é’Ÿï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤5æ¬¡
        """
        print(f"ğŸš€ åˆå§‹åŒ–GraphRAGç´¢å¼•å™¨ï¼ˆè¶…æ—¶: {timeout}ç§’, é‡è¯•: {max_retries}æ¬¡ï¼‰...")
        
        # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶åˆå§‹åŒ–å®ä½“æå–å™¨
        self.entity_extractor = EntityExtractor(
            timeout=timeout,
            max_retries=max_retries
        )
        self.entity_deduplicator = EntityDeduplicator()
        
        # å¯¼å…¥å…¶ä»–å¿…è¦çš„ç±»
        from knowledge_graph import KnowledgeGraph, CommunitySummarizer
        self.knowledge_graph = KnowledgeGraph()
        self.community_summarizer = CommunitySummarizer()
        
        self.indexed = False
        
        print("âœ… GraphRAGç´¢å¼•å™¨åˆå§‹åŒ–å®Œæˆ")


# æ–¹æ¡ˆ 2: æä¾›å¿«é€Ÿé‡å¯è„šæœ¬
print("\nğŸ“ æ–¹æ¡ˆ 2: é‡å¯ Ollama æœåŠ¡")
print("-"*60)
print("è¿è¡Œä»¥ä¸‹å‘½ä»¤:")
print("  !pkill -9 ollama")
print("  !sleep 2")
print("  !nohup ollama serve > /tmp/ollama.log 2>&1 &")
print("  !sleep 5")
print("  !curl http://localhost:11434/api/tags")


# æ–¹æ¡ˆ 3: è·³è¿‡å½“å‰æ–‡æ¡£
print("\nğŸ“ æ–¹æ¡ˆ 3: è·³è¿‡é—®é¢˜æ–‡æ¡£å¹¶ç»§ç»­")
print("-"*60)
print("å¦‚æœæŸä¸ªæ–‡æ¡£æŒç»­å¤±è´¥ï¼Œå¯ä»¥è·³è¿‡å®ƒ:")
print("""
# ç¤ºä¾‹ï¼šä»æ–‡æ¡£ #57 å¼€å§‹ç»§ç»­å¤„ç†
problem_doc_index = 55  # æ–‡æ¡£ #56 çš„ç´¢å¼•
doc_splits_filtered = doc_splits[:problem_doc_index] + doc_splits[problem_doc_index+1:]

# ä½¿ç”¨è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨
graph = indexer.index_documents(
    documents=doc_splits_filtered,
    batch_size=3
)
""")


# ä½¿ç”¨ç¤ºä¾‹
print("\n" + "="*60)
print("âœ… ä¿®å¤æ–¹æ¡ˆå‡†å¤‡å®Œæˆ")
print("="*60)
print("\nğŸ’¡ æ¨èçš„ä½¿ç”¨æ–¹æ³•:")
print("-"*60)

usage_example = """
# 1. å¯¼å…¥ä¿®å¤åçš„ç´¢å¼•å™¨
from fix_timeout_issue import GraphRAGIndexerWithLongerTimeout

# 2. ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆ3åˆ†é’Ÿï¼‰åˆ›å»ºç´¢å¼•å™¨
indexer = GraphRAGIndexerWithLongerTimeout(
    timeout=180,      # 3åˆ†é’Ÿè¶…æ—¶
    max_retries=5     # 5æ¬¡é‡è¯•
)

# 3. å‡å°æ‰¹æ¬¡å¤§å°ï¼Œç»§ç»­å¤„ç†
# å¦‚æœå·²ç»å¤„ç†äº†éƒ¨åˆ†æ–‡æ¡£ï¼Œå¯ä»¥è·³è¿‡å®ƒä»¬
processed_count = 55  # å·²å¤„ç†åˆ°æ–‡æ¡£ #55

remaining_docs = doc_splits[processed_count:]

graph = indexer.index_documents(
    documents=remaining_docs,
    batch_size=3,  # æ›´å°çš„æ‰¹æ¬¡
    save_path="/content/drive/MyDrive/knowledge_graph.pkl"
)

# 4. å¦‚æœè¿˜æ˜¯è¶…æ—¶ï¼Œè€ƒè™‘è·³è¿‡é—®é¢˜æ–‡æ¡£
# problem_indices = [55]  # æ–‡æ¡£ #56 çš„ç´¢å¼•
# remaining_docs_filtered = [doc for i, doc in enumerate(doc_splits[processed_count:]) 
#                            if (processed_count + i) not in problem_indices]
"""

print(usage_example)

print("\n" + "="*60)
print("ğŸ¯ ç«‹å³æ‰§è¡Œçš„æ­¥éª¤:")
print("="*60)
print("""
1ï¸âƒ£ é¦–å…ˆé‡å¯ Ollama æœåŠ¡:
   !pkill -9 ollama && sleep 2 && nohup ollama serve > /tmp/ollama.log 2>&1 & && sleep 5

2ï¸âƒ£ ç„¶åä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´ç»§ç»­:
   from fix_timeout_issue import GraphRAGIndexerWithLongerTimeout
   indexer = GraphRAGIndexerWithLongerTimeout(timeout=180, max_retries=5)
   
3ï¸âƒ£ ä»æ–‡æ¡£ #56 ç»§ç»­å¤„ç†ï¼ˆå‡å°æ‰¹æ¬¡å¤§å°ï¼‰:
   remaining_docs = doc_splits[55:]  # ä»æ–‡æ¡£ #56 å¼€å§‹
   graph = indexer.index_documents(remaining_docs, batch_size=3)

4ï¸âƒ£ å¦‚æœæ–‡æ¡£ #56 ä»ç„¶è¶…æ—¶ï¼Œè·³è¿‡å®ƒ:
   remaining_docs = doc_splits[56:]  # è·³è¿‡æ–‡æ¡£ #56ï¼Œä» #57 å¼€å§‹
   graph = indexer.index_documents(remaining_docs, batch_size=3)
""")

print("\nâš ï¸ æ³¨æ„:")
print("  â€¢ è¶…æ—¶é€šå¸¸è¯´æ˜æ–‡æ¡£å†…å®¹å¤æ‚æˆ– Ollama è´Ÿè½½è¿‡é‡")
print("  â€¢ é‡å¯ Ollama é€šå¸¸èƒ½è§£å†³è´Ÿè½½é—®é¢˜")
print("  â€¢ å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆ180ç§’ï¼‰èƒ½å¤„ç†å¤æ‚æ–‡æ¡£")
print("  â€¢ å‡å°æ‰¹æ¬¡å¤§å°ï¼ˆ3ä¸ªæ–‡æ¡£/æ‰¹æ¬¡ï¼‰èƒ½å‡è½»è´Ÿè½½")
print("  â€¢ å¦‚æœæŸä¸ªæ–‡æ¡£æŒç»­å¤±è´¥ï¼Œå¯ä»¥è€ƒè™‘è·³è¿‡å®ƒ")
