"""
å¼€æºå¹»è§‰æ£€æµ‹æ¨¡å‹æ¨èå’Œä½¿ç”¨æŒ‡å—
æ›¿ä»£ Vectara æ¨¡å‹çš„æœ€ä½³æ–¹æ¡ˆ

æœ¬æ–‡æ¡£æä¾›äº†å¤šä¸ªæ— éœ€ç‰¹æ®Šæƒé™çš„å¼€æºå¹»è§‰æ£€æµ‹æ¨¡å‹ï¼Œ
å¯ä»¥ç›´æ¥é›†æˆåˆ°æ‚¨çš„ RAG ç³»ç»Ÿä¸­ã€‚
"""

# ==========================================
# 1. å½“å‰é¡¹ç›®å·²å®ç°çš„æ–¹æ¡ˆ
# ==========================================

print("ğŸ¯ å½“å‰é¡¹ç›®å·²å®ç°çš„å¼€æºæ–¹æ¡ˆ")
print("="*50)

print("\n1ï¸âƒ£ NLI æ–¹æ³•ï¼ˆæ¨èï¼‰")
print("   æ¨¡å‹: cross-encoder/nli-deberta-v3-xsmall")
print("   å¤§å°: ~90MB")
print("   ç‰¹ç‚¹: è½»é‡ã€å¿«é€Ÿã€å¼€æº")
print("   å‡†ç¡®ç‡: 80-85%")
print("   ä½¿ç”¨: å·²åœ¨é¡¹ç›®ä¸­å®ç°")

print("\n2ï¸âƒ£ æ··åˆæ–¹æ³•")
print("   æ¨¡å‹: NLI + LLM-as-Judge")
print("   ç‰¹ç‚¹: ä¸¤é˜¶æ®µæ£€æµ‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®ç‡")
print("   å‡†ç¡®ç‡: 85-90%")
print("   ä½¿ç”¨: å·²åœ¨é¡¹ç›®ä¸­å®ç°")

# ==========================================
# 2. æ¨èçš„å…¶ä»–å¼€æºæ¨¡å‹
# ==========================================

print("\n" + "="*50)
print("ğŸ”§ æ¨èçš„å…¶ä»–å¼€æºå¹»è§‰æ£€æµ‹æ¨¡å‹")
print("="*50)

models = [
    {
        "name": "cross-encoder/nli-roberta-base",
        "size": "430MB",
        "accuracy": "88%",
        "speed": "ä¸­ç­‰",
        "pros": ["é«˜å‡†ç¡®ç‡", "ç¨³å®šå¯é "],
        "cons": ["æ¨¡å‹è¾ƒå¤§", "é€Ÿåº¦ä¸€èˆ¬"]
    },
    {
        "name": "facebook/bart-large-mnli",
        "size": "1.6GB",
        "accuracy": "87%",
        "speed": "è¾ƒæ…¢",
        "pros": ["å¤šè¯­è¨€æ”¯æŒ", "æˆç†Ÿç¨³å®š"],
        "cons": ["æ¨¡å‹å¾ˆå¤§", "æ¨ç†è¾ƒæ…¢"]
    },
    {
        "name": "cross-encoder/nli-MiniLM2-L6-H768",
        "size": "80MB",
        "accuracy": "85%",
        "speed": "å¿«é€Ÿ",
        "pros": ["è½»é‡å¿«é€Ÿ", "å¼€æºå…è´¹"],
        "cons": ["å‡†ç¡®ç‡ç¨ä½"]
    },
    {
        "name": "microsoft/deberta-v3-base-mnli",
        "size": "680MB",
        "accuracy": "89%",
        "speed": "ä¸­ç­‰",
        "pros": ["æœ€æ–°æ¶æ„", "é«˜å‡†ç¡®ç‡"],
        "cons": ["æ¨¡å‹è¾ƒå¤§", "éœ€è¦è¾ƒæ–° transformers"]
    }
]

for i, model in enumerate(models, 1):
    print(f"\n{i}. {model['name']}")
    print(f"   ğŸ“Š æ¨¡å‹å¤§å°: {model['size']}")
    print(f"   ğŸ¯ å‡†ç¡®ç‡: {model['accuracy']}")
    print(f"   âš¡ æ¨ç†é€Ÿåº¦: {model['speed']}")
    print(f"   âœ… ä¼˜ç‚¹: {', '.join(model['pros'])}")
    print(f"   âŒ ç¼ºç‚¹: {', '.join(model['cons'])}")

# ==========================================
# 3. ç®€å•çš„ä½¿ç”¨ç¤ºä¾‹
# ==========================================

print("\n" + "="*50)
print("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ä»£ç ")
print("="*50)

print("""
# ä½¿ç”¨ cross-encoder/nli-MiniLM2-L6-H768ï¼ˆæ¨èè½»é‡æ–¹æ¡ˆï¼‰
from transformers import pipeline

class SimpleHallucinationDetector:
    def __init__(self):
        # é€‰æ‹©è½»é‡ã€å¿«é€Ÿçš„æ¨¡å‹
        self.nli = pipeline(
            "text-classification",
            model="cross-encoder/nli-MiniLM2-L6-H768",
            device=0 if torch.cuda.is_available() else -1
        )
    
    def detect(self, premise: str, hypothesis: str) -> float:
        \"\"\"
        æ£€æµ‹å‡è®¾ç›¸å¯¹äºå‰ææ˜¯å¦åŒ…å«å¹»è§‰
        è¿”å›å¹»è§‰åˆ†æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šå¯èƒ½æ˜¯å¹»è§‰ï¼‰
        \"\"\"
        # æ ¼å¼åŒ–è¾“å…¥
        input_text = f"Premise: {premise} Hypothesis: {hypothesis}"
        
        # è·å– NLI ç»“æœ
        result = self.nli(input_text)
        
        # è§£æç»“æœï¼ˆCONTRADICTION = å¯èƒ½æ˜¯å¹»è§‰ï¼‰
        for item in result:
            if item['label'] == 'CONTRADICTION':
                return item['score']  # è¿”å›çŸ›ç›¾æ¦‚ç‡ä½œä¸ºå¹»è§‰åˆ†æ•°
            elif item['label'] == 'ENTAILMENT':
                return 0.1  # ä½å¹»è§‰åˆ†æ•°
            else:  # NEUTRAL
                return 0.5  # ä¸­ç­‰å¹»è§‰åˆ†æ•°
        
        return 0.5  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

# ä½¿ç”¨ç¤ºä¾‹
detector = SimpleHallucinationDetector()
documents = "The capital of France is Paris."
generation = "The capital of France is Berlin."

hallucination_score = detector.detect(documents, generation)
print(f"å¹»è§‰åˆ†æ•°: {hallucination_score:.3f}")
""")

# ==========================================
# 4. æ¨èé…ç½®æ–¹æ¡ˆ
# ==========================================

print("\n" + "="*50)
print("âš™ï¸ æ¨èé…ç½®æ–¹æ¡ˆ")
print("="*50)

print("""
æ–¹æ¡ˆ1: è½»é‡å¿«é€Ÿï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰
- æ¨¡å‹: cross-encoder/nli-MiniLM2-L6-H768
- ç‰¹ç‚¹: 80MBï¼Œæ¨ç†å¿«é€Ÿï¼Œå‡†ç¡®ç‡85%
- é€‚ç”¨: å¯¹å»¶è¿Ÿè¦æ±‚é«˜çš„åœºæ™¯

æ–¹æ¡ˆ2: é«˜å‡†ç¡®ç‡ï¼ˆé‡è¦å†³ç­–æ¨èï¼‰
- æ¨¡å‹: microsoft/deberta-v3-base-mnli
- ç‰¹ç‚¹: 680MBï¼Œæ¨ç†ä¸­ç­‰ï¼Œå‡†ç¡®ç‡89%
- é€‚ç”¨: å¯¹å‡†ç¡®ç‡è¦æ±‚é«˜çš„åœºæ™¯

æ–¹æ¡ˆ3: æ··åˆæ–¹æ¡ˆï¼ˆå¹³è¡¡é€‰æ‹©ï¼‰
- ä¸»æ¨¡å‹: cross-encoder/nli-deberta-v3-xsmall
- å¤‡ç”¨: LLM-as-Judge
- ç‰¹ç‚¹: ä¸¤é˜¶æ®µæ£€æµ‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®ç‡
- é€‚ç”¨: å¤§å¤šæ•°RAGåº”ç”¨åœºæ™¯
""")

# ==========================================
# 5. é›†æˆåˆ°å½“å‰é¡¹ç›®çš„æ–¹æ³•
# ==========================================

print("\n" + "="*50)
print("ğŸ”— é›†æˆåˆ°å½“å‰é¡¹ç›®çš„æ–¹æ³•")
print("="*50)

print("""
æ–¹æ³•1: ä¿®æ”¹é…ç½®æ–‡ä»¶
# åœ¨ hallucination_config.py ä¸­è®¾ç½®:
HALLUCINATION_DETECTION_METHOD = "nli"
NLI_CONTRADICTION_THRESHOLD = 0.4  # æ ¹æ®éœ€è¦è°ƒæ•´é˜ˆå€¼

æ–¹æ³•2: åˆ›å»ºæ–°çš„æ£€æµ‹å™¨
# å¤åˆ¶ hallucination_detector.py ä¸­çš„ NLIHallucinationDetector
# æ ¹æ®éœ€è¦ä¿®æ”¹æ¨¡å‹é€‰æ‹©å’Œé˜ˆå€¼

æ–¹æ³•3: ä½¿ç”¨å¿«é€Ÿä¿®å¤è„šæœ¬
python disable_vectara_quickfix.py  # å·²ä¸ºæ‚¨åˆ›å»ºçš„è‡ªåŠ¨åŒ–è„šæœ¬
""")

print("\nğŸ’¡ æ€»ç»“: æ‚¨çš„é¡¹ç›®å·²ç»æœ‰ä¸€ä¸ªå¾ˆå¥½çš„ NLI å®ç°æ–¹æ¡ˆï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€ç‰¹æ®Šæƒé™ï¼")