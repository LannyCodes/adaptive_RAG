"""
Kaggle Ollama åŠ è½½è„šæœ¬
ä» Kaggle Dataset å¿«é€ŸåŠ è½½ Ollama å’Œæ¨¡å‹ï¼Œæ— éœ€é‡æ–°ä¸‹è½½

å‰ç½®æ¡ä»¶:
1. å·²ä½¿ç”¨ KAGGLE_SAVE_OLLAMA.py åˆ›å»ºå¤‡ä»½
2. å·²åœ¨ Kaggle ä¸Šä¼  Dataset
3. å·²åœ¨ Notebook ä¸­æ·»åŠ è¯¥ Dataset

ä½¿ç”¨æ–¹æ³•:
åœ¨ Kaggle Notebook ç¬¬ä¸€ä¸ªå•å…ƒæ ¼è¿è¡Œ:
    exec(open('/kaggle/working/adaptive_RAG/KAGGLE_LOAD_OLLAMA.py').read())
"""

import os
import subprocess
import tarfile
import shutil
import time

print("="*70)
print("ğŸ“¦ ä» Dataset åŠ è½½ Ollamaï¼ˆå¿«é€Ÿå¯åŠ¨ï¼‰")
print("="*70)

# ==================== é…ç½® ====================
# ä¿®æ”¹ä¸ºä½ çš„ Dataset åç§°
# å¸¸è§åç§°: ollama-mistral-backup, ollama-phi-backup, ollama-backup ç­‰
DATASET_NAME = "ollama-mistral-backup"  # ğŸ‘ˆ ä¿®æ”¹è¿™é‡Œä¸ºä½ çš„å®é™… Dataset åç§°
DATASET_PATH = f"/kaggle/input/{DATASET_NAME}"

print(f"ğŸ’¡ æç¤º: å¦‚æœ Dataset ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥:")
print(f"   1. Dataset æ˜¯å¦å·²æ·»åŠ åˆ° Notebook")
print(f"   2. Dataset åç§°æ˜¯å¦æ­£ç¡®")
print(f"   3. å¯ç”¨çš„ Datasets:")
import os
if os.path.exists("/kaggle/input"):
    available = os.listdir("/kaggle/input")
    if available:
        for ds in available:
            print(f"      â€¢ {ds}")
    else:
        print(f"      ï¼ˆæ— ï¼‰")
print()

print(f"\nğŸ“‹ é…ç½®:")
print(f"   Dataset è·¯å¾„: {DATASET_PATH}")

# ==================== æ£€æŸ¥ Dataset ====================
print(f"\nğŸ” æ­¥éª¤ 1/5: æ£€æŸ¥ Dataset...")

if not os.path.exists(DATASET_PATH):
    print(f"   âŒ Dataset ä¸å­˜åœ¨: {DATASET_PATH}")
    print(f"\nğŸ’¡ è¯·æ£€æŸ¥:")
    print(f"   1. Dataset æ˜¯å¦å·²æ·»åŠ åˆ° Notebook")
    print(f"   2. Dataset åç§°æ˜¯å¦æ­£ç¡®")
    print(f"   3. å¯ç”¨çš„ Datasets:")
    
    if os.path.exists("/kaggle/input"):
        for item in os.listdir("/kaggle/input"):
            print(f"      â€¢ {item}")
    
    print(f"\nğŸ“ å¦‚ä½•æ·»åŠ  Dataset:")
    print(f"   1. ç‚¹å‡»å³ä¾§ 'Add data' æŒ‰é’®")
    print(f"   2. é€‰æ‹© 'Your Datasets'")
    print(f"   3. æ‰¾åˆ°ä½ çš„ ollama å¤‡ä»½ Dataset")
    print(f"   4. ç‚¹å‡» 'Add'")
    
    exit(1)

print(f"   âœ… Dataset å­˜åœ¨")

# åˆ—å‡º Dataset å†…å®¹
print(f"\n   Dataset å†…å®¹:")
for item in os.listdir(DATASET_PATH):
    item_path = os.path.join(DATASET_PATH, item)
    if os.path.isfile(item_path):
        size = os.path.getsize(item_path)
        size_str = f"{size / (1024**3):.2f} GB" if size > 1024**3 else f"{size / (1024**2):.2f} MB"
        print(f"      â€¢ {item}: {size_str}")

# ==================== å®‰è£… Ollama äºŒè¿›åˆ¶æ–‡ä»¶ ====================
print(f"\nğŸ”§ æ­¥éª¤ 2/5: å®‰è£… Ollama äºŒè¿›åˆ¶æ–‡ä»¶...")

ollama_bin_source = os.path.join(DATASET_PATH, "ollama")

if os.path.exists(ollama_bin_source):
    # å…ˆåœæ­¢å¯èƒ½æ­£åœ¨è¿è¡Œçš„ Ollama æœåŠ¡
    print(f"   ğŸ›‘ æ£€æŸ¥å¹¶åœæ­¢ç°æœ‰ Ollama è¿›ç¨‹...")
    subprocess.run(['pkill', '-9', 'ollama'], capture_output=True)
    time.sleep(2)
    
    # å¤åˆ¶åˆ°ç³»ç»Ÿè·¯å¾„
    ollama_bin_dest = "/usr/local/bin/ollama"
    
    try:
        shutil.copy2(ollama_bin_source, ollama_bin_dest)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(ollama_bin_dest, 0o755)
        
        print(f"   âœ… Ollama å·²å®‰è£…åˆ°: {ollama_bin_dest}")
        
        # éªŒè¯ç‰ˆæœ¬
        version_result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        if version_result.returncode == 0:
            print(f"   ğŸ“Œ {version_result.stdout.strip()}")
    except OSError as e:
        if "Text file busy" in str(e):
            print(f"   âš ï¸ æ–‡ä»¶è¢«å ç”¨ï¼Œå°è¯•å¼ºåˆ¶åœæ­¢...")
            subprocess.run(['killall', '-9', 'ollama'], capture_output=True)
            time.sleep(3)
            # é‡è¯•
            shutil.copy2(ollama_bin_source, ollama_bin_dest)
            os.chmod(ollama_bin_dest, 0o755)
            print(f"   âœ… Ollama å·²å®‰è£…ï¼ˆé‡è¯•æˆåŠŸï¼‰")
        else:
            raise
else:
    print(f"   âŒ æœªæ‰¾åˆ° Ollama äºŒè¿›åˆ¶æ–‡ä»¶")
    exit(1)

# ==================== è§£å‹æ¨¡å‹æ–‡ä»¶ ====================
print(f"\nğŸ“¦ æ­¥éª¤ 3/5: æ¢å¤æ¨¡å‹æ–‡ä»¶...")

models_archive = os.path.join(DATASET_PATH, "ollama_models.tar.gz")
ollama_home = os.path.expanduser("~")

# æ£€æŸ¥æ˜¯å¦æœ‰å‹ç¼©åŒ…
if os.path.exists(models_archive):
    # æƒ…å†µ1: æœ‰å‹ç¼©åŒ…ï¼Œéœ€è¦è§£å‹
    print(f"   æ‰¾åˆ°æ¨¡å‹å‹ç¼©åŒ…: {os.path.getsize(models_archive) / (1024**3):.2f} GB")
    print(f"   ğŸ“¦ å¼€å§‹è§£å‹ï¼ˆè¿™å¯èƒ½éœ€è¦ 10-30 ç§’ï¼‰...")
    
    start_time = time.time()
    
    with tarfile.open(models_archive, 'r:gz') as tar:
        tar.extractall(ollama_home)  # ä¼šè‡ªåŠ¨åˆ›å»º ~/.ollama ç›®å½•
    
    elapsed = time.time() - start_time
    print(f"   âœ… è§£å‹å®Œæˆï¼ˆè€—æ—¶: {int(elapsed)}ç§’ï¼‰")
    
else:
    # æƒ…å†µ2: æ²¡æœ‰å‹ç¼©åŒ…ï¼Œæ£€æŸ¥æ˜¯å¦å·²è§£å‹
    print(f"   âš ï¸  æœªæ‰¾åˆ°å‹ç¼©åŒ…ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è§£å‹åçš„æ–‡ä»¶...")
    
    # æ£€æŸ¥å¸¸è§çš„è§£å‹åæ–‡ä»¶/ç›®å½•
    possible_sources = [
        os.path.join(DATASET_PATH, ".ollama"),              # ç›´æ¥åœ¨æ ¹ç›®å½•
        os.path.join(DATASET_PATH, "ollama_model", ".ollama"),  # åœ¨ ollama_model æ–‡ä»¶å¤¹å†…ï¼ˆåµŒå¥—ç»“æ„ï¼‰
        os.path.join(DATASET_PATH, "ollama_models", ".ollama"), # åœ¨ ollama_models æ–‡ä»¶å¤¹å†…
        os.path.join(DATASET_PATH, "ollama"),               # å¤‡ç”¨è·¯å¾„
        os.path.join(DATASET_PATH, "models")                # å¤‡ç”¨è·¯å¾„
    ]
    
    found = False
    for source in possible_sources:
        if os.path.exists(source):
            print(f"   âœ… æ‰¾åˆ°è§£å‹åçš„ç›®å½•: {source}")
            
            # ç¡®å®šç›®æ ‡ç›®å½•
            if source.endswith(".ollama"):
                # ç›´æ¥å¤åˆ¶æ•´ä¸ª .ollama ç›®å½•
                dest = os.path.join(ollama_home, ".ollama")
            else:
                # åˆ›å»º .ollama/models ç›®å½•
                dest = os.path.join(ollama_home, ".ollama", "models")
                os.makedirs(os.path.dirname(dest), exist_ok=True)
            
            print(f"   ğŸ“‹ å¤åˆ¶åˆ°: {dest}")
            
            # å¤åˆ¶æ–‡ä»¶
            if os.path.isdir(source):
                shutil.copytree(source, dest, dirs_exist_ok=True)
            else:
                shutil.copy2(source, dest)
            
            found = True
            break
    
    if not found:
        print(f"   âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        print(f"\n   Dataset å†…å®¹:")
        for item in os.listdir(DATASET_PATH):
            print(f"      â€¢ {item}")
        exit(1)

# æ£€æŸ¥æ¨¡å‹ç›®å½•
models_dir = os.path.join(ollama_home, ".ollama")
if os.path.exists(models_dir):
        total_size = sum(
            os.path.getsize(os.path.join(dirpath, filename))
            for dirpath, dirnames, filenames in os.walk(models_dir)
            for filename in filenames
        )
        print(f"   ğŸ“Š æ¨¡å‹æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
else:
    print(f"   âŒ æœªæ‰¾åˆ°æ¨¡å‹å‹ç¼©åŒ…")
    exit(1)

# ==================== å¯åŠ¨ Ollama æœåŠ¡ ====================
print(f"\nğŸš€ æ­¥éª¤ 4/5: å¯åŠ¨ Ollama æœåŠ¡...")

# æ£€æŸ¥æ˜¯å¦å·²è¿è¡Œ
ps_check = subprocess.run(['pgrep', '-f', 'ollama serve'], capture_output=True)

if ps_check.returncode == 0:
    print(f"   âœ… Ollama æœåŠ¡å·²åœ¨è¿è¡Œ")
else:
    print(f"   ğŸ”„ å¯åŠ¨æœåŠ¡...")
    subprocess.Popen(
        ['ollama', 'serve'],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )
    
    print(f"   â³ ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼ˆ15ç§’ï¼‰...")
    time.sleep(15)
    
    # éªŒè¯æœåŠ¡
    import requests
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=10)
        if response.status_code == 200:
            print(f"   âœ… Ollama æœåŠ¡è¿è¡Œæ­£å¸¸")
    except Exception as e:
        print(f"   âš ï¸ æœåŠ¡éªŒè¯å¤±è´¥: {e}")
        print(f"   ä½†å¯èƒ½ä»åœ¨å¯åŠ¨ä¸­...")

# ==================== éªŒè¯æ¨¡å‹ ====================
print(f"\nâœ… æ­¥éª¤ 5/5: éªŒè¯æ¨¡å‹...")

list_result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
print(f"\n   å¯ç”¨æ¨¡å‹:")
print(f"   {list_result.stdout}")

# ==================== å®Œæˆ ====================
print("="*70)
print("âœ… Ollama åŠ è½½å®Œæˆï¼")
print("="*70)

print(f"\nğŸ“Š åŠ è½½æ€»ç»“:")
print(f"   â€¢ Ollama æœåŠ¡: âœ… è¿è¡Œä¸­")
print(f"   â€¢ æ¨¡å‹: âœ… å·²åŠ è½½")
print(f"   â€¢ æ€»è€—æ—¶: < 1 åˆ†é’Ÿ")

print(f"\nğŸ’¡ å¯¹æ¯”:")
print(f"   â€¢ ä¼ ç»Ÿæ–¹å¼: 5-10 åˆ†é’Ÿï¼ˆé‡æ–°ä¸‹è½½ï¼‰")
print(f"   â€¢ Dataset æ–¹å¼: < 1 åˆ†é’Ÿï¼ˆç›´æ¥åŠ è½½ï¼‰")
print(f"   â€¢ èŠ‚çœæ—¶é—´: çº¦ 90%ï¼")

print(f"\nğŸ§ª å¿«é€Ÿæµ‹è¯•:")
print(f"   åœ¨æ–°å•å…ƒæ ¼è¿è¡Œ:")
print(f"   !ollama run mistral 'Hi, respond in one word'")

print(f"\nğŸ“ ä¸‹ä¸€æ­¥:")
print(f"   ç»§ç»­è¿è¡Œä½ çš„ GraphRAG ç´¢å¼•:")
print(f"""
   from document_processor import DocumentProcessor
   from graph_indexer import GraphRAGIndexer
   
   processor = DocumentProcessor()
   vectorstore, retriever, doc_splits = processor.setup_knowledge_base(enable_graphrag=True)
   
   indexer = GraphRAGIndexer(async_batch_size=8)
   graph = indexer.index_documents(doc_splits)
""")

print("\n" + "="*70)
