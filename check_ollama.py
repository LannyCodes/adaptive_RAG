"""
OllamaæœåŠ¡å¿«é€Ÿæ£€æŸ¥å·¥å…·
åœ¨å¯åŠ¨RAGç³»ç»Ÿå‰æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
"""

import requests
import subprocess
import sys


def check_ollama_service():
    """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ"""
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=2)
        if response.status_code == 200:
            print("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
            
            # æ˜¾ç¤ºå·²ä¸‹è½½çš„æ¨¡å‹
            try:
                models = response.json().get('models', [])
                if models:
                    print(f"\nğŸ“¦ å·²ä¸‹è½½çš„æ¨¡å‹ ({len(models)}ä¸ª):")
                    for model in models:
                        print(f"   - {model['name']}")
                else:
                    print("\nâš ï¸  æ²¡æœ‰å·²ä¸‹è½½çš„æ¨¡å‹")
                    print("è¯·è¿è¡Œ: ollama pull mistral")
            except:
                pass
            
            return True
        else:
            return False
    except (requests.exceptions.ConnectionError, requests.exceptions.Timeout):
        return False


def start_ollama_service():
    """å°è¯•å¯åŠ¨OllamaæœåŠ¡"""
    print("ğŸ”§ æ­£åœ¨å°è¯•å¯åŠ¨OllamaæœåŠ¡...")
    try:
        # åå°å¯åŠ¨Ollama
        process = subprocess.Popen(
            ['ollama', 'serve'],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        
        # ç­‰å¾…å‡ ç§’è®©æœåŠ¡å¯åŠ¨
        import time
        time.sleep(3)
        
        # å†æ¬¡æ£€æŸ¥
        if check_ollama_service():
            print("âœ… OllamaæœåŠ¡å·²æˆåŠŸå¯åŠ¨")
            return True
        else:
            print("âŒ OllamaæœåŠ¡å¯åŠ¨å¤±è´¥")
            return False
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°ollamaå‘½ä»¤ï¼Œè¯·å…ˆå®‰è£…Ollama")
        print("   å®‰è£…å‘½ä»¤: curl -fsSL https://ollama.com/install.sh | sh")
        return False
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ” OllamaæœåŠ¡æ£€æŸ¥å·¥å…·")
    print("=" * 60)
    
    if check_ollama_service():
        print("\nâœ… æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥å¯åŠ¨RAGç³»ç»Ÿ")
        return 0
    else:
        print("\nâŒ OllamaæœåŠ¡æœªè¿è¡Œ")
        
        # è¯¢é—®æ˜¯å¦è‡ªåŠ¨å¯åŠ¨
        print("\næ˜¯å¦å°è¯•è‡ªåŠ¨å¯åŠ¨OllamaæœåŠ¡ï¼Ÿ")
        print("1. æ˜¯ï¼ˆæ¨èï¼‰")
        print("2. å¦ï¼Œæ‰‹åŠ¨å¯åŠ¨")
        
        choice = input("\nè¯·é€‰æ‹© [1/2]: ").strip()
        
        if choice == "1":
            if start_ollama_service():
                print("\nâœ… ç°åœ¨å¯ä»¥å¯åŠ¨RAGç³»ç»Ÿäº†")
                return 0
            else:
                print("\nâŒ è‡ªåŠ¨å¯åŠ¨å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨")
                print_manual_instructions()
                return 1
        else:
            print_manual_instructions()
            return 1


def print_manual_instructions():
    """æ‰“å°æ‰‹åŠ¨å¯åŠ¨è¯´æ˜"""
    print("\n" + "=" * 60)
    print("ğŸ“– æ‰‹åŠ¨å¯åŠ¨OllamaæœåŠ¡")
    print("=" * 60)
    print("\næ–¹å¼1: åœ¨ç»ˆç«¯è¿è¡Œ")
    print("  $ ollama serve")
    print("\næ–¹å¼2: åœ¨Pythonä¸­è¿è¡Œ")
    print("  import subprocess")
    print("  subprocess.Popen(['ollama', 'serve'])")
    print("\næ–¹å¼3: åœ¨Kaggle Notebookä¸­è¿è¡Œ")
    print("  %run KAGGLE_LOAD_OLLAMA.py")
    print("\nå¯åŠ¨åè¯·é‡æ–°è¿è¡ŒRAGç³»ç»Ÿ")
    print("=" * 60)


if __name__ == "__main__":
    sys.exit(main())
