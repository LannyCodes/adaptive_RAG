"""
ä¸“ä¸šå¹»è§‰æ£€æµ‹æ¨¡å—
æ”¯æŒå¤šç§æ£€æµ‹æ–¹æ³•ï¼šNLIæ¨¡å‹ã€ä¸“é—¨æ£€æµ‹æ¨¡å‹ã€æ··åˆæ£€æµ‹
"""

import re
from typing import List, Dict, Tuple
import torch
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    pipeline
)
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np


class VectaraHallucinationDetector:
    """
    Vectara ä¸“é—¨çš„å¹»è§‰æ£€æµ‹æ¨¡å‹
    ä½¿ç”¨ HHEM (Hughes Hallucination Evaluation Model)
    """
    
    def __init__(self):
        """åˆå§‹åŒ– Vectara å¹»è§‰æ£€æµ‹æ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ– Vectara å¹»è§‰æ£€æµ‹æ¨¡å‹...")
        
        try:
            self.model_name = "vectara/hallucination_evaluation_model"
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            
            # ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model.to(self.device)
            
            print(f"âœ… Vectara æ¨¡å‹åŠ è½½æˆåŠŸ (device: {self.device})")
        except Exception as e:
            print(f"âš ï¸ Vectara æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨ NLI æ¨¡å‹ä½œä¸ºå¤‡é€‰...")
            self.model = None
    
    def detect(self, generation: str, documents: str) -> Dict:
        """
        æ£€æµ‹å¹»è§‰
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£
            
        Returns:
            {
                "has_hallucination": bool,
                "hallucination_score": float (0-1),
                "factuality_score": float (0-1)
            }
        """
        if self.model is None:
            return {"has_hallucination": False, "hallucination_score": 0.0, "factuality_score": 1.0}
        
        try:
            # å‡†å¤‡è¾“å…¥
            inputs = self.tokenizer(
                documents,
                generation,
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding=True
            ).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)
            
            # Vectara æ¨¡å‹è¾“å‡ºï¼š[0] = factual, [1] = hallucinated
            factuality_score = probs[0][0].item()
            hallucination_score = probs[0][1].item()
            
            # åˆ¤æ–­æ˜¯å¦æœ‰å¹»è§‰ï¼ˆé˜ˆå€¼ 0.5ï¼‰
            has_hallucination = hallucination_score > 0.5
            
            return {
                "has_hallucination": has_hallucination,
                "hallucination_score": hallucination_score,
                "factuality_score": factuality_score
            }
        
        except Exception as e:
            print(f"âŒ Vectara æ£€æµ‹å¤±è´¥: {e}")
            return {"has_hallucination": False, "hallucination_score": 0.0, "factuality_score": 1.0}


class NLIHallucinationDetector:
    """
    åŸºäº NLI (Natural Language Inference) çš„å¹»è§‰æ£€æµ‹
    ä½¿ç”¨ DeBERTa æ¨¡å‹
    """
    
    def __init__(self):
        """åˆå§‹åŒ– NLI æ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ– NLI å¹»è§‰æ£€æµ‹æ¨¡å‹...")
        
        try:
            self.nli_model = pipeline(
                "text-classification",
                model="microsoft/deberta-large-mnli",
                device=0 if torch.cuda.is_available() else -1
            )
            print("âœ… NLI æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ NLI æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.nli_model = None
    
    def split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        # ç®€å•çš„å¥å­åˆ†å‰²ï¼ˆå¯ä»¥ç”¨æ›´å¤æ‚çš„ NLP å·¥å…·ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?]\s*', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def detect(self, generation: str, documents: str) -> Dict:
        """
        æ£€æµ‹å¹»è§‰
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£
            
        Returns:
            {
                "has_hallucination": bool,
                "contradiction_count": int,
                "neutral_count": int,
                "entailment_count": int,
                "problematic_sentences": List[str]
            }
        """
        if self.nli_model is None:
            print("âš ï¸ NLI æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡æ£€æµ‹")
            return {
                "has_hallucination": False,
                "contradiction_count": 0,
                "neutral_count": 0,
                "entailment_count": 0,
                "problematic_sentences": []
            }
        
        # åˆ†å‰²æˆå¥å­
        sentences = self.split_sentences(generation)
        
        if not sentences:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆå¥å­")
            return {
                "has_hallucination": False,
                "contradiction_count": 0,
                "neutral_count": 0,
                "entailment_count": 0,
                "problematic_sentences": []
            }
        
        contradiction_count = 0
        neutral_count = 0
        entailment_count = 0
        problematic_sentences = []
        
        for sentence in sentences:
            if len(sentence) < 10:  # è·³è¿‡å¤ªçŸ­çš„å¥å­
                continue
            
            try:
                # NLI æ¨ç†ï¼špremise (æ–‡æ¡£) â†’ hypothesis (ç”Ÿæˆçš„å¥å­)
                result = self.nli_model({
                    "text": documents[:500],  # é™åˆ¶æ–‡æ¡£é•¿åº¦
                    "text_pair": sentence
                })
                
                label = result[0]['label'].lower()
                
                if 'contradiction' in label:
                    contradiction_count += 1
                    problematic_sentences.append(sentence)
                elif 'neutral' in label:
                    neutral_count += 1
                    # neutral ä¹Ÿå¯èƒ½æ˜¯å¹»è§‰ï¼ˆæ–‡æ¡£ä¸­æ²¡æœ‰æ”¯æŒï¼‰
                    problematic_sentences.append(sentence)
                elif 'entailment' in label:
                    entailment_count += 1
            
            except Exception as e:
                print(f"âš ï¸ NLI æ£€æµ‹å¥å­å¤±è´¥: {str(e)[:100]}")
                continue
        
        # åˆ¤æ–­æ˜¯å¦æœ‰å¹»è§‰
        has_hallucination = contradiction_count > 0 or neutral_count > len(sentences) * 0.5
        
        return {
            "has_hallucination": has_hallucination,
            "contradiction_count": contradiction_count,
            "neutral_count": neutral_count,
            "entailment_count": entailment_count,
            "problematic_sentences": problematic_sentences
        }


class HybridHallucinationDetector:
    """
    æ··åˆå¹»è§‰æ£€æµ‹å™¨
    ç»“åˆ Vectara æ¨¡å‹å’Œ NLI æ¨¡å‹ï¼Œæä¾›æœ€ä½³æ£€æµ‹æ•ˆæœ
    """
    
    def __init__(self, use_vectara: bool = True, use_nli: bool = True):
        """
        åˆå§‹åŒ–æ··åˆæ£€æµ‹å™¨
        
        Args:
            use_vectara: æ˜¯å¦ä½¿ç”¨ Vectara æ¨¡å‹
            use_nli: æ˜¯å¦ä½¿ç”¨ NLI æ¨¡å‹
        """
        self.detectors = {}
        
        if use_vectara:
            try:
                self.detectors['vectara'] = VectaraHallucinationDetector()
            except Exception as e:
                print(f"âš ï¸ Vectara æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if use_nli:
            try:
                self.detectors['nli'] = NLIHallucinationDetector()
            except Exception as e:
                print(f"âš ï¸ NLI æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if not self.detectors:
            raise RuntimeError("âŒ æ‰€æœ‰æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼")
        
        print(f"âœ… æ··åˆæ£€æµ‹å™¨å°±ç»ªï¼Œå·²åŠ è½½: {list(self.detectors.keys())}")
    
    def detect(self, generation: str, documents: str) -> Dict:
        """
        ç»¼åˆæ£€æµ‹å¹»è§‰
        
        Returns:
            {
                "has_hallucination": bool,
                "confidence": float,
                "vectara_result": Dict,
                "nli_result": Dict,
                "method_used": str
            }
        """
        results = {
            "has_hallucination": False,
            "confidence": 0.0,
            "method_used": ""
        }
        
        # 1. ä¼˜å…ˆä½¿ç”¨ Vectaraï¼ˆæœ€å‡†ç¡®ï¼‰
        if 'vectara' in self.detectors:
            vectara_result = self.detectors['vectara'].detect(generation, documents)
            results['vectara_result'] = vectara_result
            
            if vectara_result['hallucination_score'] > 0.3:  # é™ä½é˜ˆå€¼ä»¥æé«˜çµæ•åº¦
                results['has_hallucination'] = True
                results['confidence'] = vectara_result['hallucination_score']
                results['method_used'] = 'vectara'
                return results
        
        # 2. å¦‚æœ Vectara ä¸ç¡®å®šæˆ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ NLI äºŒæ¬¡ç¡®è®¤
        if 'nli' in self.detectors:
            nli_result = self.detectors['nli'].detect(generation, documents)
            results['nli_result'] = nli_result
            
            if nli_result['has_hallucination']:
                results['has_hallucination'] = True
                # è®¡ç®—ç½®ä¿¡åº¦
                total_sentences = (nli_result['contradiction_count'] + 
                                 nli_result['neutral_count'] + 
                                 nli_result['entailment_count'])
                if total_sentences > 0:
                    results['confidence'] = (nli_result['contradiction_count'] + 
                                           nli_result['neutral_count'] * 0.5) / total_sentences
                results['method_used'] = 'nli'
        
        # å¦‚æœä¸¤ä¸ªæ¨¡å‹éƒ½æœ‰ç»“æœï¼ŒæŠ•ç¥¨å†³å®š
        if 'vectara_result' in results and 'nli_result' in results:
            vectara_vote = results['vectara_result']['has_hallucination']
            nli_vote = results['nli_result']['has_hallucination']
            
            if vectara_vote and nli_vote:
                results['has_hallucination'] = True
                results['confidence'] = min(
                    results.get('vectara_result', {}).get('hallucination_score', 0.5),
                    results.get('confidence', 0.5)
                )
                results['method_used'] = 'vectara+nli'
        
        return results
    
    def grade(self, generation: str, documents) -> str:
        """
        å…¼å®¹åŸæœ‰æ¥å£çš„æ£€æµ‹æ–¹æ³•
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            "yes" è¡¨ç¤ºæ— å¹»è§‰ï¼Œ"no" è¡¨ç¤ºæœ‰å¹»è§‰
        """
        # å¤„ç†æ–‡æ¡£æ ¼å¼
        if isinstance(documents, list):
            doc_text = "\n\n".join([
                doc.page_content if hasattr(doc, 'page_content') else str(doc)
                for doc in documents
            ])
        else:
            doc_text = str(documents)
        
        # æ£€æµ‹å¹»è§‰
        result = self.detect(generation, doc_text)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if result['has_hallucination']:
            print(f"âš ï¸ æ£€æµ‹åˆ°å¹»è§‰ (ç½®ä¿¡åº¦: {result['confidence']:.2f}, æ–¹æ³•: {result['method_used']})")
            if 'nli_result' in result:
                print(f"   çŸ›ç›¾å¥å­: {result['nli_result']['contradiction_count']}")
                if result['nli_result']['problematic_sentences']:
                    print(f"   é—®é¢˜å¥å­: {result['nli_result']['problematic_sentences'][:2]}")
        else:
            print(f"âœ… æœªæ£€æµ‹åˆ°å¹»è§‰ (æ–¹æ³•: {result['method_used']})")
        
        # è¿”å›å…¼å®¹æ ¼å¼
        return "no" if result['has_hallucination'] else "yes"


def initialize_hallucination_detector(method: str = "hybrid") -> object:
    """
    åˆå§‹åŒ–å¹»è§‰æ£€æµ‹å™¨
    
    Args:
        method: 'vectara', 'nli', æˆ– 'hybrid' (æ¨è)
        
    Returns:
        å¹»è§‰æ£€æµ‹å™¨å®ä¾‹
    """
    if method == "vectara":
        return VectaraHallucinationDetector()
    elif method == "nli":
        return NLIHallucinationDetector()
    elif method == "hybrid":
        return HybridHallucinationDetector(use_vectara=True, use_nli=True)
    else:
        raise ValueError(f"æœªçŸ¥çš„æ£€æµ‹æ–¹æ³•: {method}")
