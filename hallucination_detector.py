"""
ä¸“ä¸šå¹»è§‰æ£€æµ‹æ¨¡å—
æ”¯æŒå¤šç§æ£€æµ‹æ–¹æ³•ï¼šNLIæ¨¡å‹ã€ä¸“é—¨æ£€æµ‹æ¨¡å‹ã€è½»é‡çº§æ¨¡å‹ã€æ··åˆæ£€æµ‹
"""

import re
from typing import List, Dict, Tuple
import torch
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    pipeline
)
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# å¯¼å…¥è½»é‡çº§æ£€æµ‹å™¨
from lightweight_hallucination_detector import LightweightHallucinationDetector


class VectaraHallucinationDetector:
    """
    Vectara ä¸“é—¨çš„å¹»è§‰æ£€æµ‹æ¨¡å‹
    ä½¿ç”¨ HHEM (Hughes Hallucination Evaluation Model)
    """
    
    def __init__(self):
        """åˆå§‹åŒ– Vectara å¹»è§‰æ£€æµ‹æ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ– Vectara å¹»è§‰æ£€æµ‹æ¨¡å‹...")
        
        try:
            self.model_name = "vectara/hallucination_evaluation_model"
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            
            # ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model.to(self.device)
            
            print(f"âœ… Vectara æ¨¡å‹åŠ è½½æˆåŠŸ (device: {self.device})")
        except Exception as e:
            print(f"âš ï¸ Vectara æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å°è¯•ä½¿ç”¨ NLI æ¨¡å‹ä½œä¸ºå¤‡é€‰...")
            self.model = None
    
    def detect(self, generation: str, documents: str) -> Dict:
        """
        æ£€æµ‹å¹»è§‰
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£
            
        Returns:
            {
                "has_hallucination": bool,
                "hallucination_score": float (0-1),
                "factuality_score": float (0-1)
            }
        """
        if self.model is None:
            return {"has_hallucination": False, "hallucination_score": 0.0, "factuality_score": 1.0}
        
        try:
            # å‡†å¤‡è¾“å…¥
            inputs = self.tokenizer(
                documents,
                generation,
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding=True
            ).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)
            
            # Vectara æ¨¡å‹è¾“å‡ºï¼š[0] = factual, [1] = hallucinated
            factuality_score = probs[0][0].item()
            hallucination_score = probs[0][1].item()
            
            # åˆ¤æ–­æ˜¯å¦æœ‰å¹»è§‰ï¼ˆé˜ˆå€¼ 0.5ï¼‰
            has_hallucination = hallucination_score > 0.5
            
            return {
                "has_hallucination": has_hallucination,
                "hallucination_score": hallucination_score,
                "factuality_score": factuality_score
            }
        
        except Exception as e:
            print(f"âŒ Vectara æ£€æµ‹å¤±è´¥: {e}")
            return {"has_hallucination": False, "hallucination_score": 0.0, "factuality_score": 1.0}
    
    def grade(self, generation: str, documents) -> str:
        """
        å…¼å®¹åŸæœ‰æ¥å£çš„æ£€æµ‹æ–¹æ³•
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            "yes" è¡¨ç¤ºæ— å¹»è§‰ï¼Œ"no" è¡¨ç¤ºæœ‰å¹»è§‰
        """
        # å¤„ç†æ–‡æ¡£æ ¼å¼
        if isinstance(documents, list):
            doc_text = "\n\n".join([
                doc.page_content if hasattr(doc, 'page_content') else str(doc)
                for doc in documents
            ])
        else:
            doc_text = str(documents)
        
        # æ£€æµ‹å¹»è§‰
        result = self.detect(generation, doc_text)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if result['has_hallucination']:
            print(f"âš ï¸ Vectara æ£€æµ‹åˆ°å¹»è§‰ (å¾—åˆ†: {result['hallucination_score']:.2f})")
        else:
            print(f"âœ… Vectara æœªæ£€æµ‹åˆ°å¹»è§‰ (çœŸå®æ€§å¾—åˆ†: {result['factuality_score']:.2f})")
        
        # è¿”å›å…¼å®¹æ ¼å¼
        return "no" if result['has_hallucination'] else "yes"


class NLIHallucinationDetector:
    """
    åŸºäº NLI (Natural Language Inference) çš„å¹»è§‰æ£€æµ‹
    ä½¿ç”¨ DeBERTa æ¨¡å‹
    """
    
    def __init__(self):
        """åˆå§‹åŒ– NLI æ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ– NLI å¹»è§‰æ£€æµ‹æ¨¡å‹...")
        
        # å°è¯•å¤šä¸ªæ¨¡å‹ï¼ŒæŒ‰ç…§ä»å°åˆ°å¤§çš„é¡ºåº
        models_to_try = [
            "cross-encoder/nli-deberta-v3-xsmall",  # æœ€å° 40MB
            "cross-encoder/nli-deberta-v3-small",   # å° 150MB
            "cross-encoder/nli-MiniLM2-L6-H768",    # è½»é‡ 90MB
            "facebook/bart-large-mnli",              # å¤‡ç”¨
        ]
        
        self.nli_model = None
        
        for model_name in models_to_try:
            try:
                print(f"   å°è¯•åŠ è½½: {model_name}...")
                self.nli_model = pipeline(
                    "text-classification",
                    model=model_name,
                    device=0 if torch.cuda.is_available() else -1,
                    truncation=True,
                    max_length=512
                )
                print(f"âœ… NLI æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
                self.model_name = model_name
                break  # æˆåŠŸåŠ è½½ï¼Œé€€å‡ºå¾ªç¯
            except Exception as e:
                print(f"   âš ï¸ {model_name} åŠ è½½å¤±è´¥: {str(e)[:80]}")
                continue
        
        if self.nli_model is None:
            print("âŒ æ‰€æœ‰ NLI æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ç¦ç”¨ NLI æ£€æµ‹")
    
    def split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        # ç®€å•çš„å¥å­åˆ†å‰²ï¼ˆå¯ä»¥ç”¨æ›´å¤æ‚çš„ NLP å·¥å…·ï¼‰
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?]\s*', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def detect(self, generation: str, documents) -> Dict:
        """
        æ£€æµ‹å¹»è§‰ï¼ˆæ”¯æŒå¤šæ–‡æ¡£æœ€å¤§åŒ¹é…ç­–ç•¥ï¼‰
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£ (str æˆ– List[Document/str])
            
        Returns:
            {
                "has_hallucination": bool,
                "contradiction_count": int,
                "neutral_count": int,
                "entailment_count": int,
                "problematic_sentences": List[str]
            }
        """
        if self.nli_model is None:
            print("âš ï¸ NLI æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡æ£€æµ‹")
            return {
                "has_hallucination": False,
                "contradiction_count": 0,
                "neutral_count": 0,
                "entailment_count": 0,
                "problematic_sentences": []
            }
        
        # 1. é¢„å¤„ç†æ–‡æ¡£åˆ—è¡¨
        docs_content = []
        if isinstance(documents, list):
            for doc in documents:
                if hasattr(doc, 'page_content'):
                    docs_content.append(doc.page_content)
                else:
                    docs_content.append(str(doc))
        else:
            # å¦‚æœæ˜¯å•ä¸ªå­—ç¬¦ä¸²ï¼Œå°è¯•æŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œæˆ–è€…ä½œä¸ºå•æ–‡æ¡£å¤„ç†
            docs_content = [str(documents)]

        # 2. åˆ†å‰²ç”Ÿæˆå†…å®¹ä¸ºå¥å­
        sentences = self.split_sentences(generation)
        
        if not sentences:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆå¥å­")
            return {
                "has_hallucination": False,
                "contradiction_count": 0,
                "neutral_count": 0,
                "entailment_count": 0,
                "problematic_sentences": []
            }
        
        contradiction_count = 0
        neutral_count = 0
        entailment_count = 0
        problematic_sentences = []
        
        # 3. é€å¥æ£€æµ‹ (Max-Entailment Strategy)
        for sentence in sentences:
            if len(sentence) < 10:  # è·³è¿‡å¤ªçŸ­çš„å¥å­
                continue
            
            # é»˜è®¤ä¸º Neutral (æ‰¾ä¸åˆ°æ”¯æŒ)
            best_label = "neutral"
            best_score = 0.0
            
            # éå†æ‰€æœ‰æ–‡æ¡£å—ï¼Œå¯»æ‰¾æœ€ä½³åŒ¹é…
            # åªè¦æœ‰ä¸€ä¸ªæ–‡æ¡£èƒ½ Entail (æ”¯æŒ) è¿™ä¸ªå¥å­ï¼Œå°±ç®—é€šè¿‡
            sentence_supported = False
            
            for doc_content in docs_content:
                # æˆªæ–­å•ä¸ªæ–‡æ¡£å—ä»¥é€‚åº”æ¨¡å‹ (ä¿ç•™å‰ 800 å­—ç¬¦ï¼Œé€šå¸¸è¶³å¤Ÿè¦†ç›– 512 tokens)
                # æ³¨æ„ï¼šè¿™é‡Œæ˜¯å¯¹å•ä¸ªæ–‡æ¡£å—æˆªæ–­ï¼Œè€Œä¸æ˜¯å¯¹æ‰€æœ‰æ–‡æ¡£æ‹¼æ¥åæˆªæ–­
                premise = doc_content[:800]
                
                try:
                    # NLI æ¨ç†
                    if hasattr(self, 'model_name') and 'cross-encoder' in self.model_name:
                        result = self.nli_model(
                            f"{premise} [SEP] {sentence}",
                            truncation=True,
                            max_length=512
                        )
                    else:
                        result = self.nli_model(
                            sentence,
                            premise,
                            truncation=True,
                            max_length=512
                        )
                    
                    # è§£æç»“æœ
                    if isinstance(result, list) and len(result) > 0:
                        current_label = result[0]['label'].lower()
                        current_score = result[0]['score']
                        
                        # ä¼˜å…ˆçº§é€»è¾‘ï¼šEntailment > Contradiction > Neutral
                        # å¦‚æœæ‰¾åˆ° Entailmentï¼Œç«‹å³åœæ­¢æŸ¥æ‰¾ï¼ˆå·²éªŒè¯ï¼‰
                        if 'entailment' in current_label or 'entail' in current_label:
                            best_label = "entailment"
                            sentence_supported = True
                            break
                        
                        # å¦‚æœæ˜¯ Contradictionï¼Œè®°å½•ä¸‹æ¥ï¼Œä½†ç»§ç»­æ‰¾ï¼ˆä¹Ÿè®¸å…¶ä»–æ–‡æ¡£èƒ½è§£é‡Šï¼‰
                        if 'contradiction' in current_label or 'contradict' in current_label:
                            # åªæœ‰å½“ç›®å‰æ˜¯ Neutral æ—¶æ‰æ›´æ–°ä¸º Contradiction
                            # è¿™æ ·é˜²æ­¢ Contradiction è¦†ç›–äº†æ½œåœ¨çš„ Entailment (è™½ç„¶ä¸Šé¢breakäº†ï¼Œä½†è¿™é€»è¾‘ä¿æŒä¸¥è°¨)
                            if best_label == "neutral":
                                best_label = "contradiction"
                                best_score = current_score
                                
                    else:
                        continue
                        
                except Exception as e:
                    print(f"âš ï¸ NLI å­ä»»åŠ¡å¤±è´¥: {str(e)[:50]}")
                    continue
            
            # ç»Ÿè®¡è¯¥å¥å­çš„æœ€ç»ˆåˆ¤å®š
            if best_label == "entailment":
                entailment_count += 1
            elif best_label == "contradiction":
                contradiction_count += 1
                problematic_sentences.append(sentence)
            else: # neutral
                neutral_count += 1
                
        # 4. ç»¼åˆè¯„åˆ†
        total_sentences = contradiction_count + neutral_count + entailment_count
        
        has_hallucination = False
        if total_sentences > 0:
            contradiction_ratio = contradiction_count / total_sentences
            neutral_ratio = neutral_count / total_sentences
            # é˜ˆå€¼åˆ¤æ–­
            has_hallucination = (contradiction_ratio > 0.3) or (neutral_ratio > 0.8)
            
            # Debug ä¿¡æ¯
            print(f"ğŸ“Š NLI æ£€æµ‹ç»“æœ: Entail={entailment_count}, Contra={contradiction_count}, Neutral={neutral_count}")
        
        return {
            "has_hallucination": has_hallucination,
            "contradiction_count": contradiction_count,
            "neutral_count": neutral_count,
            "entailment_count": entailment_count,
            "problematic_sentences": problematic_sentences
        }
    
    def grade(self, generation: str, documents) -> str:
        """
        å…¼å®¹åŸæœ‰æ¥å£çš„æ£€æµ‹æ–¹æ³•
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            "yes" è¡¨ç¤ºæ— å¹»è§‰ï¼Œ"no" è¡¨ç¤ºæœ‰å¹»è§‰
        """
        # å¤„ç†æ–‡æ¡£æ ¼å¼
        if isinstance(documents, list):
            doc_text = "\n\n".join([
                doc.page_content if hasattr(doc, 'page_content') else str(doc)
                for doc in documents
            ])
        else:
            doc_text = str(documents)
        
        # æ£€æµ‹å¹»è§‰
        result = self.detect(generation, doc_text)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if result['has_hallucination']:
            print(f"âš ï¸ NLI æ£€æµ‹åˆ°å¹»è§‰")
            print(f"   çŸ›ç›¾å¥å­: {result['contradiction_count']}")
            print(f"   ä¸­ç«‹å¥å­: {result['neutral_count']}")
            print(f"   è•´å«å¥å­: {result['entailment_count']}")
            if result['problematic_sentences']:
                print(f"   é—®é¢˜å¥å­: {result['problematic_sentences'][:2]}")
        else:
            print(f"âœ… NLI æœªæ£€æµ‹åˆ°å¹»è§‰")
        
        # è¿”å›å…¼å®¹æ ¼å¼
        return "no" if result['has_hallucination'] else "yes"


class HybridHallucinationDetector:
    """
    æ··åˆå¹»è§‰æ£€æµ‹å™¨
    ç»“åˆ Vectara æ¨¡å‹å’Œ NLI æ¨¡å‹ï¼Œæä¾›æœ€ä½³æ£€æµ‹æ•ˆæœ
    """
    
    def __init__(self, use_vectara: bool = True, use_nli: bool = True):
        """
        åˆå§‹åŒ–æ··åˆæ£€æµ‹å™¨
        
        Args:
            use_vectara: æ˜¯å¦ä½¿ç”¨ Vectara æ¨¡å‹
            use_nli: æ˜¯å¦ä½¿ç”¨ NLI æ¨¡å‹
        """
        self.detectors = {}
        
        if use_vectara:
            try:
                self.detectors['vectara'] = VectaraHallucinationDetector()
            except Exception as e:
                print(f"âš ï¸ Vectara æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if use_nli:
            try:
                self.detectors['nli'] = NLIHallucinationDetector()
            except Exception as e:
                print(f"âš ï¸ NLI æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        if not self.detectors:
            raise RuntimeError("âŒ æ‰€æœ‰æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼")
        
        print(f"âœ… æ··åˆæ£€æµ‹å™¨å°±ç»ªï¼Œå·²åŠ è½½: {list(self.detectors.keys())}")
    
    def detect(self, generation: str, documents: str) -> Dict:
        """
        ç»¼åˆæ£€æµ‹å¹»è§‰
        
        Returns:
            {
                "has_hallucination": bool,
                "confidence": float,
                "vectara_result": Dict,
                "nli_result": Dict,
                "method_used": str
            }
        """
        results = {
            "has_hallucination": False,
            "confidence": 0.0,
            "method_used": ""
        }
        
        # 1. ä¼˜å…ˆä½¿ç”¨ Vectaraï¼ˆæœ€å‡†ç¡®ï¼‰
        if 'vectara' in self.detectors:
            vectara_result = self.detectors['vectara'].detect(generation, documents)
            results['vectara_result'] = vectara_result
            
            if vectara_result['hallucination_score'] > 0.3:  # é™ä½é˜ˆå€¼ä»¥æé«˜çµæ•åº¦
                results['has_hallucination'] = True
                results['confidence'] = vectara_result['hallucination_score']
                results['method_used'] = 'vectara'
                return results
            else:
                # Vectara æœªæ£€æµ‹åˆ°å¹»è§‰ï¼Œè®¾ç½® method_used
                results['method_used'] = 'vectara'
        
        # 2. å¦‚æœ Vectara ä¸ç¡®å®šæˆ–ä¸å¯ç”¨ï¼Œä½¿ç”¨ NLI äºŒæ¬¡ç¡®è®¤
        if 'nli' in self.detectors:
            nli_result = self.detectors['nli'].detect(generation, documents)
            results['nli_result'] = nli_result
            
            if nli_result['has_hallucination']:
                results['has_hallucination'] = True
                # è®¡ç®—ç½®ä¿¡åº¦
                total_sentences = (nli_result['contradiction_count'] + 
                                 nli_result['neutral_count'] + 
                                 nli_result['entailment_count'])
                if total_sentences > 0:
                    results['confidence'] = (nli_result['contradiction_count'] + 
                                           nli_result['neutral_count'] * 0.5) / total_sentences
                results['method_used'] = 'nli'
            else:
                # æœªæ£€æµ‹åˆ°å¹»è§‰ï¼Œä¹Ÿè¦è®¾ç½® method_used
                if not results['method_used']:  # åªæœ‰å½“å‰é¢æ²¡æœ‰è®¾ç½®æ—¶
                    results['method_used'] = 'nli'
        
        # å¦‚æœä¸¤ä¸ªæ¨¡å‹éƒ½æœ‰ç»“æœï¼ŒæŠ•ç¥¨å†³å®š
        if 'vectara_result' in results and 'nli_result' in results:
            vectara_vote = results['vectara_result']['has_hallucination']
            nli_vote = results['nli_result']['has_hallucination']
            
            if vectara_vote and nli_vote:
                results['has_hallucination'] = True
                results['confidence'] = min(
                    results.get('vectara_result', {}).get('hallucination_score', 0.5),
                    results.get('confidence', 0.5)
                )
                results['method_used'] = 'vectara+nli'
        
        return results
    
    def grade(self, generation: str, documents) -> str:
        """
        å…¼å®¹åŸæœ‰æ¥å£çš„æ£€æµ‹æ–¹æ³•
        
        Args:
            generation: LLM ç”Ÿæˆçš„å†…å®¹
            documents: å‚è€ƒæ–‡æ¡£ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            "yes" è¡¨ç¤ºæ— å¹»è§‰ï¼Œ"no" è¡¨ç¤ºæœ‰å¹»è§‰
        """
        # å¤„ç†æ–‡æ¡£æ ¼å¼
        if isinstance(documents, list):
            doc_text = "\n\n".join([
                doc.page_content if hasattr(doc, 'page_content') else str(doc)
                for doc in documents
            ])
        else:
            doc_text = str(documents)
        
        # æ£€æµ‹å¹»è§‰
        result = self.detect(generation, doc_text)
        
        # æ‰“å°è¯¦ç»†ä¿¡æ¯
        if result['has_hallucination']:
            print(f"âš ï¸ æ£€æµ‹åˆ°å¹»è§‰ (ç½®ä¿¡åº¦: {result['confidence']:.2f}, æ–¹æ³•: {result['method_used']})")
            if 'nli_result' in result:
                print(f"   çŸ›ç›¾å¥å­: {result['nli_result']['contradiction_count']}")
                if result['nli_result']['problematic_sentences']:
                    print(f"   é—®é¢˜å¥å­: {result['nli_result']['problematic_sentences'][:2]}")
        else:
            print(f"âœ… æœªæ£€æµ‹åˆ°å¹»è§‰ (æ–¹æ³•: {result['method_used']})")
        
        # è¿”å›å…¼å®¹æ ¼å¼
        return "no" if result['has_hallucination'] else "yes"


def initialize_hallucination_detector(method: str = "nli") -> object:
    """
    åˆå§‹åŒ–å¹»è§‰æ£€æµ‹å™¨
    
    Args:
        method: 'vectara', 'nli', æˆ– 'hybrid' (æ¨è)
        
    Returns:
        å¹»è§‰æ£€æµ‹å™¨å®ä¾‹
    """
    if method == "vectara":
        return VectaraHallucinationDetector()
    elif method == "nli":
        return NLIHallucinationDetector()
    elif method == "hybrid":
        return HybridHallucinationDetector(use_vectara=False, use_nli=True)  # ç¦ç”¨Vectaraï¼Œä½¿ç”¨NLI
    else:
        raise ValueError(f"æœªçŸ¥çš„æ£€æµ‹æ–¹æ³•: {method}")
