"""
VAEè®­ç»ƒè¿‡ç¨‹è¯¦ç»†ç¤ºä¾‹
å±•ç¤ºVAEåœ¨MNISTæ•°æ®é›†ä¸Šçš„å®Œæ•´è®­ç»ƒæµç¨‹
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

from vae_model_structure import VAE, VAELoss


class VAEVisualizer:
    """VAEå¯è§†åŒ–å·¥å…·ç±»"""
    
    @staticmethod
    def plot_reconstruction(original, reconstructed, epoch):
        """ç»˜åˆ¶åŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒçš„å¯¹æ¯”"""
        fig, axes = plt.subplots(2, 10, figsize=(15, 3))
        
        for i in range(10):
            # åŸå§‹å›¾åƒ
            axes[0, i].imshow(original[i].cpu().detach().numpy().reshape(28, 28), cmap='gray')
            axes[0, i].set_title('Original')
            axes[0, i].axis('off')
            
            # é‡å»ºå›¾åƒ
            axes[1, i].imshow(reconstructed[i].cpu().detach().numpy().reshape(28, 28), cmap='gray')
            axes[1, i].set_title('Reconstructed')
            axes[1, i].axis('off')
        
        plt.suptitle(f'Epoch {epoch} - Reconstruction Comparison')
        plt.tight_layout()
        plt.show()
    
    @staticmethod
    def plot_latent_space(model, test_loader, device):
        """å¯è§†åŒ–æ½œåœ¨ç©ºé—´"""
        model.eval()
        
        latent_vectors = []
        labels = []
        
        with torch.no_grad():
            for data, target in test_loader:
                data = data.to(device)
                mu, _ = model.encoder(data.view(-1, 784))
                latent_vectors.append(mu.cpu().numpy())
                labels.append(target.numpy())
        
        latent_vectors = np.concatenate(latent_vectors)
        labels = np.concatenate(labels)
        
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], 
                             c=labels, cmap='tab10', alpha=0.6)
        plt.colorbar(scatter)
        plt.title('2D Latent Space Visualization')
        plt.xlabel('Latent Dimension 1')
        plt.ylabel('Latent Dimension 2')
        plt.show()


class VAETrainer:
    """VAEè®­ç»ƒå™¨ç±»"""
    
    def __init__(self, model, train_loader, test_loader, device, learning_rate=1e-3):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.device = device
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        
        # è®°å½•è®­ç»ƒå†å²
        self.train_losses = []
        self.test_losses = []
        
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        train_loss = 0
        
        for batch_idx, (data, _) in enumerate(self.train_loader):
            data = data.to(self.device)
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            recon_batch, mu, logvar = self.model(data.view(-1, 784))
            
            # è®¡ç®—æŸå¤±
            loss = VAELoss.loss_function(recon_batch, data.view(-1, 784), mu, logvar)
            
            # åå‘ä¼ æ’­
            loss.backward()
            train_loss += loss.item()
            self.optimizer.step()
            
            if batch_idx % 100 == 0:
                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(self.train_loader.dataset)} '
                      f'({100. * batch_idx / len(self.train_loader):.0f}%)]\tLoss: {loss.item() / len(data):.6f}')
        
        avg_loss = train_loss / len(self.train_loader.dataset)
        self.train_losses.append(avg_loss)
        return avg_loss
    
    def test_epoch(self, epoch):
        """æµ‹è¯•ä¸€ä¸ªepoch"""
        self.model.eval()
        test_loss = 0
        
        with torch.no_grad():
            for data, _ in self.test_loader:
                data = data.to(self.device)
                recon_batch, mu, logvar = self.model(data.view(-1, 784))
                test_loss += VAELoss.loss_function(recon_batch, data.view(-1, 784), mu, logvar).item()
        
        avg_loss = test_loss / len(self.test_loader.dataset)
        self.test_losses.append(avg_loss)
        
        print(f'====> Test set loss: {avg_loss:.4f}')
        return avg_loss
    
    def train(self, epochs=10):
        """å®Œæ•´è®­ç»ƒè¿‡ç¨‹"""
        print("ğŸš€ å¼€å§‹VAEè®­ç»ƒ...")
        
        for epoch in range(1, epochs + 1):
            train_loss = self.train_epoch(epoch)
            test_loss = self.test_epoch(epoch)
            
            # æ¯5ä¸ªepochå¯è§†åŒ–ä¸€æ¬¡
            if epoch % 5 == 0:
                self.visualize_reconstruction(epoch)
        
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        self.plot_training_history()
    
    def visualize_reconstruction(self, epoch):
        """å¯è§†åŒ–é‡å»ºç»“æœ"""
        self.model.eval()
        
        with torch.no_grad():
            # è·å–ä¸€æ‰¹æµ‹è¯•æ•°æ®
            data_iter = iter(self.test_loader)
            test_data, _ = next(data_iter)
            test_data = test_data.to(self.device)
            
            # é‡å»º
            recon_batch, _, _ = self.model(test_data.view(-1, 784))
            
            # å¯è§†åŒ–
            VAEVisualizer.plot_reconstruction(test_data.view(-1, 784)[:10], 
                                             recon_batch[:10], epoch)
    
    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        plt.figure(figsize=(10, 6))
        plt.plot(self.train_losses, label='Train Loss')
        plt.plot(self.test_losses, label='Test Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('VAE Training History')
        plt.legend()
        plt.grid(True)
        plt.show()


# ============================================================================
# æ•°æ®å‡†å¤‡
# ============================================================================

def load_mnist_data(batch_size=128):
    """åŠ è½½MNISTæ•°æ®é›†"""
    
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    
    # è®­ç»ƒé›†
    train_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=True, 
        download=True, 
        transform=transform
    )
    
    # æµ‹è¯•é›†
    test_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=False, 
        download=True, 
        transform=transform
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, test_loader


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    print("ğŸ“¦ åŠ è½½MNISTæ•°æ®é›†...")
    train_loader, test_loader = load_mnist_data()
    
    # åˆ›å»ºVAEæ¨¡å‹
    print("ğŸ—ï¸  åˆ›å»ºVAEæ¨¡å‹...")
    model = VAE(input_dim=784, hidden_dims=[512, 256], latent_dim=20)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = VAETrainer(model, train_loader, test_loader, device)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(epochs=10)
    
    # å¯è§†åŒ–æ½œåœ¨ç©ºé—´
    print("\nğŸŒŒ å¯è§†åŒ–æ½œåœ¨ç©ºé—´...")
    VAEVisualizer.plot_latent_space(model, test_loader, device)
    
    return model, trainer


if __name__ == "__main__":
    model, trainer = main()