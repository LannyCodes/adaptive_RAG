"""
çŸ¥è¯†å›¾è°±æ¨¡å—
å®ç°GraphRAGçš„æ ¸å¿ƒåŠŸèƒ½ï¼šå›¾è°±æ„å»ºã€ç¤¾åŒºæ£€æµ‹ã€å±‚æ¬¡åŒ–æ‘˜è¦
"""

import networkx as nx
from typing import List, Dict, Set, Tuple, Optional
from collections import defaultdict
import json

try:
    from community import community_louvain  # python-louvain
    LOUVAIN_AVAILABLE = True
except ImportError:
    LOUVAIN_AVAILABLE = False
    print("âš ï¸ python-louvainæœªå®‰è£…ï¼Œç¤¾åŒºæ£€æµ‹åŠŸèƒ½å—é™")

try:
    from langchain_core.prompts import PromptTemplate
except ImportError:
    from langchain.prompts import PromptTemplate
from langchain_community.chat_models import ChatOllama
from langchain_core.output_parsers import StrOutputParser
from config import LOCAL_LLM


class KnowledgeGraph:
    """çŸ¥è¯†å›¾è°±ç±» - ä½¿ç”¨NetworkXæ„å»ºå’Œç®¡ç†å›¾è°±"""
    
    def __init__(self):
        self.graph = nx.Graph()  # æ— å‘å›¾
        self.entities = {}  # å®ä½“è¯¦ç»†ä¿¡æ¯
        self.communities = {}  # ç¤¾åŒºåˆ’åˆ†ç»“æœ
        self.community_summaries = {}  # ç¤¾åŒºæ‘˜è¦
        
    def add_entity(self, name: str, entity_type: str, description: str = "", **kwargs):
        """æ·»åŠ å®ä½“èŠ‚ç‚¹"""
        self.graph.add_node(
            name,
            type=entity_type,
            description=description,
            **kwargs
        )
        self.entities[name] = {
            "name": name,
            "type": entity_type,
            "description": description,
            **kwargs
        }
    
    def add_relation(self, source: str, target: str, relation_type: str, 
                    description: str = "", weight: float = 1.0):
        """æ·»åŠ å…³ç³»è¾¹"""
        self.graph.add_edge(
            source,
            target,
            relation_type=relation_type,
            description=description,
            weight=weight
        )
    
    def build_from_extractions(self, extraction_results: List[Dict]):
        """
        ä»å®ä½“æå–ç»“æœæ„å»ºå›¾è°±
        
        Args:
            extraction_results: å®ä½“å’Œå…³ç³»æå–ç»“æœåˆ—è¡¨
        """
        print("ğŸ”¨ å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±...")
        
        total_entities = 0
        total_relations = 0
        
        for result in extraction_results:
            # æ·»åŠ å®ä½“
            entities = result.get("entities", [])
            for entity in entities:
                self.add_entity(
                    name=entity["name"],
                    entity_type=entity.get("type", "UNKNOWN"),
                    description=entity.get("description", "")
                )
                total_entities += 1
            
            # æ·»åŠ å…³ç³»
            relations = result.get("relations", [])
            for relation in relations:
                source = relation.get("source")
                target = relation.get("target")
                
                # ç¡®ä¿èŠ‚ç‚¹å­˜åœ¨
                if source in self.graph and target in self.graph:
                    self.add_relation(
                        source=source,
                        target=target,
                        relation_type=relation.get("relation_type", "RELATED_TO"),
                        description=relation.get("description", "")
                    )
                    total_relations += 1
        
        print(f"âœ… å›¾è°±æ„å»ºå®Œæˆ: {total_entities} ä¸ªå®ä½“, {total_relations} ä¸ªå…³ç³»")
        print(f"   å®é™…èŠ‚ç‚¹æ•°: {self.graph.number_of_nodes()}")
        print(f"   å®é™…è¾¹æ•°: {self.graph.number_of_edges()}")
    
    def detect_communities(self, algorithm: str = "louvain") -> Dict[str, int]:
        """
        ç¤¾åŒºæ£€æµ‹ - GraphRAGçš„æ ¸å¿ƒç»„ä»¶
        
        Args:
            algorithm: ç¤¾åŒºæ£€æµ‹ç®—æ³• ('louvain', 'greedy', 'label_propagation')
            
        Returns:
            èŠ‚ç‚¹åˆ°ç¤¾åŒºIDçš„æ˜ å°„
        """
        print(f"ğŸ” å¼€å§‹ç¤¾åŒºæ£€æµ‹ (ç®—æ³•: {algorithm})...")
        
        if self.graph.number_of_nodes() == 0:
            print("âš ï¸ å›¾è°±ä¸ºç©ºï¼Œè·³è¿‡ç¤¾åŒºæ£€æµ‹")
            return {}
        
        try:
            if algorithm == "louvain" and LOUVAIN_AVAILABLE:
                communities = community_louvain.best_partition(self.graph)
            elif algorithm == "greedy":
                communities_generator = nx.community.greedy_modularity_communities(self.graph)
                communities = {}
                for idx, community_set in enumerate(communities_generator):
                    for node in community_set:
                        communities[node] = idx
            elif algorithm == "label_propagation":
                communities_generator = nx.community.label_propagation_communities(self.graph)
                communities = {}
                for idx, community_set in enumerate(communities_generator):
                    for node in community_set:
                        communities[node] = idx
            else:
                print(f"âš ï¸ æœªçŸ¥ç®—æ³• {algorithm}ï¼Œä½¿ç”¨è´ªå©ªç®—æ³•")
                communities_generator = nx.community.greedy_modularity_communities(self.graph)
                communities = {}
                for idx, community_set in enumerate(communities_generator):
                    for node in community_set:
                        communities[node] = idx
            
            self.communities = communities
            num_communities = len(set(communities.values()))
            print(f"âœ… æ£€æµ‹åˆ° {num_communities} ä¸ªç¤¾åŒº")
            
            return communities
            
        except Exception as e:
            print(f"âŒ ç¤¾åŒºæ£€æµ‹å¤±è´¥: {e}")
            return {}
    
    def get_community_members(self, community_id: int) -> List[str]:
        """è·å–æŒ‡å®šç¤¾åŒºçš„æ‰€æœ‰æˆå‘˜"""
        return [node for node, cid in self.communities.items() if cid == community_id]
    
    def get_community_subgraph(self, community_id: int) -> nx.Graph:
        """è·å–æŒ‡å®šç¤¾åŒºçš„å­å›¾"""
        members = self.get_community_members(community_id)
        return self.graph.subgraph(members)
    
    def get_node_neighbors(self, node: str, depth: int = 1) -> Set[str]:
        """è·å–èŠ‚ç‚¹çš„é‚»å±…ï¼ˆæ”¯æŒå¤šè·³ï¼‰"""
        if node not in self.graph:
            return set()
        
        neighbors = {node}
        current_layer = {node}
        
        for _ in range(depth):
            next_layer = set()
            for n in current_layer:
                next_layer.update(self.graph.neighbors(n))
            neighbors.update(next_layer)
            current_layer = next_layer
        
        return neighbors
    
    def get_entity_info(self, entity_name: str) -> Optional[Dict]:
        """è·å–å®ä½“è¯¦ç»†ä¿¡æ¯"""
        return self.entities.get(entity_name)
    
    def search_entities_by_type(self, entity_type: str) -> List[str]:
        """æŒ‰ç±»å‹æœç´¢å®ä½“"""
        return [
            name for name, data in self.entities.items()
            if data.get("type") == entity_type
        ]
    
    def get_statistics(self) -> Dict:
        """è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "num_nodes": self.graph.number_of_nodes(),
            "num_edges": self.graph.number_of_edges(),
            "num_communities": len(set(self.communities.values())) if self.communities else 0,
            "density": nx.density(self.graph) if self.graph.number_of_nodes() > 0 else 0,
            "entity_types": {}
        }
        
        # ç»Ÿè®¡å®ä½“ç±»å‹åˆ†å¸ƒ
        for entity in self.entities.values():
            etype = entity.get("type", "UNKNOWN")
            stats["entity_types"][etype] = stats["entity_types"].get(etype, 0) + 1
        
        return stats
    
    def save_to_file(self, filepath: str):
        """ä¿å­˜å›¾è°±åˆ°æ–‡ä»¶"""
        data = {
            "entities": self.entities,
            "edges": [
                {
                    "source": u,
                    "target": v,
                    "data": data
                }
                for u, v, data in self.graph.edges(data=True)
            ],
            "communities": self.communities,
            "community_summaries": self.community_summaries
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å›¾è°±å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_from_file(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½å›¾è°±"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.entities = data.get("entities", {})
        self.communities = data.get("communities", {})
        self.community_summaries = data.get("community_summaries", {})
        
        # é‡å»ºå›¾
        self.graph.clear()
        for name, entity in self.entities.items():
            self.add_entity(**entity)
        
        for edge in data.get("edges", []):
            self.graph.add_edge(
                edge["source"],
                edge["target"],
                **edge["data"]
            )
        
        print(f"âœ… å›¾è°±å·²ä»æ–‡ä»¶åŠ è½½: {filepath}")


class CommunitySummarizer:
    """ç¤¾åŒºæ‘˜è¦ç”Ÿæˆå™¨ - GraphRAGçš„å…³é”®ç»„ä»¶"""
    
    def __init__(self):
        self.llm = ChatOllama(model=LOCAL_LLM, temperature=0.3)
        
        self.summary_prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±åˆ†æä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹ç¤¾åŒºç”Ÿæˆä¸€ä¸ªç»¼åˆæ‘˜è¦ã€‚

ç¤¾åŒºæˆå‘˜ï¼ˆå®ä½“ï¼‰:
{entities}

å®ä½“é—´çš„å…³ç³»:
{relations}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œæè¿°ï¼š
1. è¿™ä¸ªç¤¾åŒºçš„ä¸»é¢˜æ˜¯ä»€ä¹ˆ
2. ä¸»è¦åŒ…å«å“ªäº›æ ¸å¿ƒæ¦‚å¿µ
3. å®ä½“ä¹‹é—´çš„å…³é”®å…³ç³»

æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰:
""",
            input_variables=["entities", "relations"]
        )
        
        self.summary_chain = self.summary_prompt | self.llm | StrOutputParser()
    
    def summarize_community(self, kg: KnowledgeGraph, community_id: int) -> str:
        """
        ä¸ºæŒ‡å®šç¤¾åŒºç”Ÿæˆæ‘˜è¦
        
        Args:
            kg: çŸ¥è¯†å›¾è°±å¯¹è±¡
            community_id: ç¤¾åŒºID
            
        Returns:
            ç¤¾åŒºæ‘˜è¦æ–‡æœ¬
        """
        members = kg.get_community_members(community_id)
        subgraph = kg.get_community_subgraph(community_id)
        
        # å‡†å¤‡å®ä½“ä¿¡æ¯
        entity_info = []
        for member in members[:20]:  # é™åˆ¶æ•°é‡
            info = kg.get_entity_info(member)
            if info:
                entity_info.append(
                    f"- {info['name']} ({info.get('type', 'UNKNOWN')}): {info.get('description', 'æ— æè¿°')}"
                )
        
        # å‡†å¤‡å…³ç³»ä¿¡æ¯
        relation_info = []
        for u, v, data in subgraph.edges(data=True):
            relation_info.append(
                f"- {u} --[{data.get('relation_type', 'RELATED')}]--> {v}"
            )
        
        entities_text = "\n".join(entity_info) if entity_info else "æ— å®ä½“"
        relations_text = "\n".join(relation_info[:15]) if relation_info else "æ— å…³ç³»"
        
        try:
            summary = self.summary_chain.invoke({
                "entities": entities_text,
                "relations": relations_text
            })
            return summary.strip()
        except Exception as e:
            print(f"âŒ ç¤¾åŒº {community_id} æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return f"ç¤¾åŒº{community_id}: åŒ…å«{len(members)}ä¸ªå®ä½“"
    
    def summarize_all_communities(self, kg: KnowledgeGraph) -> Dict[int, str]:
        """ä¸ºæ‰€æœ‰ç¤¾åŒºç”Ÿæˆæ‘˜è¦"""
        if not kg.communities:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ç¤¾åŒºï¼Œè¯·å…ˆè¿è¡Œç¤¾åŒºæ£€æµ‹")
            return {}
        
        community_ids = set(kg.communities.values())
        print(f"ğŸ“ å¼€å§‹ä¸º {len(community_ids)} ä¸ªç¤¾åŒºç”Ÿæˆæ‘˜è¦...")
        
        summaries = {}
        for cid in community_ids:
            print(f"   å¤„ç†ç¤¾åŒº {cid}...")
            summary = self.summarize_community(kg, cid)
            summaries[cid] = summary
            kg.community_summaries[cid] = summary
        
        print("âœ… æ‰€æœ‰ç¤¾åŒºæ‘˜è¦ç”Ÿæˆå®Œæˆ")
        return summaries


def initialize_knowledge_graph():
    """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±"""
    return KnowledgeGraph()


def initialize_community_summarizer():
    """åˆå§‹åŒ–ç¤¾åŒºæ‘˜è¦ç”Ÿæˆå™¨"""
    return CommunitySummarizer()
