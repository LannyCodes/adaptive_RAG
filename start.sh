#!/bin/bash
export OLLAMA_MODELS=/home/user/.ollama/models
export OLLAMA_HOST=127.0.0.1:11434

echo "ğŸš€ Starting application on ModelScope..."

# å¯åŠ¨ Ollama
echo "ğŸ”´ Starting Ollama..."
ollama serve > ollama.log 2>&1 &

echo "â³ Waiting for Ollama to start..."
sleep 5

# å°è¯•æ‹‰å–æ¨¡å‹
echo "â¬‡ï¸  Pulling model (qwen2:1.5b)..."
# åœ¨åå°æ‹‰å–ï¼Œä¸é˜»å¡æœåŠ¡å¯åŠ¨
(ollama pull qwen2:1.5b && echo "âœ… Model pulled successfully") || echo "âš ï¸ Model pull failed" &

# å¯åŠ¨ FastAPI
echo "ğŸŸ¢ Starting FastAPI Server..."
# ç»‘å®š 0.0.0.0:7860
uvicorn server:app --host 0.0.0.0 --port 7860
