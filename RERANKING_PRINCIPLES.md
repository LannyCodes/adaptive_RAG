# å‘é‡é‡æ’ï¼ˆVector Rerankingï¼‰åŸç†è¯¦è§£

## ğŸ¯ ä»€ä¹ˆæ˜¯å‘é‡é‡æ’

å‘é‡é‡æ’æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿä¸­çš„ä¸€ç§é«˜çº§æŠ€æœ¯ï¼Œç”¨äºåœ¨åˆå§‹å‘é‡æ£€ç´¢åå¯¹å€™é€‰æ–‡æ¡£è¿›è¡Œé‡æ–°æ’åºï¼Œä»¥æé«˜æœ€ç»ˆæ£€ç´¢ç»“æœçš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

## ğŸ” ä¸ºä»€ä¹ˆéœ€è¦é‡æ’

### åˆå§‹æ£€ç´¢çš„å±€é™æ€§

1. **è¯­ä¹‰è·ç¦»åå·®**
   - å‘é‡ç›¸ä¼¼åº¦å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰è¯­ä¹‰ç›¸å…³æ€§
   - æŸäº›ç›¸å…³æ–‡æ¡£å¯èƒ½å› ä¸ºè¡¨è¾¾æ–¹å¼ä¸åŒè€Œæ’åé å

2. **ä¸Šä¸‹æ–‡ç†è§£ä¸è¶³**
   - ç®€å•çš„ä½™å¼¦ç›¸ä¼¼åº¦æ— æ³•ç†è§£å¤æ‚çš„æŸ¥è¯¢æ„å›¾
   - ç¼ºä¹å¯¹æŸ¥è¯¢å’Œæ–‡æ¡£äº¤äº’å…³ç³»çš„æ·±åº¦ç†è§£

3. **å¤šæ ·æ€§é—®é¢˜**
   - åˆå§‹æ£€ç´¢å¯èƒ½è¿”å›å†…å®¹ç›¸ä¼¼çš„é‡å¤æ–‡æ¡£
   - ç¼ºä¹ç»“æœçš„å¤šæ ·æ€§å’Œå…¨é¢æ€§

## ğŸ§  é‡æ’çš„æ ¸å¿ƒåŸç†

### 1. åŒé˜¶æ®µæ£€ç´¢æ¶æ„

```
æŸ¥è¯¢ â†’ ç²—æ’ï¼ˆå‘é‡æ£€ç´¢ï¼‰â†’ ç²¾æ’ï¼ˆé‡æ’æ¨¡å‹ï¼‰â†’ æœ€ç»ˆç»“æœ
     â†“                  â†“
   å¬å›å€™é€‰é›†        é‡æ–°æ’åºæ‰“åˆ†
   (100-1000ç¯‡)      (é€‰æ‹©å‰kç¯‡)
```

### 2. é‡æ’æ¨¡å‹ç±»å‹

#### A. äº¤å‰ç¼–ç å™¨ï¼ˆCross-Encoderï¼‰
```python
# åŸç†ç¤ºæ„
def cross_encoder_rerank(query, documents):
    scores = []
    for doc in documents:
        # æŸ¥è¯¢å’Œæ–‡æ¡£ä¸€èµ·ç¼–ç 
        input_text = f"[CLS] {query} [SEP] {doc} [SEP]"
        score = model(input_text)  # ç›´æ¥è¾“å‡ºç›¸å…³æ€§åˆ†æ•°
        scores.append(score)
    return sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
```

#### B. åŒç¼–ç å™¨é‡æ’ï¼ˆBi-Encoder Rerankingï¼‰
```python
def bi_encoder_rerank(query, documents):
    query_embedding = query_encoder(query)
    doc_embeddings = [doc_encoder(doc) for doc in documents]
    
    # ä½¿ç”¨æ›´å¤æ‚çš„ç›¸ä¼¼åº¦è®¡ç®—
    scores = []
    for doc_emb in doc_embeddings:
        score = complex_similarity(query_embedding, doc_emb)
        scores.append(score)
    return sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
```

## ğŸ”¬ é‡æ’ç®—æ³•è¯¦è§£

### 1. åŸºäºæœºå™¨å­¦ä¹ çš„é‡æ’

#### Learning to Rank (LTR)
```python
class LearnToRankReranker:
    def __init__(self):
        self.model = None  # XGBoost, LambdaMARTç­‰
    
    def extract_features(self, query, document):
        """æå–æŸ¥è¯¢-æ–‡æ¡£ç‰¹å¾"""
        features = [
            # æ–‡æœ¬åŒ¹é…ç‰¹å¾
            jaccard_similarity(query, document),
            tf_idf_score(query, document),
            bm25_score(query, document),
            
            # è¯­ä¹‰ç‰¹å¾
            cosine_similarity(query_emb, doc_emb),
            bert_score(query, document),
            
            # æ–‡æ¡£ç‰¹å¾
            document_length(document),
            document_quality_score(document),
            
            # æŸ¥è¯¢ç‰¹å¾
            query_complexity(query),
            query_type_classification(query)
        ]
        return features
    
    def rerank(self, query, documents):
        features_matrix = []
        for doc in documents:
            features = self.extract_features(query, doc)
            features_matrix.append(features)
        
        scores = self.model.predict(features_matrix)
        return sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
```

### 2. åŸºäºæ·±åº¦å­¦ä¹ çš„é‡æ’

#### Transformeré‡æ’æ¨¡å‹
```python
class TransformerReranker:
    def __init__(self, model_name="microsoft/DialoGPT-medium"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
    
    def rerank(self, query, documents, top_k=5):
        scores = []
        
        for doc in documents:
            # æ„é€ è¾“å…¥
            inputs = self.tokenizer(
                query, doc,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            )
            
            # è·å–ç›¸å…³æ€§åˆ†æ•°
            with torch.no_grad():
                outputs = self.model(**inputs)
                score = torch.softmax(outputs.logits, dim=-1)[0][1]  # ç›¸å…³æ€§æ¦‚ç‡
                scores.append(score.item())
        
        # é‡æ–°æ’åº
        ranked_results = sorted(
            zip(documents, scores), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        return ranked_results[:top_k]
```

### 3. å¤šç­–ç•¥èåˆé‡æ’

```python
class MultiStrategyReranker:
    def __init__(self):
        self.semantic_weight = 0.4
        self.lexical_weight = 0.3
        self.diversity_weight = 0.2
        self.freshness_weight = 0.1
    
    def rerank(self, query, documents):
        # 1. è¯­ä¹‰ç›¸å…³æ€§åˆ†æ•°
        semantic_scores = self.compute_semantic_scores(query, documents)
        
        # 2. è¯æ±‡åŒ¹é…åˆ†æ•°
        lexical_scores = self.compute_lexical_scores(query, documents)
        
        # 3. å¤šæ ·æ€§åˆ†æ•°
        diversity_scores = self.compute_diversity_scores(documents)
        
        # 4. æ—¶æ•ˆæ€§åˆ†æ•°
        freshness_scores = self.compute_freshness_scores(documents)
        
        # 5. åŠ æƒèåˆ
        final_scores = []
        for i in range(len(documents)):
            score = (
                self.semantic_weight * semantic_scores[i] +
                self.lexical_weight * lexical_scores[i] +
                self.diversity_weight * diversity_scores[i] +
                self.freshness_weight * freshness_scores[i]
            )
            final_scores.append(score)
        
        return sorted(zip(documents, final_scores), key=lambda x: x[1], reverse=True)
```

## ğŸ›ï¸ é‡æ’ç‰¹å¾å·¥ç¨‹

### 1. æ–‡æœ¬åŒ¹é…ç‰¹å¾
```python
def extract_text_features(query, document):
    return {
        # ç²¾ç¡®åŒ¹é…
        'exact_match_ratio': exact_match_count(query, document) / len(query.split()),
        
        # æ¨¡ç³ŠåŒ¹é…
        'fuzzy_match_score': fuzz.ratio(query, document) / 100,
        
        # N-gramé‡å 
        'bigram_overlap': ngram_overlap(query, document, n=2),
        'trigram_overlap': ngram_overlap(query, document, n=3),
        
        # TF-IDFç›¸ä¼¼åº¦
        'tfidf_similarity': tfidf_cosine_similarity(query, document),
        
        # BM25åˆ†æ•°
        'bm25_score': compute_bm25(query, document)
    }
```

### 2. è¯­ä¹‰ç‰¹å¾
```python
def extract_semantic_features(query, document, embeddings):
    query_emb = embeddings['query']
    doc_emb = embeddings['document']
    
    return {
        # ä½™å¼¦ç›¸ä¼¼åº¦
        'cosine_similarity': cosine_sim(query_emb, doc_emb),
        
        # æ¬§å‡ é‡Œå¾—è·ç¦»
        'euclidean_distance': euclidean_distance(query_emb, doc_emb),
        
        # æ›¼å“ˆé¡¿è·ç¦»
        'manhattan_distance': manhattan_distance(query_emb, doc_emb),
        
        # BERTåˆ†æ•°
        'bert_score': bert_score_f1(query, document),
        
        # è¯­ä¹‰è§’åº¦
        'semantic_angle': semantic_angle(query_emb, doc_emb)
    }
```

### 3. æ–‡æ¡£è´¨é‡ç‰¹å¾
```python
def extract_quality_features(document):
    return {
        # é•¿åº¦ç‰¹å¾
        'doc_length': len(document.split()),
        'sentence_count': len(sent_tokenize(document)),
        
        # å¯è¯»æ€§ç‰¹å¾
        'readability_score': textstat.flesch_reading_ease(document),
        'complexity_score': textstat.flesch_kincaid_grade(document),
        
        # ä¿¡æ¯å¯†åº¦
        'unique_word_ratio': len(set(document.split())) / len(document.split()),
        'stopword_ratio': stopword_count(document) / len(document.split()),
        
        # ç»“æ„ç‰¹å¾
        'has_headers': bool(re.search(r'^#+\s', document, re.MULTILINE)),
        'has_lists': bool(re.search(r'^\s*[-*+]\s', document, re.MULTILINE))
    }
```

## ğŸš€ å®é™…åº”ç”¨ç¤ºä¾‹

### é›†æˆåˆ°RAGç³»ç»Ÿä¸­
```python
class AdaptiveRAGWithReranking:
    def __init__(self):
        self.initial_retriever = VectorRetriever()
        self.reranker = TransformerReranker()
        self.generator = LanguageModel()
    
    def query(self, question, top_k=5, rerank_candidates=20):
        # 1. åˆå§‹æ£€ç´¢ï¼ˆè·å–æ›´å¤šå€™é€‰ï¼‰
        initial_docs = self.initial_retriever.retrieve(
            question, 
            top_k=rerank_candidates
        )
        
        # 2. é‡æ’
        reranked_docs = self.reranker.rerank(
            question, 
            initial_docs, 
            top_k=top_k
        )
        
        # 3. ç”Ÿæˆç­”æ¡ˆ
        context = "\n\n".join([doc[0] for doc in reranked_docs])
        answer = self.generator.generate(question, context)
        
        return {
            'answer': answer,
            'sources': reranked_docs,
            'confidence': self.calculate_confidence(reranked_docs)
        }
```

## ğŸ“Š æ€§èƒ½è¯„ä¼°æŒ‡æ ‡

### 1. æ’åºè´¨é‡æŒ‡æ ‡
```python
def evaluate_reranking(original_ranking, reranked_results, ground_truth):
    return {
        # NDCG (Normalized Discounted Cumulative Gain)
        'ndcg@5': ndcg_score(ground_truth, reranked_results, k=5),
        'ndcg@10': ndcg_score(ground_truth, reranked_results, k=10),
        
        # MAP (Mean Average Precision)
        'map': mean_average_precision(ground_truth, reranked_results),
        
        # MRR (Mean Reciprocal Rank)
        'mrr': mean_reciprocal_rank(ground_truth, reranked_results),
        
        # æ’åºæ”¹è¿›åº¦
        'ranking_improvement': kendall_tau(original_ranking, reranked_results)
    }
```

### 2. ç«¯åˆ°ç«¯æ•ˆæœè¯„ä¼°
```python
def evaluate_rag_with_reranking(test_questions, ground_truth_answers):
    results = []
    
    for question, gt_answer in zip(test_questions, ground_truth_answers):
        # æ— é‡æ’
        original_answer = rag_without_rerank(question)
        
        # æœ‰é‡æ’
        reranked_answer = rag_with_rerank(question)
        
        results.append({
            'question': question,
            'original_score': evaluate_answer(original_answer, gt_answer),
            'reranked_score': evaluate_answer(reranked_answer, gt_answer),
            'improvement': evaluate_answer(reranked_answer, gt_answer) - 
                          evaluate_answer(original_answer, gt_answer)
        })
    
    return results
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é‡æ’ç­–ç•¥é€‰æ‹©
- **å®æ—¶æ€§è¦æ±‚é«˜**: ä½¿ç”¨è½»é‡çº§è§„åˆ™æˆ–ç®€å•MLæ¨¡å‹
- **ç²¾åº¦è¦æ±‚é«˜**: ä½¿ç”¨æ·±åº¦å­¦ä¹ é‡æ’æ¨¡å‹
- **å¹³è¡¡æ€§èƒ½**: å¤šç­–ç•¥èåˆ + ç¼“å­˜ä¼˜åŒ–

### 2. ç‰¹å¾é€‰æ‹©åŸåˆ™
- **ç›¸å…³æ€§ç‰¹å¾**: è¯­ä¹‰ç›¸ä¼¼åº¦ã€è¯æ±‡åŒ¹é…
- **è´¨é‡ç‰¹å¾**: æ–‡æ¡£æƒå¨æ€§ã€å®Œæ•´æ€§
- **å¤šæ ·æ€§ç‰¹å¾**: é¿å…ç»“æœå†—ä½™
- **æ—¶æ•ˆæ€§ç‰¹å¾**: ä¿¡æ¯æ–°é²œåº¦

### 3. ç³»ç»Ÿä¼˜åŒ–
```python
class OptimizedReranker:
    def __init__(self):
        self.cache = LRUCache(maxsize=1000)
        self.batch_size = 32
    
    @lru_cache(maxsize=1000)
    def cached_rerank(self, query_hash, doc_hashes):
        """ç¼“å­˜é‡æ’ç»“æœ"""
        pass
    
    def batch_rerank(self, queries, documents):
        """æ‰¹é‡é‡æ’ä¼˜åŒ–"""
        pass
```

é‡æ’å‘é‡æ˜¯æå‡RAGç³»ç»Ÿæ£€ç´¢ç²¾åº¦çš„å…³é”®æŠ€æœ¯ï¼Œé€šè¿‡å¤šå±‚æ¬¡çš„ç›¸å…³æ€§è¯„ä¼°å’Œæ™ºèƒ½æ’åºï¼Œæ˜¾è‘—æé«˜äº†æœ€ç»ˆç­”æ¡ˆçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚